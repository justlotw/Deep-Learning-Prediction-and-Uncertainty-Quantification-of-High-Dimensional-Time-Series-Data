{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14d57da9-ca77-4333-ba41-8236efa46467",
   "metadata": {},
   "source": [
    "# Method: RC \n",
    "# Dataset: Lorenz-96, F = 8\n",
    "# Purpose: Uncertainty Quantification - Deep Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9711fa4f-7843-43d5-a047-14c762fd2e5f",
   "metadata": {},
   "source": [
    "# 1. Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9f852d7-2ea3-49a4-8bd5-a85ba731f802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# Package\n",
    "import sys\n",
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ee758f3-121d-4ca7-a44e-f00db4631d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from create_data import load_data\n",
    "from utils import * # Number of testing samples\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from scipy import sparse\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import value_and_grad\n",
    "from jax.numpy import tanh\n",
    "from jax.example_libraries import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee80a55c-5e5d-4120-8c56-8be07285e9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = load_data(\"Lorenz 96, F = 8\", \"../../data/lorenz8\", 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e30a3f5f-c622-4e95-ae1c-dd652be02b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (90000, 40)\n",
      "Test size: (90000, 40)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train size: {train.data.shape}\")\n",
    "print(f\"Test size: {test.data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8288061f-20ca-4fe6-840e-6ee8cd8064b1",
   "metadata": {},
   "source": [
    "**Create test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c868d5f-50c3-48a5-8762-e0de61468e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_forecast_test = 400   # steps to forecast forward (when testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a2ec67a-c0aa-45b0-b059-cb9a1dceb438",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "data_test = test.data\n",
    "\n",
    "T_test, data_dim = data_test.shape\n",
    "possible_idx = T_test - (L_forecast_test + 1) # minus number of steps forward, and the warm-up period\n",
    "T_indices = np.random.randint(0, possible_idx, size = NUM_TEST)\n",
    "\n",
    "t_past_batch = np.repeat(T_indices[:, None], WARM_UP_TEST, axis = 1).astype(int) # 200 warmup \n",
    "t_pred_batch = (T_indices[:, None] + np.arange(1, 1 + L_forecast_test)[None, :].astype(int))\n",
    "\n",
    "X_test = data_test[t_past_batch]\n",
    "y_test = data_test[t_pred_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e57b737-d4d5-41f0-9077-071567f3758f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test input size: (100, 2000, 40)\n",
      "Test output size: (100, 400, 40)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test input size: {X_test.shape}\")  # Number of test points x input length x dim\n",
    "print(f\"Test output size: {y_test.shape}\") # Number of test points x horizon x dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0bd417-72d0-4d90-8b16-30945dd0ee20",
   "metadata": {},
   "source": [
    "# 2. RC Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf9258f6-5dd2-4ddf-ab11-8f9f274ffb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameters(nn_size, connectivity, spec_radius, lambd, \n",
    "                   seed, batch_size, num_epoch, lr_schedule = [1e-4], \n",
    "                   early_stopping = EARLY_STOPPING):\n",
    "    \"\"\"\n",
    "    Returns trained parameters (beta, intercept) and hidden layer values\n",
    "    \"\"\"\n",
    "    def initialize_coef():\n",
    "        \"\"\"\n",
    "        Initializes W_in and W. \n",
    "        W_in size = nn_size x data_dim\n",
    "        W size = nn_size x nn_size\n",
    "        \"\"\"\n",
    "        start = time()\n",
    "\n",
    "        # Generate input -> hidden unit weights\n",
    "        W_in = 2 * (np.random.rand(nn_size, data_dim) - 0.5) \n",
    "        W_in = W_in / (4 * np.sqrt(data_dim))\n",
    "\n",
    "        # Generate hidden -> hidden unit weights\n",
    "        # Considers connectivity to make the matrix sparse\n",
    "        start_mat = time()\n",
    "        rows = np.concatenate([np.full(connectivity, i) for i in range(nn_size)])\n",
    "        cols = np.concatenate([np.random.choice(range(nn_size), size = connectivity, replace = False) for _ in range(nn_size)])\n",
    "        vals = np.random.uniform(low = -omega, high = omega, size = (nn_size * connectivity))\n",
    "        W = sparse.csr_matrix((vals, (rows, cols)), shape = (nn_size, nn_size))\n",
    "        end_mat = time()\n",
    "        print(f\"W generated. Time taken: {end_mat - start_mat:.2f}s\")\n",
    "\n",
    "        # Calculate eigenvalues for scaling of matrix\n",
    "        print(\"Calculating eigenvalue\")\n",
    "        e_start = time()\n",
    "        eigenvals = sparse.linalg.eigs(W, which = \"LM\", return_eigenvectors = False, k = 1)\n",
    "        max_eigen = np.abs(eigenvals)\n",
    "        e_end = time()\n",
    "        print(f\"Eigenvalue calculated. Time taken: {e_end - e_start:.2f}s\")\n",
    "\n",
    "        # Scale matrix by spectral radius\n",
    "        W = W / max_eigen * spec_radius # scale the matrix W by its spectral radius\n",
    "        W = sparse.csr_matrix(W)\n",
    "        \n",
    "        end = time()\n",
    "        print(f\"W and W_in generated. Time taken: {end-start:.2f}s\")\n",
    "        print()\n",
    "        \n",
    "        return W_in, W\n",
    "    \n",
    "    def generate_hidden_states(W_in, W):\n",
    "        \"\"\" \n",
    "        Generate hidden states (z) values\n",
    "        hidden_states size = data_size x nn_size \n",
    "        \"\"\"\n",
    "        start = time()\n",
    "        \n",
    "        print(\"Generating z values...\")\n",
    "        indiv_z = np.zeros(shape = nn_size)\n",
    "        hidden_states = np.zeros((train_size, nn_size))\n",
    "        \n",
    "        for t in range(train_size):  \n",
    "            indiv_z = (1 - alpha) * indiv_z + \\\n",
    "                alpha * np.tanh(W_in @ x[t] + W @ indiv_z)\n",
    "            hidden_states[t, :] = indiv_z\n",
    "        end = time()\n",
    "        print(f\"z values generated. Time taken: {end-start:.2f}s\")\n",
    "        \n",
    "        return hidden_states\n",
    "    \n",
    "    def mse(y, y_pred):\n",
    "        return jnp.mean((y_pred - y)**2)\n",
    "    \n",
    "    @jax.jit\n",
    "    def mse_loss(params, x, y):\n",
    "        \"\"\"\n",
    "        returns mean squared error with ridge penalty\n",
    "        \"\"\"\n",
    "        beta, intercept = params\n",
    "        pred = x @ beta + intercept\n",
    "        return mse(pred, y) + np.mean(beta**2) * lambd / 2 + np.mean(intercept**2) * lambd / 2\n",
    "    \n",
    "    def validation_loss(params, x_val, y_val):\n",
    "        beta, intercept = params\n",
    "        num_data_test, trans, data_dim = x_val.shape # testing ex, # steps used (transient), dim of data\n",
    "\n",
    "        def prediction(inp):\n",
    "            \"\"\"\n",
    "            Returns the mean of one of the testing input\n",
    "\n",
    "            mean will be a length_to_test x data_dim vector\n",
    "            \"\"\"\n",
    "            z = np.zeros((nn_size // 2, ))\n",
    "            for i in range(trans):\n",
    "                z = (1 - alpha) * z + alpha * np.tanh(W_in @ inp[i] + W @ z)\n",
    "\n",
    "            mus = []\n",
    "            stddevs = []\n",
    "\n",
    "            x = beta.T @ np.concatenate([z, z**2]) + intercept # output / input_of_next | size = dim_data\n",
    "            mus.append(x)\n",
    "\n",
    "            for _ in range(L_forecast_test - 1):\n",
    "                z = (1 - alpha) * z + alpha * np.tanh(W_in @ x + W @ z)\n",
    "                x = beta.T @ np.concatenate([z, z**2]) + intercept # output / input_of_next\n",
    "                mus.append(x)\n",
    "\n",
    "            return mus\n",
    "\n",
    "        mean_list = []\n",
    "        sd_list = []\n",
    "\n",
    "        for i in range(num_data_test):\n",
    "            pred = prediction(x_val[i])\n",
    "            mean_list.append(pred)\n",
    "\n",
    "        return mse(mean_list, y_val)\n",
    "\n",
    "    def training(x, y):\n",
    "        \"\"\" \n",
    "        Trains regression of y~x using SGD. \n",
    "        Returns parameters (beta, intercept) where \n",
    "        beta, intercept -> weights to determine the mean\n",
    "        \n",
    "        beta size = nn_size x data_dim\n",
    "        intercept = data_dim (will be added for each training data)\n",
    "        \n",
    "        should predict a mu with train_size x data_dim (\\mu per dimension per datapoint)\n",
    "        and a sigma with train_size x 1 (single \\sigma for all dimensions per datapoint)\n",
    "        \"\"\"\n",
    "        \n",
    "        @jax.jit\n",
    "        def step(opt_state, x, y):\n",
    "            params = get_params(opt_state)\n",
    "            value, g = value_and_grad(mse_loss)(params, x, y)\n",
    "            opt_state = opt_update(0, g, opt_state)\n",
    "            return get_params(opt_state), opt_state, value\n",
    "\n",
    "        start = time()\n",
    "        \n",
    "        # Plot loss\n",
    "        loss_train_traj = []\n",
    "        loss_train_all_traj = []\n",
    "        \n",
    "        # Init parameters\n",
    "        beta = np.random.normal(0, 1 / np.sqrt(nn_size), size = (nn_size, data_dim))\n",
    "        intercept = np.random.normal(0, 1 / np.sqrt(nn_size * 2), size = (data_dim, ))\n",
    "        \n",
    "        t_size = int(1. * train_size)\n",
    "        # v_size = train_size - t_size\n",
    "        # t_start_val = np.linspace(t_size, train_size - (L_forecast_test + 2), NUM_TEST // 2, dtype = int)\n",
    "        # t_past_batch_val = np.repeat(t_start_val[:, None], WARM_UP_TEST, axis = 1).astype(int) \n",
    "        # t_pred_batch_val = (t_start_val[:,None] + np.arange(1,1+L_forecast_test)[None,:]).astype(int) \n",
    "        # x_val = copy_x[t_past_batch_val] \n",
    "        # y_val = copy_y[t_pred_batch_val]\n",
    "        \n",
    "        overall_best_mse = 9999999\n",
    "        \n",
    "        for i, lr in enumerate(lr_schedule):\n",
    "            opt_init, opt_update, get_params = optimizers.adam(step_size = lr) \n",
    "            opt_state = opt_init([beta, intercept])\n",
    "            \n",
    "            # For early stopping\n",
    "            best_state = opt_state\n",
    "            counter = 0 \n",
    "            best_val_loss = 9999999\n",
    "            \n",
    "            for epoch in range(num_epoch[i]):\n",
    "                e_start = time()\n",
    "                \n",
    "                T_indices = np.arange(train_size)\n",
    "                np.random.shuffle(T_indices)\n",
    "\n",
    "                loss_epoch_train = []\n",
    "                for k in range(t_size // batch_size + 1):\n",
    "                    t_start = T_indices[np.arange(k * batch_size, (k+1) * batch_size).astype(int) % len(T_indices)]\n",
    "                    x_batch = x[t_start]\n",
    "                    y_batch = y[t_start]\n",
    "\n",
    "                    params, opt_state, l = step(opt_state, x_batch, y_batch)\n",
    "                    loss_epoch_train.append(l)\n",
    "                \n",
    "                \n",
    "                loss_train_all_traj += loss_epoch_train\n",
    "                mse_train = np.mean(loss_epoch_train)\n",
    "                loss_train_traj.append(mse_train)\n",
    "                \n",
    "                e_end = time()\n",
    "                \n",
    "                if mse_train < best_val_loss:\n",
    "                    best_val_loss = mse_train\n",
    "                    counter = 0\n",
    "                    best_state = opt_state\n",
    "                else:\n",
    "                    counter += 1\n",
    "                    \n",
    "                if (epoch + 1) % 10 == 0 or (counter == 0 and epoch > 49):\n",
    "                    print(f\"Epoch {epoch + 1}: Train time = {e_end - e_start:.2f} | Train Loss = {mse_train:.7f}\", end = \" \")\n",
    "                    \n",
    "                    # when_to_evaluate = 199 if i == 0 else 49\n",
    "                    # if epoch >= when_to_evaluate:\n",
    "                    #     # Validation\n",
    "                    #     val_start = time()\n",
    "                    #     mse_val = validation_loss(params, x_val, y_val)\n",
    "                    #     if best_val_loss > mse_val: # Improvement \n",
    "                    #         counter = 0\n",
    "                    #         best_val_loss = mse_val\n",
    "                    #         best_state = opt_state\n",
    "                    #     else:\n",
    "                    #         counter += 1    \n",
    "                        # val_end = time()\n",
    "                        # print(f\"| Val time: {val_end - val_start:2f} | Val loss: {mse_val:.7f}\", end = \"\")\n",
    "                    print()\n",
    "                if counter == early_stopping:\n",
    "                    print(f\"EARLY STOPPING. Epoch {epoch + 1}: Train loss = {mse_train:.7f}\")\n",
    "                    break\n",
    "            \n",
    "            print(f\"Best Training MSE: {best_val_loss:.7f}\") \n",
    "            \n",
    "            if best_val_loss < overall_best_mse:\n",
    "                print(\"IMPROVED VALIDATION MSE\")\n",
    "                overall_best_mse = best_val_loss\n",
    "                overall_best_state = best_state\n",
    "            \n",
    "            beta, intercept = get_params(overall_best_state)\n",
    "            print()\n",
    "        \n",
    "        end = time()\n",
    "        print(f\"Total time: {end - start:.2f}\")\n",
    "        \n",
    "        return get_params(overall_best_state) # beta, intercept\n",
    "    \n",
    "    start = time()\n",
    "   \n",
    "    x, y = train.data[:-1], train.data[1:]\n",
    "    copy_x, copy_y = x, y \n",
    "    train_size, data_dim = x.data.shape\n",
    "       \n",
    "    np.random.seed(seed)\n",
    "    W_in, W = initialize_coef()\n",
    "    z = generate_hidden_states(W_in, W)\n",
    "\n",
    "    # Want to regression Y ~ X ==> Y ~ [z, z**2]\n",
    "    final_y = y[transient:]\n",
    "    final_z = z[transient:]\n",
    "    print(\"Concatenating z with z**2\", end = \" \"); concat_start = time()\n",
    "    final_z = np.concatenate([final_z, final_z**2], axis = 1) # shape: train_size x (nn_size*2)\n",
    "    concat_end = time()\n",
    "    print(f\"Contenation complete. Time taken: {concat_end-concat_start:.2f}s\", end = \"\\n\\n\")\n",
    "    \n",
    "    train_size, nn_size = final_z.shape\n",
    "    \n",
    "    params = training(final_z, final_y)\n",
    "    end = time()\n",
    "    print(f\"Complete. Time taken: {end - start:.2f}s\")\n",
    "    \n",
    "    return params, (final_z, W_in, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2863ad98-35c2-435c-bcea-86318c9152df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_pred(data_test, nn_size, params, W_in, W):   \n",
    "    beta, intercept = params\n",
    "    num_data_test, trans, data_dim = data_test.shape # testing ex, # steps used (transient), dim of data\n",
    "    \n",
    "    def prediction(inp):\n",
    "        \"\"\"\n",
    "        Returns the mean of one of the testing input\n",
    "        \n",
    "        mean will be a length_to_test x data_dim vector\n",
    "        \"\"\"\n",
    "        \n",
    "        z = np.zeros((nn_size, ))\n",
    "        for i in range(trans):\n",
    "            z = (1 - alpha) * z + alpha * np.tanh(W_in @ inp[i] + W @ z)\n",
    "        \n",
    "        mus = []\n",
    "        stddevs = []\n",
    "        \n",
    "        x = beta.T @ np.concatenate([z, z**2]) + intercept # output / input_of_next | size = dim_data\n",
    "        mus.append(x)\n",
    "        \n",
    "        for _ in range(L_forecast_test - 1):\n",
    "            z = (1 - alpha) * z + alpha * np.tanh(W_in @ x + W @ z)\n",
    "            x = beta.T @ np.concatenate([z, z**2]) + intercept # output / input_of_next\n",
    "            mus.append(x)\n",
    "        \n",
    "        return mus\n",
    "    \n",
    "    start = time()\n",
    "    \n",
    "    mean_list = []\n",
    "    sd_list = []\n",
    "    \n",
    "    for i in range(num_data_test):\n",
    "        pred = prediction(data_test[i])\n",
    "        mean_list.append(pred)\n",
    "\n",
    "        if (i+1) % 10 == 0:\n",
    "            print(f\"{(i+1) / num_data_test * 100:.2f}% done\")\n",
    "    \n",
    "    end = time()\n",
    "    print(f\"Testing complete. Time taken: {end - start:.2f}\")\n",
    "    return np.array(mean_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffce42df-dfac-4615-b07e-4446a271acf9",
   "metadata": {},
   "source": [
    "# 3. Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fcf92b1-c8cb-4996-939f-882d454fb811",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_size = 12000\n",
    "ridge_penalty = 1e-6\n",
    "spec_radius = 0.1\n",
    "connectivity = 4\n",
    "\n",
    "lr_list = [1e-4]\n",
    "epoch_list = [300]\n",
    "\n",
    "transient = 200  # points to ignore to allow system to stabilise\n",
    "omega = 1         # scale of the values of matrix W\n",
    "alpha = 1         # hidden state memory\n",
    "b_size = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7070f12-ba7a-4599-9006-1beede669821",
   "metadata": {},
   "source": [
    "# 4. Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e54bdb2a-a05c-4129-91df-09d5cad7520f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_folder = os.path.join(\"results\", \"ensemble\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e889a637-c08a-4c93-89a7-9e47d06cd87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_seed(seed):\n",
    "    \"\"\"\n",
    "    Runs the experiment with optimal parameters and saves the predictions into a file\n",
    "    \"\"\"\n",
    "    params, internal = get_parameters(nn_size, connectivity, spec_radius, lambd = ridge_penalty, seed = seed, \n",
    "                                  batch_size = b_size, num_epoch = epoch_list, lr_schedule = lr_list)\n",
    "    _, W_in, W = internal\n",
    "    mean_pred = get_test_pred(X_test, nn_size, params, W_in, W)\n",
    "    file_name = \"mu_preds_\" + str(seed) + \".pkl\"\n",
    "    save_obj(mean_pred, res_folder, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b029e63e-02d0-42b0-bbf9-e982688efdb0",
   "metadata": {},
   "source": [
    "## 4.1 Seed 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94a029d6-0662-428d-979b-516d596711c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W generated. Time taken: 28.40s\n",
      "Calculating eigenvalue\n",
      "Eigenvalue calculated. Time taken: 3.91s\n",
      "W and W_in generated. Time taken: 36.03s\n",
      "\n",
      "Generating z values...\n",
      "z values generated. Time taken: 58.19s\n",
      "Concatenating z with z**2 Contenation complete. Time taken: 14.07s\n",
      "\n",
      "Epoch 10: Train time = 10.46 | Train Loss = 0.0000118 \n",
      "Epoch 20: Train time = 9.73 | Train Loss = 0.0000126 \n",
      "Epoch 30: Train time = 10.38 | Train Loss = 0.0000117 \n",
      "Epoch 40: Train time = 10.35 | Train Loss = 0.0000108 \n",
      "Epoch 50: Train time = 10.35 | Train Loss = 0.0000100 \n",
      "Epoch 51: Train time = 10.43 | Train Loss = 0.0000098 \n",
      "Epoch 53: Train time = 10.45 | Train Loss = 0.0000097 \n",
      "Epoch 54: Train time = 10.43 | Train Loss = 0.0000096 \n",
      "Epoch 55: Train time = 10.39 | Train Loss = 0.0000095 \n",
      "Epoch 57: Train time = 10.00 | Train Loss = 0.0000094 \n",
      "Epoch 59: Train time = 10.32 | Train Loss = 0.0000093 \n",
      "Epoch 60: Train time = 9.91 | Train Loss = 0.0000091 \n",
      "Epoch 63: Train time = 10.31 | Train Loss = 0.0000090 \n",
      "Epoch 64: Train time = 10.35 | Train Loss = 0.0000089 \n",
      "Epoch 66: Train time = 10.39 | Train Loss = 0.0000088 \n",
      "Epoch 67: Train time = 10.34 | Train Loss = 0.0000088 \n",
      "Epoch 68: Train time = 10.32 | Train Loss = 0.0000088 \n",
      "Epoch 69: Train time = 10.42 | Train Loss = 0.0000086 \n",
      "Epoch 70: Train time = 10.40 | Train Loss = 0.0000086 \n",
      "Epoch 71: Train time = 10.31 | Train Loss = 0.0000085 \n",
      "Epoch 72: Train time = 10.28 | Train Loss = 0.0000084 \n",
      "Epoch 74: Train time = 10.31 | Train Loss = 0.0000083 \n",
      "Epoch 75: Train time = 10.28 | Train Loss = 0.0000083 \n",
      "Epoch 76: Train time = 10.39 | Train Loss = 0.0000082 \n",
      "Epoch 78: Train time = 10.35 | Train Loss = 0.0000081 \n",
      "Epoch 79: Train time = 10.38 | Train Loss = 0.0000081 \n",
      "Epoch 80: Train time = 10.31 | Train Loss = 0.0000080 \n",
      "Epoch 81: Train time = 10.45 | Train Loss = 0.0000080 \n",
      "Epoch 82: Train time = 10.33 | Train Loss = 0.0000079 \n",
      "Epoch 83: Train time = 10.30 | Train Loss = 0.0000079 \n",
      "Epoch 84: Train time = 9.71 | Train Loss = 0.0000079 \n",
      "Epoch 85: Train time = 9.68 | Train Loss = 0.0000077 \n",
      "Epoch 86: Train time = 10.01 | Train Loss = 0.0000077 \n",
      "Epoch 88: Train time = 10.38 | Train Loss = 0.0000075 \n",
      "Epoch 90: Train time = 9.88 | Train Loss = 0.0000075 \n",
      "Epoch 92: Train time = 10.29 | Train Loss = 0.0000074 \n",
      "Epoch 94: Train time = 10.37 | Train Loss = 0.0000072 \n",
      "Epoch 98: Train time = 10.44 | Train Loss = 0.0000072 \n",
      "Epoch 99: Train time = 10.46 | Train Loss = 0.0000071 \n",
      "Epoch 100: Train time = 10.18 | Train Loss = 0.0000071 \n",
      "Epoch 101: Train time = 10.19 | Train Loss = 0.0000070 \n",
      "Epoch 103: Train time = 10.50 | Train Loss = 0.0000070 \n",
      "Epoch 104: Train time = 10.40 | Train Loss = 0.0000070 \n",
      "Epoch 105: Train time = 10.43 | Train Loss = 0.0000069 \n",
      "Epoch 106: Train time = 10.57 | Train Loss = 0.0000069 \n",
      "Epoch 107: Train time = 10.39 | Train Loss = 0.0000068 \n",
      "Epoch 108: Train time = 10.36 | Train Loss = 0.0000068 \n",
      "Epoch 109: Train time = 10.35 | Train Loss = 0.0000067 \n",
      "Epoch 110: Train time = 11.45 | Train Loss = 0.0000067 \n",
      "Epoch 111: Train time = 10.77 | Train Loss = 0.0000066 \n",
      "Epoch 112: Train time = 10.89 | Train Loss = 0.0000066 \n",
      "Epoch 114: Train time = 10.99 | Train Loss = 0.0000065 \n",
      "Epoch 115: Train time = 11.51 | Train Loss = 0.0000065 \n",
      "Epoch 117: Train time = 10.77 | Train Loss = 0.0000064 \n",
      "Epoch 119: Train time = 10.45 | Train Loss = 0.0000064 \n",
      "Epoch 120: Train time = 10.88 | Train Loss = 0.0000063 \n",
      "Epoch 122: Train time = 10.76 | Train Loss = 0.0000063 \n",
      "Epoch 124: Train time = 10.61 | Train Loss = 0.0000063 \n",
      "Epoch 125: Train time = 10.88 | Train Loss = 0.0000061 \n",
      "Epoch 127: Train time = 10.81 | Train Loss = 0.0000061 \n",
      "Epoch 128: Train time = 10.88 | Train Loss = 0.0000061 \n",
      "Epoch 130: Train time = 10.82 | Train Loss = 0.0000060 \n",
      "Epoch 131: Train time = 10.82 | Train Loss = 0.0000060 \n",
      "Epoch 132: Train time = 10.83 | Train Loss = 0.0000060 \n",
      "Epoch 133: Train time = 10.79 | Train Loss = 0.0000060 \n",
      "Epoch 134: Train time = 10.90 | Train Loss = 0.0000059 \n",
      "Epoch 135: Train time = 10.74 | Train Loss = 0.0000059 \n",
      "Epoch 137: Train time = 10.61 | Train Loss = 0.0000058 \n",
      "Epoch 140: Train time = 10.80 | Train Loss = 0.0000057 \n",
      "Epoch 143: Train time = 10.80 | Train Loss = 0.0000057 \n",
      "Epoch 145: Train time = 10.70 | Train Loss = 0.0000056 \n",
      "Epoch 147: Train time = 10.60 | Train Loss = 0.0000055 \n",
      "Epoch 150: Train time = 10.64 | Train Loss = 0.0000055 \n",
      "Epoch 151: Train time = 10.67 | Train Loss = 0.0000054 \n",
      "Epoch 153: Train time = 10.62 | Train Loss = 0.0000054 \n",
      "Epoch 158: Train time = 10.73 | Train Loss = 0.0000052 \n",
      "Epoch 160: Train time = 10.73 | Train Loss = 0.0000053 \n",
      "Epoch 162: Train time = 10.75 | Train Loss = 0.0000052 \n",
      "Epoch 164: Train time = 10.69 | Train Loss = 0.0000052 \n",
      "Epoch 165: Train time = 10.69 | Train Loss = 0.0000052 \n",
      "Epoch 166: Train time = 10.79 | Train Loss = 0.0000051 \n",
      "Epoch 167: Train time = 10.57 | Train Loss = 0.0000051 \n",
      "Epoch 170: Train time = 10.70 | Train Loss = 0.0000050 \n",
      "Epoch 173: Train time = 10.46 | Train Loss = 0.0000050 \n",
      "Epoch 176: Train time = 10.29 | Train Loss = 0.0000049 \n",
      "Epoch 178: Train time = 10.42 | Train Loss = 0.0000049 \n",
      "Epoch 179: Train time = 10.07 | Train Loss = 0.0000049 \n",
      "Epoch 180: Train time = 10.29 | Train Loss = 0.0000049 \n",
      "Epoch 181: Train time = 10.14 | Train Loss = 0.0000048 \n",
      "Epoch 186: Train time = 10.41 | Train Loss = 0.0000047 \n",
      "Epoch 189: Train time = 10.33 | Train Loss = 0.0000047 \n",
      "Epoch 190: Train time = 10.34 | Train Loss = 0.0000048 \n",
      "Epoch 191: Train time = 10.33 | Train Loss = 0.0000047 \n",
      "Epoch 192: Train time = 10.36 | Train Loss = 0.0000046 \n",
      "Epoch 195: Train time = 10.30 | Train Loss = 0.0000046 \n",
      "Epoch 196: Train time = 10.36 | Train Loss = 0.0000046 \n",
      "Epoch 197: Train time = 9.96 | Train Loss = 0.0000046 \n",
      "Epoch 198: Train time = 10.45 | Train Loss = 0.0000046 \n",
      "Epoch 200: Train time = 10.33 | Train Loss = 0.0000045 \n",
      "Epoch 203: Train time = 9.87 | Train Loss = 0.0000044 \n",
      "Epoch 204: Train time = 10.35 | Train Loss = 0.0000044 \n",
      "Epoch 208: Train time = 10.22 | Train Loss = 0.0000044 \n",
      "Epoch 209: Train time = 10.41 | Train Loss = 0.0000044 \n",
      "Epoch 210: Train time = 10.39 | Train Loss = 0.0000044 \n",
      "Epoch 212: Train time = 10.45 | Train Loss = 0.0000044 \n",
      "Epoch 214: Train time = 10.09 | Train Loss = 0.0000044 \n",
      "Epoch 215: Train time = 10.06 | Train Loss = 0.0000043 \n",
      "Epoch 217: Train time = 10.39 | Train Loss = 0.0000042 \n",
      "Epoch 220: Train time = 10.12 | Train Loss = 0.0000043 \n",
      "Epoch 222: Train time = 10.36 | Train Loss = 0.0000042 \n",
      "Epoch 224: Train time = 10.23 | Train Loss = 0.0000042 \n",
      "Epoch 225: Train time = 10.34 | Train Loss = 0.0000041 \n",
      "Epoch 230: Train time = 10.52 | Train Loss = 0.0000041 \n",
      "Epoch 233: Train time = 10.44 | Train Loss = 0.0000040 \n",
      "Epoch 236: Train time = 10.37 | Train Loss = 0.0000040 \n",
      "Epoch 238: Train time = 10.39 | Train Loss = 0.0000040 \n",
      "Epoch 240: Train time = 10.34 | Train Loss = 0.0000040 \n",
      "Epoch 241: Train time = 10.34 | Train Loss = 0.0000039 \n",
      "Epoch 246: Train time = 10.32 | Train Loss = 0.0000039 \n",
      "Epoch 250: Train time = 10.38 | Train Loss = 0.0000039 \n",
      "Epoch 258: Train time = 10.38 | Train Loss = 0.0000037 \n",
      "Epoch 260: Train time = 10.48 | Train Loss = 0.0000038 \n",
      "Epoch 268: Train time = 10.24 | Train Loss = 0.0000037 \n",
      "Epoch 270: Train time = 9.88 | Train Loss = 0.0000038 \n",
      "Epoch 271: Train time = 10.29 | Train Loss = 0.0000037 \n",
      "Epoch 272: Train time = 10.39 | Train Loss = 0.0000036 \n",
      "Epoch 276: Train time = 10.35 | Train Loss = 0.0000036 \n",
      "Epoch 280: Train time = 10.34 | Train Loss = 0.0000036 \n",
      "Epoch 286: Train time = 10.40 | Train Loss = 0.0000035 \n",
      "Epoch 288: Train time = 9.91 | Train Loss = 0.0000035 \n",
      "Epoch 290: Train time = 10.35 | Train Loss = 0.0000035 \n",
      "Epoch 294: Train time = 10.43 | Train Loss = 0.0000034 \n",
      "Epoch 299: Train time = 9.64 | Train Loss = 0.0000034 \n",
      "Epoch 300: Train time = 9.94 | Train Loss = 0.0000035 \n",
      "Best Training MSE: 0.0000034\n",
      "IMPROVED VALIDATION MSE\n",
      "\n",
      "Total time: 3122.45\n",
      "Complete. Time taken: 3231.12s\n",
      "10.00% done\n",
      "20.00% done\n",
      "30.00% done\n",
      "40.00% done\n",
      "50.00% done\n",
      "60.00% done\n",
      "70.00% done\n",
      "80.00% done\n",
      "90.00% done\n",
      "100.00% done\n",
      "Testing complete. Time taken: 179.52\n"
     ]
    }
   ],
   "source": [
    "run_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1bcbde-a902-403b-8e4b-7a33bb214bf6",
   "metadata": {},
   "source": [
    "## 4.2 Seed 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "234ce9db-336a-4605-935c-509ca931f01c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W generated. Time taken: 21.91s\n",
      "Calculating eigenvalue\n",
      "Eigenvalue calculated. Time taken: 10.11s\n",
      "W and W_in generated. Time taken: 35.21s\n",
      "\n",
      "Generating z values...\n",
      "z values generated. Time taken: 55.08s\n",
      "Concatenating z with z**2 Contenation complete. Time taken: 12.23s\n",
      "\n",
      "Epoch 10: Train time = 11.47 | Train Loss = 0.0000118 \n",
      "Epoch 20: Train time = 11.33 | Train Loss = 0.0000125 \n",
      "Epoch 30: Train time = 11.53 | Train Loss = 0.0000117 \n",
      "Epoch 40: Train time = 11.51 | Train Loss = 0.0000108 \n",
      "Epoch 50: Train time = 11.29 | Train Loss = 0.0000098 \n",
      "Epoch 51: Train time = 11.41 | Train Loss = 0.0000098 \n",
      "Epoch 52: Train time = 11.40 | Train Loss = 0.0000097 \n",
      "Epoch 54: Train time = 11.31 | Train Loss = 0.0000096 \n",
      "Epoch 55: Train time = 11.41 | Train Loss = 0.0000096 \n",
      "Epoch 56: Train time = 11.50 | Train Loss = 0.0000095 \n",
      "Epoch 57: Train time = 11.44 | Train Loss = 0.0000095 \n",
      "Epoch 58: Train time = 11.30 | Train Loss = 0.0000093 \n",
      "Epoch 59: Train time = 11.40 | Train Loss = 0.0000092 \n",
      "Epoch 60: Train time = 11.35 | Train Loss = 0.0000092 \n",
      "Epoch 61: Train time = 11.56 | Train Loss = 0.0000092 \n",
      "Epoch 62: Train time = 11.37 | Train Loss = 0.0000090 \n",
      "Epoch 63: Train time = 11.41 | Train Loss = 0.0000090 \n",
      "Epoch 64: Train time = 11.36 | Train Loss = 0.0000090 \n",
      "Epoch 65: Train time = 11.33 | Train Loss = 0.0000088 \n",
      "Epoch 66: Train time = 11.36 | Train Loss = 0.0000088 \n",
      "Epoch 67: Train time = 11.48 | Train Loss = 0.0000088 \n",
      "Epoch 68: Train time = 11.31 | Train Loss = 0.0000087 \n",
      "Epoch 69: Train time = 11.40 | Train Loss = 0.0000086 \n",
      "Epoch 70: Train time = 11.54 | Train Loss = 0.0000086 \n",
      "Epoch 71: Train time = 11.50 | Train Loss = 0.0000084 \n",
      "Epoch 74: Train time = 11.36 | Train Loss = 0.0000082 \n",
      "Epoch 75: Train time = 11.38 | Train Loss = 0.0000082 \n",
      "Epoch 77: Train time = 11.41 | Train Loss = 0.0000082 \n",
      "Epoch 78: Train time = 11.45 | Train Loss = 0.0000081 \n",
      "Epoch 79: Train time = 11.53 | Train Loss = 0.0000080 \n",
      "Epoch 80: Train time = 11.46 | Train Loss = 0.0000080 \n",
      "Epoch 81: Train time = 11.55 | Train Loss = 0.0000079 \n",
      "Epoch 83: Train time = 11.12 | Train Loss = 0.0000078 \n",
      "Epoch 85: Train time = 11.85 | Train Loss = 0.0000078 \n",
      "Epoch 86: Train time = 11.71 | Train Loss = 0.0000077 \n",
      "Epoch 87: Train time = 11.82 | Train Loss = 0.0000076 \n",
      "Epoch 89: Train time = 11.69 | Train Loss = 0.0000076 \n",
      "Epoch 90: Train time = 11.64 | Train Loss = 0.0000075 \n",
      "Epoch 91: Train time = 11.60 | Train Loss = 0.0000075 \n",
      "Epoch 93: Train time = 12.01 | Train Loss = 0.0000074 \n",
      "Epoch 94: Train time = 11.83 | Train Loss = 0.0000073 \n",
      "Epoch 96: Train time = 11.66 | Train Loss = 0.0000072 \n",
      "Epoch 98: Train time = 11.65 | Train Loss = 0.0000071 \n",
      "Epoch 100: Train time = 11.57 | Train Loss = 0.0000071 \n",
      "Epoch 101: Train time = 11.68 | Train Loss = 0.0000070 \n",
      "Epoch 102: Train time = 11.51 | Train Loss = 0.0000069 \n",
      "Epoch 105: Train time = 11.61 | Train Loss = 0.0000068 \n",
      "Epoch 107: Train time = 11.88 | Train Loss = 0.0000068 \n",
      "Epoch 108: Train time = 11.68 | Train Loss = 0.0000068 \n",
      "Epoch 109: Train time = 11.55 | Train Loss = 0.0000068 \n",
      "Epoch 110: Train time = 11.33 | Train Loss = 0.0000066 \n",
      "Epoch 112: Train time = 10.34 | Train Loss = 0.0000066 \n",
      "Epoch 113: Train time = 10.47 | Train Loss = 0.0000066 \n",
      "Epoch 114: Train time = 10.34 | Train Loss = 0.0000065 \n",
      "Epoch 115: Train time = 10.30 | Train Loss = 0.0000065 \n",
      "Epoch 117: Train time = 10.27 | Train Loss = 0.0000063 \n",
      "Epoch 118: Train time = 10.25 | Train Loss = 0.0000063 \n",
      "Epoch 120: Train time = 10.22 | Train Loss = 0.0000063 \n",
      "Epoch 122: Train time = 10.27 | Train Loss = 0.0000062 \n",
      "Epoch 124: Train time = 10.33 | Train Loss = 0.0000062 \n",
      "Epoch 126: Train time = 10.26 | Train Loss = 0.0000062 \n",
      "Epoch 127: Train time = 10.33 | Train Loss = 0.0000061 \n",
      "Epoch 128: Train time = 10.24 | Train Loss = 0.0000060 \n",
      "Epoch 130: Train time = 10.36 | Train Loss = 0.0000060 \n",
      "Epoch 131: Train time = 10.18 | Train Loss = 0.0000060 \n",
      "Epoch 132: Train time = 10.39 | Train Loss = 0.0000060 \n",
      "Epoch 133: Train time = 10.34 | Train Loss = 0.0000059 \n",
      "Epoch 137: Train time = 10.51 | Train Loss = 0.0000058 \n",
      "Epoch 138: Train time = 10.41 | Train Loss = 0.0000058 \n",
      "Epoch 139: Train time = 10.39 | Train Loss = 0.0000057 \n",
      "Epoch 140: Train time = 10.35 | Train Loss = 0.0000057 \n",
      "Epoch 143: Train time = 10.23 | Train Loss = 0.0000057 \n",
      "Epoch 144: Train time = 10.38 | Train Loss = 0.0000056 \n",
      "Epoch 147: Train time = 10.27 | Train Loss = 0.0000056 \n",
      "Epoch 148: Train time = 10.27 | Train Loss = 0.0000055 \n",
      "Epoch 150: Train time = 10.30 | Train Loss = 0.0000055 \n",
      "Epoch 151: Train time = 10.21 | Train Loss = 0.0000054 \n",
      "Epoch 153: Train time = 10.32 | Train Loss = 0.0000054 \n",
      "Epoch 154: Train time = 10.27 | Train Loss = 0.0000054 \n",
      "Epoch 157: Train time = 10.31 | Train Loss = 0.0000053 \n",
      "Epoch 159: Train time = 10.28 | Train Loss = 0.0000053 \n",
      "Epoch 160: Train time = 10.24 | Train Loss = 0.0000053 \n",
      "Epoch 161: Train time = 10.37 | Train Loss = 0.0000053 \n",
      "Epoch 162: Train time = 10.27 | Train Loss = 0.0000052 \n",
      "Epoch 164: Train time = 10.30 | Train Loss = 0.0000051 \n",
      "Epoch 168: Train time = 10.33 | Train Loss = 0.0000051 \n",
      "Epoch 169: Train time = 10.29 | Train Loss = 0.0000050 \n",
      "Epoch 170: Train time = 10.35 | Train Loss = 0.0000050 \n",
      "Epoch 172: Train time = 10.32 | Train Loss = 0.0000050 \n",
      "Epoch 174: Train time = 10.26 | Train Loss = 0.0000050 \n",
      "Epoch 175: Train time = 10.27 | Train Loss = 0.0000050 \n",
      "Epoch 176: Train time = 10.29 | Train Loss = 0.0000049 \n",
      "Epoch 177: Train time = 10.30 | Train Loss = 0.0000049 \n",
      "Epoch 179: Train time = 10.29 | Train Loss = 0.0000048 \n",
      "Epoch 180: Train time = 10.32 | Train Loss = 0.0000049 \n",
      "Epoch 181: Train time = 10.28 | Train Loss = 0.0000048 \n",
      "Epoch 182: Train time = 10.33 | Train Loss = 0.0000048 \n",
      "Epoch 184: Train time = 10.26 | Train Loss = 0.0000047 \n",
      "Epoch 187: Train time = 10.37 | Train Loss = 0.0000047 \n",
      "Epoch 188: Train time = 10.29 | Train Loss = 0.0000047 \n",
      "Epoch 190: Train time = 10.33 | Train Loss = 0.0000047 \n",
      "Epoch 192: Train time = 10.37 | Train Loss = 0.0000046 \n",
      "Epoch 195: Train time = 10.28 | Train Loss = 0.0000045 \n",
      "Epoch 199: Train time = 10.26 | Train Loss = 0.0000045 \n",
      "Epoch 200: Train time = 10.27 | Train Loss = 0.0000046 \n",
      "Epoch 202: Train time = 10.29 | Train Loss = 0.0000045 \n",
      "Epoch 204: Train time = 10.30 | Train Loss = 0.0000044 \n",
      "Epoch 207: Train time = 10.25 | Train Loss = 0.0000044 \n",
      "Epoch 210: Train time = 10.29 | Train Loss = 0.0000043 \n",
      "Epoch 215: Train time = 10.26 | Train Loss = 0.0000042 \n",
      "Epoch 219: Train time = 10.26 | Train Loss = 0.0000042 \n",
      "Epoch 220: Train time = 10.30 | Train Loss = 0.0000043 \n",
      "Epoch 221: Train time = 10.34 | Train Loss = 0.0000042 \n",
      "Epoch 225: Train time = 10.24 | Train Loss = 0.0000041 \n",
      "Epoch 228: Train time = 10.37 | Train Loss = 0.0000041 \n",
      "Epoch 230: Train time = 10.37 | Train Loss = 0.0000041 \n",
      "Epoch 233: Train time = 10.36 | Train Loss = 0.0000041 \n",
      "Epoch 235: Train time = 10.29 | Train Loss = 0.0000040 \n",
      "Epoch 236: Train time = 10.31 | Train Loss = 0.0000040 \n",
      "Epoch 240: Train time = 10.34 | Train Loss = 0.0000040 \n",
      "Epoch 242: Train time = 10.54 | Train Loss = 0.0000040 \n",
      "Epoch 244: Train time = 10.28 | Train Loss = 0.0000039 \n",
      "Epoch 247: Train time = 10.33 | Train Loss = 0.0000038 \n",
      "Epoch 250: Train time = 10.34 | Train Loss = 0.0000039 \n",
      "Epoch 253: Train time = 10.27 | Train Loss = 0.0000038 \n",
      "Epoch 258: Train time = 10.30 | Train Loss = 0.0000038 \n",
      "Epoch 260: Train time = 10.28 | Train Loss = 0.0000038 \n",
      "Epoch 264: Train time = 10.34 | Train Loss = 0.0000038 \n",
      "Epoch 265: Train time = 10.32 | Train Loss = 0.0000037 \n",
      "Epoch 270: Train time = 10.29 | Train Loss = 0.0000038 \n",
      "Epoch 271: Train time = 10.62 | Train Loss = 0.0000037 \n",
      "Epoch 272: Train time = 10.31 | Train Loss = 0.0000036 \n",
      "Epoch 279: Train time = 10.33 | Train Loss = 0.0000036 \n",
      "Epoch 280: Train time = 10.35 | Train Loss = 0.0000036 \n",
      "Epoch 282: Train time = 10.35 | Train Loss = 0.0000036 \n",
      "Epoch 287: Train time = 10.35 | Train Loss = 0.0000035 \n",
      "Epoch 289: Train time = 10.28 | Train Loss = 0.0000035 \n",
      "Epoch 290: Train time = 10.23 | Train Loss = 0.0000036 \n",
      "Epoch 292: Train time = 10.36 | Train Loss = 0.0000035 \n",
      "Epoch 294: Train time = 10.38 | Train Loss = 0.0000035 \n",
      "Epoch 297: Train time = 10.30 | Train Loss = 0.0000035 \n",
      "Epoch 298: Train time = 10.30 | Train Loss = 0.0000035 \n",
      "Epoch 299: Train time = 10.26 | Train Loss = 0.0000035 \n",
      "Epoch 300: Train time = 10.23 | Train Loss = 0.0000034 \n",
      "Best Training MSE: 0.0000034\n",
      "IMPROVED VALIDATION MSE\n",
      "\n",
      "Total time: 3227.19\n",
      "Complete. Time taken: 3330.15s\n",
      "10.00% done\n",
      "20.00% done\n",
      "30.00% done\n",
      "40.00% done\n",
      "50.00% done\n",
      "60.00% done\n",
      "70.00% done\n",
      "80.00% done\n",
      "90.00% done\n",
      "100.00% done\n",
      "Testing complete. Time taken: 158.29\n"
     ]
    }
   ],
   "source": [
    "run_seed(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abf4d4d-b41c-4b37-afd7-947a70837ff8",
   "metadata": {},
   "source": [
    "## 4.3 Seed 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f751f451-8373-4ae3-b8b3-594b344fa18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W generated. Time taken: 20.61s\n",
      "Calculating eigenvalue\n",
      "Eigenvalue calculated. Time taken: 0.89s\n",
      "W and W_in generated. Time taken: 24.54s\n",
      "\n",
      "Generating z values...\n",
      "z values generated. Time taken: 44.75s\n",
      "Concatenating z with z**2 Contenation complete. Time taken: 10.31s\n",
      "\n",
      "Epoch 10: Train time = 10.32 | Train Loss = 0.0000121 \n",
      "Epoch 20: Train time = 10.32 | Train Loss = 0.0000125 \n",
      "Epoch 30: Train time = 11.51 | Train Loss = 0.0000116 \n",
      "Epoch 40: Train time = 11.33 | Train Loss = 0.0000107 \n",
      "Epoch 50: Train time = 11.38 | Train Loss = 0.0000099 \n",
      "Epoch 51: Train time = 11.39 | Train Loss = 0.0000098 \n",
      "Epoch 53: Train time = 11.39 | Train Loss = 0.0000097 \n",
      "Epoch 54: Train time = 11.41 | Train Loss = 0.0000095 \n",
      "Epoch 55: Train time = 11.35 | Train Loss = 0.0000095 \n",
      "Epoch 56: Train time = 11.25 | Train Loss = 0.0000094 \n",
      "Epoch 57: Train time = 11.40 | Train Loss = 0.0000093 \n",
      "Epoch 58: Train time = 11.23 | Train Loss = 0.0000093 \n",
      "Epoch 59: Train time = 11.34 | Train Loss = 0.0000093 \n",
      "Epoch 60: Train time = 11.27 | Train Loss = 0.0000091 \n",
      "Epoch 61: Train time = 11.21 | Train Loss = 0.0000090 \n",
      "Epoch 62: Train time = 11.03 | Train Loss = 0.0000090 \n",
      "Epoch 63: Train time = 11.19 | Train Loss = 0.0000090 \n",
      "Epoch 64: Train time = 11.20 | Train Loss = 0.0000089 \n",
      "Epoch 65: Train time = 10.56 | Train Loss = 0.0000089 \n",
      "Epoch 66: Train time = 10.45 | Train Loss = 0.0000087 \n",
      "Epoch 67: Train time = 10.38 | Train Loss = 0.0000087 \n",
      "Epoch 68: Train time = 10.32 | Train Loss = 0.0000086 \n",
      "Epoch 69: Train time = 10.40 | Train Loss = 0.0000086 \n",
      "Epoch 70: Train time = 10.46 | Train Loss = 0.0000085 \n",
      "Epoch 71: Train time = 10.31 | Train Loss = 0.0000085 \n",
      "Epoch 72: Train time = 10.22 | Train Loss = 0.0000084 \n",
      "Epoch 73: Train time = 10.34 | Train Loss = 0.0000084 \n",
      "Epoch 74: Train time = 10.24 | Train Loss = 0.0000082 \n",
      "Epoch 76: Train time = 10.36 | Train Loss = 0.0000082 \n",
      "Epoch 77: Train time = 10.58 | Train Loss = 0.0000081 \n",
      "Epoch 78: Train time = 10.43 | Train Loss = 0.0000081 \n",
      "Epoch 79: Train time = 10.34 | Train Loss = 0.0000079 \n",
      "Epoch 80: Train time = 10.19 | Train Loss = 0.0000079 \n",
      "Epoch 82: Train time = 10.31 | Train Loss = 0.0000079 \n",
      "Epoch 83: Train time = 10.29 | Train Loss = 0.0000078 \n",
      "Epoch 84: Train time = 10.43 | Train Loss = 0.0000078 \n",
      "Epoch 85: Train time = 10.29 | Train Loss = 0.0000077 \n",
      "Epoch 86: Train time = 10.33 | Train Loss = 0.0000076 \n",
      "Epoch 87: Train time = 10.26 | Train Loss = 0.0000075 \n",
      "Epoch 89: Train time = 10.24 | Train Loss = 0.0000075 \n",
      "Epoch 90: Train time = 10.30 | Train Loss = 0.0000076 \n",
      "Epoch 91: Train time = 10.25 | Train Loss = 0.0000074 \n",
      "Epoch 92: Train time = 10.29 | Train Loss = 0.0000074 \n",
      "Epoch 93: Train time = 10.29 | Train Loss = 0.0000074 \n",
      "Epoch 94: Train time = 10.23 | Train Loss = 0.0000073 \n",
      "Epoch 96: Train time = 10.29 | Train Loss = 0.0000071 \n",
      "Epoch 98: Train time = 10.25 | Train Loss = 0.0000071 \n",
      "Epoch 99: Train time = 10.26 | Train Loss = 0.0000070 \n",
      "Epoch 100: Train time = 10.42 | Train Loss = 0.0000071 \n",
      "Epoch 101: Train time = 10.29 | Train Loss = 0.0000070 \n",
      "Epoch 102: Train time = 10.40 | Train Loss = 0.0000069 \n",
      "Epoch 105: Train time = 10.34 | Train Loss = 0.0000068 \n",
      "Epoch 108: Train time = 10.31 | Train Loss = 0.0000067 \n",
      "Epoch 109: Train time = 10.29 | Train Loss = 0.0000066 \n",
      "Epoch 110: Train time = 10.35 | Train Loss = 0.0000066 \n",
      "Epoch 112: Train time = 10.26 | Train Loss = 0.0000066 \n",
      "Epoch 113: Train time = 10.22 | Train Loss = 0.0000066 \n",
      "Epoch 114: Train time = 10.55 | Train Loss = 0.0000065 \n",
      "Epoch 117: Train time = 10.27 | Train Loss = 0.0000064 \n",
      "Epoch 119: Train time = 10.16 | Train Loss = 0.0000063 \n",
      "Epoch 120: Train time = 10.54 | Train Loss = 0.0000064 \n",
      "Epoch 121: Train time = 10.71 | Train Loss = 0.0000063 \n",
      "Epoch 123: Train time = 10.45 | Train Loss = 0.0000062 \n",
      "Epoch 125: Train time = 10.32 | Train Loss = 0.0000061 \n",
      "Epoch 126: Train time = 10.29 | Train Loss = 0.0000061 \n",
      "Epoch 127: Train time = 10.34 | Train Loss = 0.0000061 \n",
      "Epoch 128: Train time = 10.22 | Train Loss = 0.0000061 \n",
      "Epoch 130: Train time = 10.22 | Train Loss = 0.0000060 \n",
      "Epoch 131: Train time = 10.19 | Train Loss = 0.0000060 \n",
      "Epoch 132: Train time = 10.55 | Train Loss = 0.0000059 \n",
      "Epoch 133: Train time = 10.36 | Train Loss = 0.0000059 \n",
      "Epoch 134: Train time = 10.48 | Train Loss = 0.0000059 \n",
      "Epoch 136: Train time = 10.29 | Train Loss = 0.0000058 \n",
      "Epoch 137: Train time = 10.34 | Train Loss = 0.0000058 \n",
      "Epoch 138: Train time = 10.26 | Train Loss = 0.0000058 \n",
      "Epoch 140: Train time = 10.40 | Train Loss = 0.0000058 \n",
      "Epoch 141: Train time = 10.29 | Train Loss = 0.0000056 \n",
      "Epoch 143: Train time = 10.30 | Train Loss = 0.0000056 \n",
      "Epoch 146: Train time = 10.33 | Train Loss = 0.0000056 \n",
      "Epoch 147: Train time = 10.31 | Train Loss = 0.0000055 \n",
      "Epoch 149: Train time = 10.32 | Train Loss = 0.0000055 \n",
      "Epoch 150: Train time = 10.28 | Train Loss = 0.0000055 \n",
      "Epoch 152: Train time = 10.33 | Train Loss = 0.0000054 \n",
      "Epoch 154: Train time = 10.32 | Train Loss = 0.0000053 \n",
      "Epoch 157: Train time = 10.37 | Train Loss = 0.0000053 \n",
      "Epoch 158: Train time = 10.55 | Train Loss = 0.0000052 \n",
      "Epoch 160: Train time = 10.33 | Train Loss = 0.0000052 \n",
      "Epoch 162: Train time = 10.36 | Train Loss = 0.0000052 \n",
      "Epoch 164: Train time = 10.35 | Train Loss = 0.0000052 \n",
      "Epoch 166: Train time = 10.33 | Train Loss = 0.0000051 \n",
      "Epoch 169: Train time = 10.70 | Train Loss = 0.0000050 \n",
      "Epoch 170: Train time = 10.38 | Train Loss = 0.0000051 \n",
      "Epoch 173: Train time = 10.24 | Train Loss = 0.0000050 \n",
      "Epoch 175: Train time = 10.27 | Train Loss = 0.0000049 \n",
      "Epoch 176: Train time = 10.26 | Train Loss = 0.0000049 \n",
      "Epoch 179: Train time = 10.36 | Train Loss = 0.0000049 \n",
      "Epoch 180: Train time = 10.38 | Train Loss = 0.0000048 \n",
      "Epoch 185: Train time = 10.41 | Train Loss = 0.0000047 \n",
      "Epoch 188: Train time = 10.26 | Train Loss = 0.0000046 \n",
      "Epoch 190: Train time = 10.39 | Train Loss = 0.0000046 \n",
      "Epoch 194: Train time = 10.34 | Train Loss = 0.0000046 \n",
      "Epoch 195: Train time = 10.17 | Train Loss = 0.0000046 \n",
      "Epoch 196: Train time = 10.21 | Train Loss = 0.0000046 \n",
      "Epoch 199: Train time = 10.22 | Train Loss = 0.0000045 \n",
      "Epoch 200: Train time = 10.29 | Train Loss = 0.0000045 \n",
      "Epoch 201: Train time = 10.24 | Train Loss = 0.0000044 \n",
      "Epoch 205: Train time = 10.29 | Train Loss = 0.0000044 \n",
      "Epoch 206: Train time = 10.30 | Train Loss = 0.0000044 \n",
      "Epoch 210: Train time = 10.34 | Train Loss = 0.0000044 \n",
      "Epoch 211: Train time = 10.39 | Train Loss = 0.0000044 \n",
      "Epoch 212: Train time = 10.52 | Train Loss = 0.0000044 \n",
      "Epoch 213: Train time = 10.49 | Train Loss = 0.0000043 \n",
      "Epoch 218: Train time = 10.47 | Train Loss = 0.0000042 \n",
      "Epoch 220: Train time = 10.43 | Train Loss = 0.0000042 \n",
      "Epoch 221: Train time = 10.38 | Train Loss = 0.0000042 \n",
      "Epoch 225: Train time = 10.32 | Train Loss = 0.0000041 \n",
      "Epoch 230: Train time = 10.48 | Train Loss = 0.0000041 \n",
      "Epoch 233: Train time = 10.31 | Train Loss = 0.0000041 \n",
      "Epoch 234: Train time = 10.21 | Train Loss = 0.0000040 \n",
      "Epoch 236: Train time = 10.50 | Train Loss = 0.0000040 \n",
      "Epoch 240: Train time = 10.30 | Train Loss = 0.0000041 \n",
      "Epoch 241: Train time = 10.25 | Train Loss = 0.0000039 \n",
      "Epoch 246: Train time = 10.33 | Train Loss = 0.0000039 \n",
      "Epoch 248: Train time = 10.52 | Train Loss = 0.0000039 \n",
      "Epoch 249: Train time = 10.27 | Train Loss = 0.0000039 \n",
      "Epoch 250: Train time = 10.80 | Train Loss = 0.0000039 \n",
      "Epoch 254: Train time = 10.38 | Train Loss = 0.0000038 \n",
      "Epoch 258: Train time = 10.28 | Train Loss = 0.0000038 \n",
      "Epoch 260: Train time = 10.29 | Train Loss = 0.0000037 \n",
      "Epoch 266: Train time = 10.30 | Train Loss = 0.0000037 \n",
      "Epoch 270: Train time = 11.31 | Train Loss = 0.0000036 \n",
      "Epoch 274: Train time = 11.25 | Train Loss = 0.0000036 \n",
      "Epoch 280: Train time = 12.32 | Train Loss = 0.0000036 \n",
      "Epoch 282: Train time = 11.91 | Train Loss = 0.0000036 \n",
      "Epoch 283: Train time = 11.43 | Train Loss = 0.0000036 \n",
      "Epoch 284: Train time = 11.69 | Train Loss = 0.0000035 \n",
      "Epoch 288: Train time = 12.77 | Train Loss = 0.0000035 \n",
      "Epoch 290: Train time = 11.38 | Train Loss = 0.0000036 \n",
      "Epoch 297: Train time = 11.44 | Train Loss = 0.0000034 \n",
      "Epoch 300: Train time = 11.61 | Train Loss = 0.0000035 \n",
      "Best Training MSE: 0.0000034\n",
      "IMPROVED VALIDATION MSE\n",
      "\n",
      "Total time: 3186.50\n",
      "Complete. Time taken: 3266.58s\n",
      "10.00% done\n",
      "20.00% done\n",
      "30.00% done\n",
      "40.00% done\n",
      "50.00% done\n",
      "60.00% done\n",
      "70.00% done\n",
      "80.00% done\n",
      "90.00% done\n",
      "100.00% done\n",
      "Testing complete. Time taken: 166.74\n"
     ]
    }
   ],
   "source": [
    "run_seed(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99791ee8-6d4d-49a2-99b5-48d06755a32d",
   "metadata": {},
   "source": [
    "## 4.4 Seed 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6398e9f5-b404-4029-8d31-e839467929d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W generated. Time taken: 20.28s\n",
      "Calculating eigenvalue\n",
      "Eigenvalue calculated. Time taken: 3.46s\n",
      "W and W_in generated. Time taken: 26.74s\n",
      "\n",
      "Generating z values...\n",
      "z values generated. Time taken: 43.49s\n",
      "Concatenating z with z**2 Contenation complete. Time taken: 11.24s\n",
      "\n",
      "Epoch 10: Train time = 10.67 | Train Loss = 0.0000117 \n",
      "Epoch 20: Train time = 10.80 | Train Loss = 0.0000125 \n",
      "Epoch 30: Train time = 11.16 | Train Loss = 0.0000117 \n",
      "Epoch 40: Train time = 11.51 | Train Loss = 0.0000107 \n",
      "Epoch 50: Train time = 11.74 | Train Loss = 0.0000099 \n",
      "Epoch 51: Train time = 12.46 | Train Loss = 0.0000098 \n",
      "Epoch 52: Train time = 11.41 | Train Loss = 0.0000097 \n",
      "Epoch 54: Train time = 11.43 | Train Loss = 0.0000095 \n",
      "Epoch 55: Train time = 13.11 | Train Loss = 0.0000095 \n",
      "Epoch 56: Train time = 11.96 | Train Loss = 0.0000095 \n",
      "Epoch 57: Train time = 12.17 | Train Loss = 0.0000094 \n",
      "Epoch 58: Train time = 11.42 | Train Loss = 0.0000093 \n",
      "Epoch 59: Train time = 11.81 | Train Loss = 0.0000092 \n",
      "Epoch 60: Train time = 11.95 | Train Loss = 0.0000092 \n",
      "Epoch 61: Train time = 12.00 | Train Loss = 0.0000091 \n",
      "Epoch 62: Train time = 11.38 | Train Loss = 0.0000091 \n",
      "Epoch 63: Train time = 10.57 | Train Loss = 0.0000089 \n",
      "Epoch 64: Train time = 10.37 | Train Loss = 0.0000089 \n",
      "Epoch 65: Train time = 10.23 | Train Loss = 0.0000088 \n",
      "Epoch 66: Train time = 12.18 | Train Loss = 0.0000087 \n",
      "Epoch 67: Train time = 10.42 | Train Loss = 0.0000087 \n",
      "Epoch 68: Train time = 10.19 | Train Loss = 0.0000087 \n",
      "Epoch 70: Train time = 13.31 | Train Loss = 0.0000085 \n",
      "Epoch 71: Train time = 12.48 | Train Loss = 0.0000084 \n",
      "Epoch 73: Train time = 11.65 | Train Loss = 0.0000083 \n",
      "Epoch 75: Train time = 11.71 | Train Loss = 0.0000082 \n",
      "Epoch 76: Train time = 11.43 | Train Loss = 0.0000082 \n",
      "Epoch 78: Train time = 12.19 | Train Loss = 0.0000081 \n",
      "Epoch 79: Train time = 12.35 | Train Loss = 0.0000080 \n",
      "Epoch 80: Train time = 13.40 | Train Loss = 0.0000080 \n",
      "Epoch 81: Train time = 12.18 | Train Loss = 0.0000079 \n",
      "Epoch 82: Train time = 11.21 | Train Loss = 0.0000079 \n",
      "Epoch 83: Train time = 11.04 | Train Loss = 0.0000078 \n",
      "Epoch 84: Train time = 10.55 | Train Loss = 0.0000078 \n",
      "Epoch 85: Train time = 12.08 | Train Loss = 0.0000077 \n",
      "Epoch 86: Train time = 11.38 | Train Loss = 0.0000077 \n",
      "Epoch 87: Train time = 11.39 | Train Loss = 0.0000076 \n",
      "Epoch 88: Train time = 11.88 | Train Loss = 0.0000075 \n",
      "Epoch 89: Train time = 11.91 | Train Loss = 0.0000075 \n",
      "Epoch 90: Train time = 11.19 | Train Loss = 0.0000074 \n",
      "Epoch 92: Train time = 11.16 | Train Loss = 0.0000074 \n",
      "Epoch 93: Train time = 11.41 | Train Loss = 0.0000074 \n",
      "Epoch 94: Train time = 11.48 | Train Loss = 0.0000073 \n",
      "Epoch 95: Train time = 10.14 | Train Loss = 0.0000073 \n",
      "Epoch 96: Train time = 10.50 | Train Loss = 0.0000072 \n",
      "Epoch 97: Train time = 10.44 | Train Loss = 0.0000072 \n",
      "Epoch 98: Train time = 10.49 | Train Loss = 0.0000071 \n",
      "Epoch 99: Train time = 11.72 | Train Loss = 0.0000071 \n",
      "Epoch 100: Train time = 11.73 | Train Loss = 0.0000070 \n",
      "Epoch 101: Train time = 11.82 | Train Loss = 0.0000070 \n",
      "Epoch 102: Train time = 11.79 | Train Loss = 0.0000070 \n",
      "Epoch 103: Train time = 11.82 | Train Loss = 0.0000070 \n",
      "Epoch 104: Train time = 11.32 | Train Loss = 0.0000069 \n",
      "Epoch 105: Train time = 10.49 | Train Loss = 0.0000069 \n",
      "Epoch 106: Train time = 10.52 | Train Loss = 0.0000068 \n",
      "Epoch 107: Train time = 9.86 | Train Loss = 0.0000068 \n",
      "Epoch 109: Train time = 10.10 | Train Loss = 0.0000067 \n",
      "Epoch 110: Train time = 12.05 | Train Loss = 0.0000066 \n",
      "Epoch 113: Train time = 10.17 | Train Loss = 0.0000065 \n",
      "Epoch 114: Train time = 10.24 | Train Loss = 0.0000065 \n",
      "Epoch 116: Train time = 12.20 | Train Loss = 0.0000064 \n",
      "Epoch 118: Train time = 12.17 | Train Loss = 0.0000064 \n",
      "Epoch 119: Train time = 11.04 | Train Loss = 0.0000063 \n",
      "Epoch 120: Train time = 11.91 | Train Loss = 0.0000063 \n",
      "Epoch 122: Train time = 11.41 | Train Loss = 0.0000063 \n",
      "Epoch 123: Train time = 11.48 | Train Loss = 0.0000062 \n",
      "Epoch 125: Train time = 13.08 | Train Loss = 0.0000061 \n",
      "Epoch 129: Train time = 10.04 | Train Loss = 0.0000060 \n",
      "Epoch 130: Train time = 11.06 | Train Loss = 0.0000060 \n",
      "Epoch 131: Train time = 11.99 | Train Loss = 0.0000059 \n",
      "Epoch 133: Train time = 11.37 | Train Loss = 0.0000059 \n",
      "Epoch 135: Train time = 10.90 | Train Loss = 0.0000058 \n",
      "Epoch 136: Train time = 11.12 | Train Loss = 0.0000058 \n",
      "Epoch 137: Train time = 11.45 | Train Loss = 0.0000058 \n",
      "Epoch 138: Train time = 11.42 | Train Loss = 0.0000058 \n",
      "Epoch 139: Train time = 11.31 | Train Loss = 0.0000057 \n",
      "Epoch 140: Train time = 10.69 | Train Loss = 0.0000058 \n",
      "Epoch 141: Train time = 10.58 | Train Loss = 0.0000057 \n",
      "Epoch 143: Train time = 11.12 | Train Loss = 0.0000056 \n",
      "Epoch 144: Train time = 12.18 | Train Loss = 0.0000056 \n",
      "Epoch 145: Train time = 11.21 | Train Loss = 0.0000056 \n",
      "Epoch 147: Train time = 12.22 | Train Loss = 0.0000055 \n",
      "Epoch 149: Train time = 12.52 | Train Loss = 0.0000055 \n",
      "Epoch 150: Train time = 11.67 | Train Loss = 0.0000055 \n",
      "Epoch 151: Train time = 12.06 | Train Loss = 0.0000054 \n",
      "Epoch 153: Train time = 10.99 | Train Loss = 0.0000054 \n",
      "Epoch 155: Train time = 11.17 | Train Loss = 0.0000054 \n",
      "Epoch 156: Train time = 11.48 | Train Loss = 0.0000053 \n",
      "Epoch 157: Train time = 11.32 | Train Loss = 0.0000053 \n",
      "Epoch 158: Train time = 11.43 | Train Loss = 0.0000053 \n",
      "Epoch 159: Train time = 11.04 | Train Loss = 0.0000052 \n",
      "Epoch 160: Train time = 11.84 | Train Loss = 0.0000053 \n",
      "Epoch 161: Train time = 12.01 | Train Loss = 0.0000052 \n",
      "Epoch 164: Train time = 10.25 | Train Loss = 0.0000052 \n",
      "Epoch 165: Train time = 10.17 | Train Loss = 0.0000051 \n",
      "Epoch 166: Train time = 10.87 | Train Loss = 0.0000051 \n",
      "Epoch 167: Train time = 10.59 | Train Loss = 0.0000050 \n",
      "Epoch 170: Train time = 10.15 | Train Loss = 0.0000051 \n",
      "Epoch 172: Train time = 10.05 | Train Loss = 0.0000050 \n",
      "Epoch 173: Train time = 10.15 | Train Loss = 0.0000049 \n",
      "Epoch 175: Train time = 10.58 | Train Loss = 0.0000049 \n",
      "Epoch 176: Train time = 11.01 | Train Loss = 0.0000049 \n",
      "Epoch 177: Train time = 10.20 | Train Loss = 0.0000049 \n",
      "Epoch 179: Train time = 10.73 | Train Loss = 0.0000049 \n",
      "Epoch 180: Train time = 11.51 | Train Loss = 0.0000048 \n",
      "Epoch 184: Train time = 12.02 | Train Loss = 0.0000047 \n",
      "Epoch 190: Train time = 13.28 | Train Loss = 0.0000047 \n",
      "Epoch 191: Train time = 10.49 | Train Loss = 0.0000046 \n",
      "Epoch 194: Train time = 10.05 | Train Loss = 0.0000046 \n",
      "Epoch 196: Train time = 9.95 | Train Loss = 0.0000045 \n",
      "Epoch 197: Train time = 10.84 | Train Loss = 0.0000045 \n",
      "Epoch 200: Train time = 12.52 | Train Loss = 0.0000045 \n",
      "Epoch 201: Train time = 11.94 | Train Loss = 0.0000045 \n",
      "Epoch 203: Train time = 11.19 | Train Loss = 0.0000044 \n",
      "Epoch 205: Train time = 11.11 | Train Loss = 0.0000044 \n",
      "Epoch 209: Train time = 13.13 | Train Loss = 0.0000043 \n",
      "Epoch 210: Train time = 10.77 | Train Loss = 0.0000044 \n",
      "Epoch 212: Train time = 10.32 | Train Loss = 0.0000043 \n",
      "Epoch 213: Train time = 10.20 | Train Loss = 0.0000043 \n",
      "Epoch 219: Train time = 10.47 | Train Loss = 0.0000042 \n",
      "Epoch 220: Train time = 10.05 | Train Loss = 0.0000042 \n",
      "Epoch 221: Train time = 11.20 | Train Loss = 0.0000042 \n",
      "Epoch 223: Train time = 11.68 | Train Loss = 0.0000041 \n",
      "Epoch 230: Train time = 11.53 | Train Loss = 0.0000040 \n",
      "Epoch 235: Train time = 10.76 | Train Loss = 0.0000040 \n",
      "Epoch 236: Train time = 10.95 | Train Loss = 0.0000040 \n",
      "Epoch 238: Train time = 10.99 | Train Loss = 0.0000040 \n",
      "Epoch 240: Train time = 11.31 | Train Loss = 0.0000040 \n",
      "Epoch 243: Train time = 11.65 | Train Loss = 0.0000039 \n",
      "Epoch 246: Train time = 9.92 | Train Loss = 0.0000038 \n",
      "Epoch 250: Train time = 11.08 | Train Loss = 0.0000038 \n",
      "Epoch 256: Train time = 12.00 | Train Loss = 0.0000038 \n",
      "Epoch 258: Train time = 10.64 | Train Loss = 0.0000038 \n",
      "Epoch 260: Train time = 11.94 | Train Loss = 0.0000037 \n",
      "Epoch 263: Train time = 11.80 | Train Loss = 0.0000037 \n",
      "Epoch 265: Train time = 11.32 | Train Loss = 0.0000037 \n",
      "Epoch 267: Train time = 11.47 | Train Loss = 0.0000037 \n",
      "Epoch 270: Train time = 10.99 | Train Loss = 0.0000037 \n",
      "Epoch 271: Train time = 10.72 | Train Loss = 0.0000036 \n",
      "Epoch 279: Train time = 10.84 | Train Loss = 0.0000035 \n",
      "Epoch 280: Train time = 11.81 | Train Loss = 0.0000036 \n",
      "Epoch 285: Train time = 11.10 | Train Loss = 0.0000035 \n",
      "Epoch 289: Train time = 10.12 | Train Loss = 0.0000035 \n",
      "Epoch 290: Train time = 9.99 | Train Loss = 0.0000035 \n",
      "Epoch 293: Train time = 12.19 | Train Loss = 0.0000034 \n",
      "Epoch 300: Train time = 12.12 | Train Loss = 0.0000034 \n",
      "Best Training MSE: 0.0000034\n",
      "IMPROVED VALIDATION MSE\n",
      "\n",
      "Total time: 3372.25\n",
      "Complete. Time taken: 3454.24s\n",
      "10.00% done\n",
      "20.00% done\n",
      "30.00% done\n",
      "40.00% done\n",
      "50.00% done\n",
      "60.00% done\n",
      "70.00% done\n",
      "80.00% done\n",
      "90.00% done\n",
      "100.00% done\n",
      "Testing complete. Time taken: 168.13\n"
     ]
    }
   ],
   "source": [
    "run_seed(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44cb3d9-6d9b-4bc9-bfae-2f56f7a8848b",
   "metadata": {},
   "source": [
    "## 4.5 Seed 42\n",
    "Done in original prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "436ad033-e6d1-45ef-b5af-dc01acc59176",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W generated. Time taken: 23.49s\n",
      "Calculating eigenvalue\n",
      "Eigenvalue calculated. Time taken: 2.70s\n",
      "W and W_in generated. Time taken: 29.42s\n",
      "\n",
      "Generating z values...\n",
      "z values generated. Time taken: 51.86s\n",
      "Concatenating z with z**2 Contenation complete. Time taken: 157.77s\n",
      "\n",
      "Epoch 10: Train time = 16.58 | Train Loss = 0.0000119 \n",
      "Epoch 20: Train time = 15.82 | Train Loss = 0.0000125 \n",
      "Epoch 30: Train time = 14.82 | Train Loss = 0.0000117 \n",
      "Epoch 40: Train time = 16.09 | Train Loss = 0.0000107 \n",
      "Epoch 50: Train time = 14.65 | Train Loss = 0.0000099 \n",
      "Epoch 51: Train time = 16.30 | Train Loss = 0.0000098 \n",
      "Epoch 52: Train time = 14.97 | Train Loss = 0.0000098 \n",
      "Epoch 53: Train time = 16.32 | Train Loss = 0.0000097 \n",
      "Epoch 54: Train time = 14.93 | Train Loss = 0.0000095 \n",
      "Epoch 55: Train time = 15.66 | Train Loss = 0.0000094 \n",
      "Epoch 57: Train time = 14.37 | Train Loss = 0.0000094 \n",
      "Epoch 58: Train time = 13.40 | Train Loss = 0.0000093 \n",
      "Epoch 59: Train time = 12.19 | Train Loss = 0.0000092 \n",
      "Epoch 60: Train time = 13.59 | Train Loss = 0.0000091 \n",
      "Epoch 61: Train time = 12.42 | Train Loss = 0.0000091 \n",
      "Epoch 62: Train time = 12.75 | Train Loss = 0.0000091 \n",
      "Epoch 63: Train time = 13.45 | Train Loss = 0.0000089 \n",
      "Epoch 64: Train time = 11.95 | Train Loss = 0.0000089 \n",
      "Epoch 65: Train time = 13.83 | Train Loss = 0.0000088 \n",
      "Epoch 66: Train time = 12.51 | Train Loss = 0.0000088 \n",
      "Epoch 68: Train time = 13.98 | Train Loss = 0.0000086 \n",
      "Epoch 70: Train time = 13.71 | Train Loss = 0.0000085 \n",
      "Epoch 71: Train time = 12.80 | Train Loss = 0.0000085 \n",
      "Epoch 72: Train time = 12.72 | Train Loss = 0.0000084 \n",
      "Epoch 73: Train time = 13.81 | Train Loss = 0.0000084 \n",
      "Epoch 74: Train time = 11.37 | Train Loss = 0.0000083 \n",
      "Epoch 75: Train time = 13.30 | Train Loss = 0.0000082 \n",
      "Epoch 77: Train time = 12.43 | Train Loss = 0.0000081 \n",
      "Epoch 78: Train time = 13.23 | Train Loss = 0.0000080 \n",
      "Epoch 79: Train time = 12.29 | Train Loss = 0.0000080 \n",
      "Epoch 80: Train time = 12.90 | Train Loss = 0.0000080 \n",
      "Epoch 81: Train time = 13.37 | Train Loss = 0.0000079 \n",
      "Epoch 82: Train time = 12.18 | Train Loss = 0.0000079 \n",
      "Epoch 83: Train time = 13.90 | Train Loss = 0.0000078 \n",
      "Epoch 84: Train time = 13.31 | Train Loss = 0.0000078 \n",
      "Epoch 86: Train time = 14.14 | Train Loss = 0.0000076 \n",
      "Epoch 87: Train time = 12.46 | Train Loss = 0.0000076 \n",
      "Epoch 88: Train time = 13.70 | Train Loss = 0.0000076 \n",
      "Epoch 89: Train time = 13.23 | Train Loss = 0.0000075 \n",
      "Epoch 90: Train time = 12.44 | Train Loss = 0.0000075 \n",
      "Epoch 91: Train time = 14.22 | Train Loss = 0.0000074 \n",
      "Epoch 92: Train time = 12.89 | Train Loss = 0.0000073 \n",
      "Epoch 94: Train time = 14.01 | Train Loss = 0.0000073 \n",
      "Epoch 96: Train time = 14.16 | Train Loss = 0.0000072 \n",
      "Epoch 98: Train time = 13.32 | Train Loss = 0.0000070 \n",
      "Epoch 100: Train time = 12.59 | Train Loss = 0.0000070 \n",
      "Epoch 102: Train time = 12.60 | Train Loss = 0.0000069 \n",
      "Epoch 103: Train time = 13.14 | Train Loss = 0.0000069 \n",
      "Epoch 104: Train time = 13.85 | Train Loss = 0.0000069 \n",
      "Epoch 105: Train time = 12.22 | Train Loss = 0.0000069 \n",
      "Epoch 106: Train time = 13.72 | Train Loss = 0.0000068 \n",
      "Epoch 107: Train time = 13.55 | Train Loss = 0.0000068 \n",
      "Epoch 108: Train time = 11.89 | Train Loss = 0.0000067 \n",
      "Epoch 110: Train time = 12.46 | Train Loss = 0.0000067 \n",
      "Epoch 111: Train time = 13.54 | Train Loss = 0.0000066 \n",
      "Epoch 113: Train time = 12.00 | Train Loss = 0.0000065 \n",
      "Epoch 115: Train time = 12.83 | Train Loss = 0.0000065 \n",
      "Epoch 117: Train time = 13.98 | Train Loss = 0.0000064 \n",
      "Epoch 118: Train time = 12.55 | Train Loss = 0.0000063 \n",
      "Epoch 120: Train time = 12.91 | Train Loss = 0.0000064 \n",
      "Epoch 121: Train time = 14.04 | Train Loss = 0.0000063 \n",
      "Epoch 122: Train time = 14.03 | Train Loss = 0.0000063 \n",
      "Epoch 123: Train time = 12.70 | Train Loss = 0.0000061 \n",
      "Epoch 128: Train time = 12.04 | Train Loss = 0.0000060 \n",
      "Epoch 129: Train time = 13.72 | Train Loss = 0.0000060 \n",
      "Epoch 130: Train time = 12.69 | Train Loss = 0.0000060 \n",
      "Epoch 131: Train time = 13.16 | Train Loss = 0.0000060 \n",
      "Epoch 132: Train time = 13.97 | Train Loss = 0.0000059 \n",
      "Epoch 134: Train time = 13.69 | Train Loss = 0.0000058 \n",
      "Epoch 137: Train time = 13.76 | Train Loss = 0.0000058 \n",
      "Epoch 138: Train time = 12.08 | Train Loss = 0.0000058 \n",
      "Epoch 139: Train time = 13.24 | Train Loss = 0.0000057 \n",
      "Epoch 140: Train time = 13.16 | Train Loss = 0.0000058 \n",
      "Epoch 141: Train time = 12.03 | Train Loss = 0.0000057 \n",
      "Epoch 143: Train time = 12.63 | Train Loss = 0.0000057 \n",
      "Epoch 144: Train time = 12.17 | Train Loss = 0.0000056 \n",
      "Epoch 145: Train time = 13.54 | Train Loss = 0.0000056 \n",
      "Epoch 146: Train time = 12.17 | Train Loss = 0.0000056 \n",
      "Epoch 147: Train time = 12.52 | Train Loss = 0.0000055 \n",
      "Epoch 149: Train time = 11.32 | Train Loss = 0.0000054 \n",
      "Epoch 150: Train time = 13.46 | Train Loss = 0.0000055 \n",
      "Epoch 153: Train time = 13.95 | Train Loss = 0.0000054 \n",
      "Epoch 154: Train time = 12.35 | Train Loss = 0.0000053 \n",
      "Epoch 156: Train time = 13.15 | Train Loss = 0.0000053 \n",
      "Epoch 159: Train time = 12.28 | Train Loss = 0.0000053 \n",
      "Epoch 160: Train time = 13.08 | Train Loss = 0.0000052 \n",
      "Epoch 161: Train time = 13.45 | Train Loss = 0.0000052 \n",
      "Epoch 163: Train time = 13.44 | Train Loss = 0.0000052 \n",
      "Epoch 165: Train time = 12.71 | Train Loss = 0.0000051 \n",
      "Epoch 166: Train time = 14.15 | Train Loss = 0.0000051 \n",
      "Epoch 169: Train time = 14.16 | Train Loss = 0.0000050 \n",
      "Epoch 170: Train time = 14.48 | Train Loss = 0.0000050 \n",
      "Epoch 172: Train time = 14.69 | Train Loss = 0.0000050 \n",
      "Epoch 173: Train time = 15.51 | Train Loss = 0.0000049 \n",
      "Epoch 176: Train time = 14.28 | Train Loss = 0.0000049 \n",
      "Epoch 177: Train time = 15.56 | Train Loss = 0.0000049 \n",
      "Epoch 179: Train time = 14.83 | Train Loss = 0.0000049 \n",
      "Epoch 180: Train time = 14.52 | Train Loss = 0.0000050 \n",
      "Epoch 181: Train time = 14.85 | Train Loss = 0.0000048 \n",
      "Epoch 183: Train time = 14.10 | Train Loss = 0.0000047 \n",
      "Epoch 187: Train time = 13.33 | Train Loss = 0.0000047 \n",
      "Epoch 190: Train time = 12.60 | Train Loss = 0.0000047 \n",
      "Epoch 192: Train time = 12.38 | Train Loss = 0.0000046 \n",
      "Epoch 195: Train time = 13.50 | Train Loss = 0.0000045 \n",
      "Epoch 199: Train time = 13.26 | Train Loss = 0.0000045 \n",
      "Epoch 200: Train time = 13.97 | Train Loss = 0.0000045 \n",
      "Epoch 201: Train time = 13.71 | Train Loss = 0.0000045 \n",
      "Epoch 202: Train time = 11.91 | Train Loss = 0.0000044 \n",
      "Epoch 204: Train time = 12.38 | Train Loss = 0.0000044 \n",
      "Epoch 207: Train time = 12.96 | Train Loss = 0.0000044 \n",
      "Epoch 208: Train time = 14.15 | Train Loss = 0.0000044 \n",
      "Epoch 210: Train time = 14.00 | Train Loss = 0.0000043 \n",
      "Epoch 214: Train time = 12.85 | Train Loss = 0.0000042 \n",
      "Epoch 220: Train time = 14.25 | Train Loss = 0.0000042 \n",
      "Epoch 224: Train time = 12.88 | Train Loss = 0.0000041 \n",
      "Epoch 226: Train time = 13.16 | Train Loss = 0.0000041 \n",
      "Epoch 229: Train time = 12.92 | Train Loss = 0.0000041 \n",
      "Epoch 230: Train time = 14.40 | Train Loss = 0.0000043 \n",
      "Epoch 234: Train time = 13.10 | Train Loss = 0.0000040 \n",
      "Epoch 236: Train time = 12.89 | Train Loss = 0.0000040 \n",
      "Epoch 238: Train time = 13.50 | Train Loss = 0.0000040 \n",
      "Epoch 240: Train time = 14.11 | Train Loss = 0.0000040 \n",
      "Epoch 242: Train time = 14.12 | Train Loss = 0.0000040 \n",
      "Epoch 244: Train time = 13.42 | Train Loss = 0.0000039 \n",
      "Epoch 247: Train time = 13.70 | Train Loss = 0.0000039 \n",
      "Epoch 250: Train time = 12.97 | Train Loss = 0.0000039 \n",
      "Epoch 251: Train time = 12.26 | Train Loss = 0.0000038 \n",
      "Epoch 256: Train time = 12.72 | Train Loss = 0.0000038 \n",
      "Epoch 257: Train time = 13.65 | Train Loss = 0.0000038 \n",
      "Epoch 258: Train time = 12.74 | Train Loss = 0.0000038 \n",
      "Epoch 260: Train time = 13.88 | Train Loss = 0.0000038 \n",
      "Epoch 263: Train time = 13.06 | Train Loss = 0.0000037 \n",
      "Epoch 267: Train time = 14.15 | Train Loss = 0.0000037 \n",
      "Epoch 270: Train time = 14.01 | Train Loss = 0.0000036 \n",
      "Epoch 278: Train time = 12.73 | Train Loss = 0.0000036 \n",
      "Epoch 280: Train time = 13.42 | Train Loss = 0.0000036 \n",
      "Epoch 282: Train time = 14.16 | Train Loss = 0.0000035 \n",
      "Epoch 289: Train time = 14.94 | Train Loss = 0.0000035 \n",
      "Epoch 290: Train time = 13.84 | Train Loss = 0.0000036 \n",
      "Epoch 293: Train time = 47.87 | Train Loss = 0.0000034 \n",
      "Epoch 300: Train time = 14.24 | Train Loss = 0.0000034 \n",
      "Best Training MSE: 0.0000034\n",
      "IMPROVED VALIDATION MSE\n",
      "\n",
      "Total time: 4194.20\n",
      "Complete. Time taken: 4435.08s\n",
      "10.00% done\n",
      "20.00% done\n",
      "30.00% done\n",
      "40.00% done\n",
      "50.00% done\n",
      "60.00% done\n",
      "70.00% done\n",
      "80.00% done\n",
      "90.00% done\n",
      "100.00% done\n",
      "Testing complete. Time taken: 171.60\n"
     ]
    }
   ],
   "source": [
    "run_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4863a62c-1ca7-4b49-8f7e-a92172717083",
   "metadata": {},
   "source": [
    "## 4.6 Compilation of means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ec57f9e-b336-4d06-9ff8-2506df6e2b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_preds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "accdff42-1bee-4c5c-b1aa-430274d9fea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirpath, dirnames, filenames in os.walk(res_folder):\n",
    "    for f in filenames:\n",
    "        mu_preds.append(load_obj(os.path.join(res_folder, f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e738442a-17a4-43fa-a359-e4f12601dcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_preds = np.array(mu_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a860c22e-0577-40da-95b4-a44b46845243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean preds shape: (5, 100, 400, 40)\n"
     ]
    }
   ],
   "source": [
    "print(f\"mean preds shape: {mu_preds.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6622806d-4d17-4d9a-abf0-0253f0a0446d",
   "metadata": {},
   "source": [
    "# 5. Analyze results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fff9919-57f9-4dfc-84f5-df7bdbb432ad",
   "metadata": {},
   "source": [
    "## 5.1 MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "530f5e3f-7972-41d4-bd82-923c484dec2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture_pred_all_mean = mu_preds.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7908deac-a4c9-404c-a7f4-465a345d2b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It takes around 2.02 Lyapunov Time for mean error to exceed 0.5\n",
      "\n",
      "Median NRMSE at 0.5 Lyapunov Time: 0.069\n",
      "Median NRMSE at 1.0 Lyapunov Time: 0.159\n",
      "Median NRMSE at 2.0 Lyapunov Time: 0.497\n",
      "Median NRMSE at 5.0 Lyapunov Time: 0.977\n"
     ]
    }
   ],
   "source": [
    "res_single = PointExperimentResultLyapunov(mixture_pred_all_mean - y_test, \"lorenz\")\n",
    "res_single.plot_rmse(save_name = \"RC Deep Ensemble Horizon\")\n",
    "print()\n",
    "res_single.get_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c6be55-7e0f-459e-8f65-dcf863bf84c9",
   "metadata": {},
   "source": [
    "## 5.2 Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cb6451-b9fe-4a03-8e97-01bb0bc77cf6",
   "metadata": {},
   "source": [
    "**Visualise for one dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "667fc9e7-266c-416c-9a04-5f052ee4e97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06d946c3-ca53-4dee-80e9-69c4c0e52675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(L_forecast_test) / LORENZ_LT * 0.01, mu_preds.var(axis = 0)[idx].mean(axis = 1))\n",
    "plt.grid(\"on\")\n",
    "plt.xlabel(\"Lyapunov Time\")\n",
    "plt.ylabel(\"Variance\")\n",
    "plt.savefig(\"RC Deep Ensemble Variance.png\", facecolor = \"white\", bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95781e2b-0ea5-4745-8a62-21f9d08a1e53",
   "metadata": {},
   "source": [
    "## 5.3 Negative Log LH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6008d350-7c3e-4a2c-8e34-8600950d519f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_log_LH(mean_pred, sd_pred):\n",
    "    d = 40\n",
    "    \n",
    "    constant_loss = d * np.log(2 * np.pi)\n",
    "    mu_loss = (mean_pred - y_test)**2\n",
    "    \n",
    "    return 0.5 * (constant_loss + d * np.log(sd_pred) + (mu_loss / sd_pred**2)).mean(axis = (0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b974d6f8-a9d0-4be1-9bd2-5052d44e2b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_dev = mu_preds.std(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3682d95-1258-4e76-919d-e16c0ecafd29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEGCAYAAACO8lkDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAnVUlEQVR4nO3deXxcdb3/8dcne5o0Tdd0SaAFWjZbWlrKptwWEFAQVLjaK3gRkaI/rvuKqBfuvbigF/RxXRFQAbWCrCq7EhCx0BZKSxdoaUu3pHuzT5KZ+fz+mAmkTdJOk0zOnMz7+XjkkZk5M3PeySM5n/ku53vM3REREeksJ+gAIiKSeVQcRESkCxUHERHpQsVBRES6UHEQEZEu8oIO0B9GjRrlEydO7PXrm5qaKCkp6b9AAySsuSG82cOaG8KbPay5IfOzL1myZKe7j+5u26AoDhMnTmTx4sW9fn11dTVz5szpv0ADJKy5IbzZw5obwps9rLkh87Ob2Zs9bVO3koiIdKHiICIiXag4iIhIFyoOIiLShYqDiIh0oeIgIiJdqDiIiEgXg+I8BxGRTBaNxYnGnRwzcgzMjPZYnPZYnLZonPaY0x6L09QWpSESpb6lnYZIlPZYnNZonD1NbeTkGCUFuRTk5RKLJ94vFncmjSrhrGMr+j2zioOIDGqt0RhPr97Bkyu3EY3HGVtWxBGjSxg+pIDigtzkQTpxcI7GnLbkQTsac1qjMfY2t7O3pZ29zW3sbW4nN8eYUF6MGbRG4zS3xqiPtFMfSRzQC/NyKMrPpT3m7KlvpvXZJ9jT3J62n++CaeNUHERE3J0dDa1s2NXM1r0tbG+I0BCJ0tgapTESZU9zG7ua2tjd1MbuxjYaWqMAjCgpYGhRHjV7I7TF4invLy/HKB+ST/mQAsqL82mPxVlVU4+ZUZCbQ2lhHmXFeVQMLeKIUXm0ReNEojHycnIoiTdxzKRxjCwppCAv0Ysfjztxh/y8xOvz3/oyhhQk3mtoUT5Di/IoyM2hIC+H8iH5uENTa5T2mJOXa+TlGLk5Rn5uekYHVBxEJK3cncbWKK3ROPG4E407rdE4LW0xItEYkbYYja1vH9T3NL19cG+IRGmsb+GXaxdS3xJlV2MrO5vaaIvue3A3g5KCPEoKcxk+pICRpQVUDi9nZEkBI0sKOH5CGWdMHk1ebg6R9hg7G1vZ09ROJBp768BckJtDXqfb+bk55OflUFKQi5n16mdPLJ8xtT9+jQAU5ef223sdjIqDiPRKc1uUXY1t7GhsZXt9a/JTfCs7G1sTB/HGth4P5gdSlJ/DyJJChpfkM6w4nyaDSHucESUFTKkYyqihBVSWF3PYyBImlBczpqyQ0oI8cnJSO4AX5edSOXwIlcN7+5NnBxUHEQESB/vaugi19RFq6yKJT9fN7YlP+O0xdje1sTN50N/Z2EpzW6zLe+TnGqNKCxlZWsCo0sLEwbw08Um+KD+X3Bwj14zC/ByK83Mpys+lOD+XIQV5DC/JZ2RJIcUF+346Tnz6Pm2gfg2SpOIgMoi5O3ua29m0u5kXa6L89cFXWfzmHkaWFOA4Ta2JLp1t9Yl++/3l5RjFBYmD+Ihkd830qnJGlRYyamiiAIwuLWRUaSEThhczfEh+r7tgJLOoOIiEWGNrlGde28GqmnoqhxfT2Bply94WNu1uYfOeZjbtbqap0yf8wrxNzJ40grqWdvJzcxhalMe4YUWcfuRIKoYVMbasiLHJ76OHFlJamKeDfZZScRAJiVjc2bCridU1DSzfUsfCdbtYvqWOWNz3ed6Qglyqhg+hakQxpxwxkqoRQ6gaXsy2dSu5+NwzGFKgf3s5OP2ViGQQd6e2PsLq2gZWbq1n+eY6tjdE2NHYyrb61rcGdvNyjBOqyvnUvxzJaUeOZFpVOfUt7ZQkp0J292m/esdqFQZJmf5SRAJU19LOovW7WbhuF8u21PFabQN1LW+fMDVpVAnjy4s48bDhVJQVMXlMKceOK+OoMaVdpjWWFurfWfqP/ppEBoi7s62+lVe31PHC+l0sXLebFVvriDsU5OUwdcIwzp82jmPGDuXoiqEcM7aMYUPyg44tWUrFQSQNYnFn/c4mVmytY2VNPSu3Jr52NbUBUJCbw4zDyvnMWZM55YiRTK8qH9ATnEQORsVBpJdicaelPUZtXSQxM2hPC6/V1rNiaz2raxpoaU/MEirIzWHK2FLOOnYMx48fxnHjy5g6YZiKgWQ0FQeRFLXH4jy/NcotP/kHq2vqae3mrN+hRXkcN66MebOrOH78MI4fX8aRo0vfWldHJCxUHER6EI87a3c0suTNPSxav5u/vbadvc3tTKnI599PPZzSwnyK8nOoKCuicngxE4YXM7asSOcFyKCg4iCSFI87z7y+g+rXtrOqpoFVtfVvnTU8oqSAM48ew2G2k89cckbK6/iIhJWKg2S9mroW/vxKDfe9tJnVtQ2UFORyzLgyLpo+nulVw5l5+HAmjhyCmVFdXa3CIFlBxUGy0q7GVh55tZY/Ld3Kixt2AzCtchg3f+gELpg2XmMEkvUCKw5mVgXcCYwF4sCt7v4jMxsB/AGYCGwAPuTue4LKKYNHc1uUx16t5aGlW3lu7U5icWfymFK++O4pvO+E8UwcVRJ0RJGMEWTLIQp80d1fMrOhwBIzexL4GPBXd/+umX0N+Brw1QBzSojF486LG3Zz35LNPLK8hqa2GJXDi5l/xhFceMJ4jhk7VAPIIt0IrDi4ew1Qk7zdYGargAnARcCc5NN+A1Sj4iCH6LXaBh5cuoWHXt7C1roIpYV5XDBtPBfPrOSkicNVEEQOwtz94M9KdwizicCzwDuAje5e3mnbHnfvcs0mM5sPzAeoqKiYuWDBgl7vv7GxkdLS0l6/PihhzQ3pyb4nEmdhTYznt0bZ1BAnx2DqqFxOHZfHjIpcCnP7XhD0Ox94Yc0NmZ997ty5S9x9VnfbAi8OZlYKPAPc6O73m9neVIpDZ7NmzfLFixf3OkPiSlNzev36oIQ1N/Rf9oZIO4++WstDS7fw/Bu7cIfpVeV8YMYEzp82jlGlhX0P24l+5wMvrLkh87ObWY/FIdDZSmaWD9wH/Nbd708+vM3Mxrl7jZmNA7YHl1Ay1cJ1u7hr4Zs8tXIbrdE4E0cO4TNnTub9MyYwSQPLIn0W5GwlA24HVrn7zZ02PQxcDnw3+f2hAOJJhlq0YTe3PPk6z7+xixElBcw7qYr3z5jA9KpyjSOI9KMgWw6nAx8FlpvZ0uRjXydRFO4xsyuBjcC/BhNPMkVrNMaDL2/hnsWbWfLmHkaVFvDNC47j0pMP0+J1ImkS5Gyl54CePuqdNZBZJDPVNbdz/8ub+eWz69haF+GoMaV84/xjufTkwykuUFEQSSedIS0Zxd1Z8uYefvfiRv6yrIbWaJwTDyvnpktO4PSjRqrrSGSAqDhIRnB3/rK8hh89tYY12xspLczjX2dVMu+kw3jHhGFBxxPJOioOErjFG3Zz4yOreHnjXo4ZO5SbLpnGBdPGMaRAf54iQdF/nwRmw84mvvfYah59tZYxQwu56ZJpXHxiJbla9VQkcCoOMuD2NLXx21WtVD/5DPm5OXz+7ClcdcYktRREMoj+G2XAtEZj/Ob5Dfzf39bSGIkyb3YVnz97CmPKioKOJiL7UXGQtHN3/ryshu89tprNe1qYc/Rozh7VyGXvmxZ0NBHpgYqDpNWiDbu58S+rWLopMdh815Wzedfk0VRXVwcdTUQOQMVB0mL9zia+9+hqHltRS0WZBptFwkbFQfpVY2uUW558nd88v4GCvBy+8O4pfOJdGmwWCRv9x0q/cHcefmUr33lkNdsaInx4VhVfOGcKY4ZqsFkkjFQcpM8ee7WWH/11Datq6nnHhDJ+dtmJzDjsgJfgEJEMp+IgvdYajfGDx1/jl39fz5SKUm66eBoXz9S4gshgoOIgvbJw3S6+/sBy1u1o4qOnHM43LziOgrycoGOJSD9RcZBDsre5jW8/sop7Fm+makQxv77iJOYcPSboWCLSz1QcJCUdA87/9aeV7G1p5+p/OYLPnTVF11UQGaRUHOSg3tzVxDcfWsGzr+/ghKpy7vrAVI4bXxZ0LBFJIxUH6VGkPcZPq9/g58+8QX6Ocf37juOjp07UgLNIFlBxkG4t2rCbr/xxGet3NnHhCeO57vxjqdACeSJZQ8VB3hKPO8+/sYuHX9nCvUs2M6G8mLuvPJl3Th4VdDQRGWAqDvKW7z22ml88u46CvByuOG0SXzxnCiWF+hMRyUb6zxeaWqN8+5FV/PaFjXzwxAlcf+HxlBXlBx1LRAKk4pDlnn9jJ1++dxlb61qYf8YRfOXco8nL1clsItlOxSFLtcfi3PLk6/zsmTeYNLKEe68+lVkTRwQdS0QyRMYWBzM7D/gRkAvc5u7fDTjSoLFhZxOfXfAyr2yu499mV/HNC47Tktoiso+MPCKYWS7wE+DdwGZgkZk97O4rg00Wbu7O/S9t4VsPvUpebg4/u/RE3jN1XNCxRCQDZWRxAGYDa919HYCZLQAuAlQceqmupZ3rHljOn5fVMHvSCH744emMLy8OOpaIZChz96AzdGFmlwDnufsnkvc/Cpzs7v/R6TnzgfkAFRUVMxcsWNDr/TU2NlJaWtq30AFINfe6vTF+srSVPa3OB47K5/wj8smxYM9yHuy/80wU1uxhzQ2Zn33u3LlL3H1Wd9syteXQ3ZFrnyrm7rcCtwLMmjXL58yZ0+udVVdX05fXByWV3L9/cSPffXIFY8qKuO3jMzLmIjyD+XeeqcKaPay5IdzZM7U4bAaqOt2vBLYGlCWUIu0x/vOhFfxh8SbOmDKaH314OsNLCoKOJSIhkanFYREw2cwmAVuAecBHgo0UHlv2tvCpu5ewbHMdnz7zKD539hQtlicihyQji4O7R83sP4DHSUxlvcPdVwQcKxSeW7OTT//+JaIx59aPzuSc48cGHUlEQigjiwOAuz8CPBJ0jrBwd37+zDq+//hqjhpTys8vm8kRozN3IExEMlvGFgdJXUOknS/fu4zHVtRy/rRx3HTxNC2YJyJ90uMRxMwa2G+GUMcmwN1dlwLLAGu3N3L1XYvZsKuZb5x/LFe+cxIW8DRVEQm/HouDuw/tuG1mL7v7jIGJJKlaVBvlmr89R1F+LndfeTKnHjky6EgiMkik2veQeWfKZbFoLM4Pnnidny9tZXpVOT+77ETGDdPZziLSf9QxHTK7Glv5zIKX+cfaXcypyuMXV59CYV5u0LFEZJA50JjDBzvdLd/vPu5+f9pSSbeWb67j6rsWs7OpjZsumcaYxjdUGEQkLQ7Ucnhfp9vP7HffARWHAbRmWwOX3raQoUX53PfJ05haOYzq6jeCjiUig9SBBqSv6GmbmV2cnjjSnW31ET72q0UU5ueyYP4pVI0YEnQkERnkens9yFv6NYX0aE9TG5ff8SJ7m9v49RUnqTCIyIDo7YC0JtIPgF2NrVx62wus29nEHZefxPHjhwUdSUSyRG+Lg6a2ptmOhlYuvW0hb+5q5o7LT+Kdk0cFHUlEssiBZistp+czpCvSlkjYXh/hI7e9wJY9LfzqYydx2lEqDCIysA7UcrhgwFLIW7bXR5j3y4XU1kX49RUncfIROutZRAbegWYrvTmQQWTfwvCbj8/mpIkjgo4kIlmqt7OVpJ+pMIhIJlFxyAAqDCKSaVQcAra9QYVBRDLPQaey9jBrqQ5YDPyPu+9KR7BsUB9p5/I7FqkwiEjGSeU8h0eBGPC75P15ye/1wK/Zd80lSVFrNMb8OxezZlsDd3zsJBUGEckoqRSH09399E73l5vZP9z9dDO7LF3BBrNY3PnCH15h4brd/PDD0zljyuigI4mI7COVMYdSMzu5446ZzQY6rlwfTUuqQczdueFPK/jL8hque++xvH/GhKAjiYh0kUrL4RPAHWZWSuLs6HrgSjMrAb6TznCD0U+eXsud/3yTq941iavOOCLoOCIi3TpocXD3RcBUMxsGmLvv7bT5nnQFG4z+9MpWfvDE67x/+niufc+xQccREenRQbuVzGyYmd0M/BV4ysz+N1ko5BAs27yXL937CrMOH873LplGTo4WthWRzJXKmMMdQAPwoeRXPfCrvuzUzL5vZqvNbJmZPWBm5Z22XWtma83sNTM7ty/7yRTb6yPMv3MJo0oL+flHZ+rSniKS8VIpDke6+3+6+7rk1w1AXzvLnwTe4e7TgNeBawHM7DgSU2WPB84DfmpmoT6SRtpjXHXXEuoj7fzy32cxqrQw6EgiIgeVSnFoMbN3dtwxs9OBlr7s1N2fcPeOmU4Lgcrk7YuABe7e6u7rgbXA7L7sK0juztfuW8Yrm/Zy84emc9z4sqAjiYikxNwPfN0eMzsBuBPoGGfYA1zu7sv6JYDZn4A/uPvdZvZjYKG7353cdjvwqLv/sZvXzQfmA1RUVMxcsGBBrzM0NjZSWlp68CceokfXt/OH19r44OR8LjyyoN/fP125B0JYs4c1N4Q3e1hzQ+Znnzt37hJ3n9XtRndP6QsoA8qStz+XwvOfAl7t5uuiTs+5DniAt4vUT4DLOm2/Hbj4YPuaOXOm98XTTz/dp9d3Z+nGPX7ktX/xq+9c7PF4vN/f3z09uQdKWLOHNbd7eLOHNbd75mcHFnsPx9WULxPq7vWd7n4B+OFBnn/2gbab2eUkLih0VjIkwGagqtPTKoGtqWbMFI2tUT6z4GXGDC3kexdPw0wzk0QkXHq7KmufjnZmdh7wVeBCd2/utOlhYJ6ZFZrZJGAy8GJf9jXQ4nHnugeWs2l3Mz+cN4NhQ/KDjiQicshSbjns58ADFQf3Y6AQeDL5qXqhu3/S3VeY2T3AShJLc1zj7rE+7mtA/eiva3ho6Va+dM4UZk/SYnoiEk49Fgcza6D7ImBAcV926u5HHWDbjcCNfXn/oGzc1czPqt/gounjuWZujz+iiEjGO9A1pIcOZJDB4NuPrCIv1/j6e4/VOIOIhJquBNdP/vnGLh5bUcv/m3MkFWVFQccREekTFYd+EIs7//3nlUwoL+YT79JKqyISfioO/eDexZtYWVPP195zDEX5oV7tQ0QESLE4mNnhZnZ28naxmWk8Iqkh0s4PnniNWYcP54Jp44KOIyLSL1JZsvsq4I/AL5IPVQIPpjFTqPzimXXsbGzjW+87ToPQIjJopNJyuAY4ncRS3bj7GmBMOkOFxY6GVu74x3red8J4plWWBx1HRKTfpFIcWt29reOOmeXR95PgBoWfPL2W1micz589OegoIiL9KpXi8IyZfR0oNrN3A/cCf0pvrMy3eU8zv3thI/86s5IjRmfuqosiIr2RSnH4GrADWA5cDTwCfCOdocLg//66FoDPnKVWg4gMPqmsrXQRcKe7/zLdYcKipq6F+1/ezL/NPozx5X1aSUREJCOl0nK4EHjdzO4ys/OTYw5Z7fa/ryfucJVOeBORQeqgxcHdrwCOIjHW8BHgDTO7Ld3BMlVdczu/f3EjF0wbR9WIIUHHERFJi5RaAe7ebmaPkpilVEyiq+kT6QyWqe5dsommthjzz1CrQUQGr1ROgjvPzH4NrAUuAW4DsvJUYHfndy9s5MTDyjl+/LCDv0BEJKRSaTl8DFgAXO3uremNk9n++cYu1u1s4uYPnRB0FBGRtDpocXD3eQMRJAx++8JGyofk896pWdlwEpEs0mO3kpk9l/zeYGb1nb4azKx+4CJmhrrmdp5cuY0PzJiglVdFZNA70JXg3pn8rhVYgb8sr6EtFueDMyqDjiIiknapDEjflcpjg92DL2/hqDGlvGNCWdBRRETSLpWT4I7vfCd5EtzM9MTJTJt2N/Piht18YMYELcstIlnhQGMO15pZAzCt83gDsA14aMASZoBHltcAcOEJ4wNOIiIyMHosDu7+neR4w/fdvSz5NdTdR7r7tQOYMXCPrahl6oRhOiNaRLJGKlNZrzWz4cBkoKjT48+mM1imqK2L8PLGvXz53KODjiIiMmBSGZD+BPAs8DhwQ/L79f2xczP7kpm5mY3q9Ni1ZrbWzF4zs3P7Yz998fiKWgDOPX5swElERAZOKgPSnwVOAt5097nADBLXd+gTM6sC3g1s7PTYccA8EoPg5wE/NbNATyp4fEUtk8eUctQYXdBHRLJHKsUh4u4RADMrdPfVQH/0sdwCfIV9Lzl6EbDA3VvdfT2J9Zxm98O+eqWpNcqiDbs581hdMltEsksqayttNrNy4EHgSTPbA2zty07N7EJgi7u/st/U0AnAws77Tj7W3XvMB+YDVFRUUF1d3es8jY2N3b7+lR1R2mNOWdNWqqu39fr906Wn3GEQ1uxhzQ3hzR7W3BDu7KkMSH8gefN6M3saGAY8drDXmdlTQHcd9dcBXwfO6e5l3UXoIdetwK0As2bN8jlz5hwsUo+qq6vp7vXP/mklhXlvcuVFczJyyYyecodBWLOHNTeEN3tYc0O4sx+0OJjZiE53lye/d3vA7szdz+7h/aYCk4COVkMl8JKZzSbRUqjq9PRK+thK6Yu/r9nB7EkjMrIwiIikUypjDi+RGIB+HViTvL3ezF4ys0M+U9rdl7v7GHef6O4TSRSEE929FngYmGdmhWY2icT02RcPdR/9obYuwprtjbxr8qiDP1lEZJBJZczhMeABd38cwMzOITGT6B7gp8DJ/RXG3VeY2T3ASiAKXOPusf56/0OxcN0uAE4/SsVBRLJPKi2HWR2FAcDdnwDOcPeFQGFfAyRbEDs73b/R3Y9096Pd/dG+vn9vvbxxDyUFuRwzVgvtiUj2SaXlsNvMvkrianAAHwb2JM8/iKctWcCWbtrL1Mph5OZooT0RyT6ptBw+QmJg+MHkV1XysVzgQ+kKFqRIe4yVNfWcUFUedBQRkUCkMpV1J/BpMyt198b9Nq9NT6xgraqppz3mzFBxEJEslcraSqeZ2UoSg8SY2Qlm9tO0JwvQ0k17AdRyEJGslUq30i3AucAuAHd/BTgjnaGCtnTTXirKChk3rDjoKCIigUilOODum/Z7KJDppQNl2eY6TqgsDzqGiEhgUikOm8zsNMDNrMDMvgSsSnOuwETaY2zY1cSx4zSFVUSyVyrF4ZPANSQWwNsMTE/eH5Te2NGIO0yu0BLdIpK9Up2tdOkAZMkIa7cnJmRNHjM04CQiIsHpsTiY2bcO8Dp39/9OQ57ArdnWSG6OMWlUSdBRREQCc6CWQ1M3j5UAVwIjgUFZHF7f1sDEkUMoyEtprF5EZFDqsTi4+/923DazoSQuF3oFiWU0/ren14Xd2u2NHD1WXUoikt0O+PHYzEaY2f8Ay0gUkhPd/avuvn1A0g2w1mhiptJkXS9aRLLcgcYcvg98kMTV1qZ2s3TGoLN+ZxNxh8kVajmISHY7UMvhi8B44BvAVjOrT341mFn9wMQbWGu2JerfUWo5iEiWO9CYQ9aNyG7YmRiD10wlEcl2WVcADmTTnmbGDC3UNaNFJOupOHSycXczVSOGBB1DRCRwKg6dbNrdwmEqDiIiKg4d2mNxaupaqBquZbpFRFQckrbubSHuUKmWg4iIikOHmroIABPK1XIQEVFxSKpNFoeKsqKAk4iIBE/FIam2PlEcxg5TcRARCaw4mNmnzew1M1thZjd1evxaM1ub3HbuQOWprYswtDCP0sKDXuJCRGTQC+RIaGZzgYuAae7eamZjko8fB8wDjiexdMdTZjbF3dN+zerauggVajWIiADBtRw+BXzX3VsBOq3yehGwwN1b3X09sBaYPRCBausjjNV4g4gIAObuA79Ts6XAQ8B5QAT4krsvMrMfAwvd/e7k824HHnX3P3bzHvOB+QAVFRUzFyxY0Os8jY2NfGtxDseOyOWqaYW9fp+B1tjYSGlpOBcJDGv2sOaG8GYPa27I/Oxz585d4u6zutuWtm4lM3sKGNvNpuuS+x0OnAKcBNxjZkcA1s3zu61e7n4rieXEmTVrls+ZM6fXWZ9++mka2luYOvlw5sw5ptfvM9Cqq6vpy88dpLBmD2tuCG/2sOaGcGdPW3Fw97N72mZmnwLu90Sz5UUziwOjgM1AVaenVgJb05WxQ0sU2mPOqNKCdO9KRCQUghpzeBA4E8DMpgAFwE7gYWCemRWa2SRgMvBiusPUtyUaJyNKVBxERCCg2UrAHcAdZvYq0AZcnmxFrDCze4CVQBS4ZiBmKjWoOIiI7COQ4uDubcBlPWy7EbhxIPN0FIeRJeEZjBYRSSedIU2nloPGHEREABUHoHPLQcVBRARUHIBEcRhSkKvLg4qIJKk4kJitNFJdSiIib1FxAJraobxYxUFEpIOKA9AcdYYWaTVWEZEOKg5Ai4qDiMg+VBxILJ8xtCg/6BgiIhlDxQFoblfLQUSks6wvDrG4E4mp5SAi0lnWF4fG1igAZWo5iIi8JeuLQ0OkHUDdSiIinag4RBItB3UriYi8TcXhreKgloOISAcVh7e6ldRyEBHpoOKgloOISBcqDhqQFhHpIuuLQ1Nb4iqkpYUqDiIiHbK+OETaE8WhKE/XchAR6aDi0B4nzyAnx4KOIiKSMVQc2mPoAnAiIvvK+uLQGo1RkKtWg4hIZ1lfHCLtcQqy/rcgIrKvrD8sqltJRKSrQIqDmU03s4VmttTMFpvZ7E7brjWztWb2mpmdm+4skfYYBRqMFhHZR1CT+28CbnD3R83svcn7c8zsOGAecDwwHnjKzKa4eyxdQSLtcQrUchAR2UdQ3UoOlCVvDwO2Jm9fBCxw91Z3Xw+sBWZ38/p+E4nGyM/6zjURkX2Zuw/8Ts2OBR4HjESBOs3d3zSzHwML3f3u5PNuBx519z928x7zgfkAFRUVMxcsWNCrLN/8Rwvl+TG+OLu0dz9MgBobGyktDV9uCG/2sOaG8GYPa27I/Oxz585d4u6zutuWtm4lM3sKGNvNpuuAs4DPu/t9ZvYh4HbgbBLFYn/dVi93vxW4FWDWrFk+Z86cXuXMX1xNcV6E3r4+SNXV1aHMDeHNHtbcEN7sYc0N4c6etuLg7mf3tM3M7gQ+m7x7L3Bb8vZmoKrTUyt5u8spLSLtMQoKNSAtItJZUL3tW4F/Sd4+E1iTvP0wMM/MCs1sEjAZeDGdQSJRnecgIrK/oGYrXQX8yMzygAjJsQN3X2Fm9wArgShwTTpnKkHHeQ5qOYiIdBZIcXD354CZPWy7EbhxgHIkz3PQVeBERDrL6g6V9pgTd3SGtIjIfrK6OESiiR4rnSEtIrKv7C4OyQv9qOUgIrKvrC4Ore1xAM1WEhHZT1YfFt9uOahbSUSksywvDmo5iIh0J6sPiyWFuZw/dRwji9VyEBHpLKuLwxGjS/nJpSdyeJlGpEVEOsvq4iAiIt1TcRARkS5UHEREpAsVBxER6ULFQUREulBxEBGRLlQcRESkCxUHERHpwtw96Ax9ZmY7gDf78BajgJ39FGcghTU3hDd7WHNDeLOHNTdkfvbD3X10dxsGRXHoKzNb7O6zgs5xqMKaG8KbPay5IbzZw5obwp1d3UoiItKFioOIiHSh4pBwa9ABeimsuSG82cOaG8KbPay5IcTZNeYgIiJdqOUgIiJdqDiIiEgXWV0czOw8M3vNzNaa2deCzpMqM7vDzLab2atBZzkUZlZlZk+b2SozW2Fmnw06U6rMrMjMXjSzV5LZbwg606Ews1wze9nM/hx0lkNhZhvMbLmZLTWzxUHnSZWZlZvZH81sdfLv/dSgMx2qrB1zMLNc4HXg3cBmYBHwb+6+MtBgKTCzM4BG4E53f0fQeVJlZuOAce7+kpkNBZYA7w/J79yAEndvNLN84Dngs+6+MOBoKTGzLwCzgDJ3vyDoPKkysw3ALHfP5BPJujCz3wB/d/fbzKwAGOLuewOOdUiyueUwG1jr7uvcvQ1YAFwUcKaUuPuzwO6gcxwqd69x95eStxuAVcCEYFOlxhMak3fzk1+h+GRlZpXA+cBtQWfJBmZWBpwB3A7g7m1hKwyQ3cVhArCp0/3NhORANRiY2URgBvBCwFFSluyaWQpsB55097Bk/yHwFSAecI7ecOAJM1tiZvODDpOiI4AdwK+SXXm3mVlJ0KEOVTYXB+vmsVB8Egw7MysF7gM+5+71QedJlbvH3H06UAnMNrOM79IzswuA7e6+JOgsvXS6u58IvAe4JtmlmunygBOBn7n7DKAJCM2YZodsLg6bgapO9yuBrQFlyRrJ/vr7gN+6+/1B5+mNZBdBNXBesElScjpwYbLvfgFwppndHWyk1Ln71uT37cADJLqDM91mYHOnluUfSRSLUMnm4rAImGxmk5IDRvOAhwPONKglB3VvB1a5+81B5zkUZjbazMqTt4uBs4HVgYZKgbtf6+6V7j6RxN/439z9soBjpcTMSpITF0h2y5wDZPwMPXevBTaZ2dHJh84CMn7Sxf7ygg4QFHePmtl/AI8DucAd7r4i4FgpMbPfA3OAUWa2GfhPd7892FQpOR34KLA82XcP8HV3fyS4SCkbB/wmOcstB7jH3UM1LTSEKoAHEp8pyAN+5+6PBRspZZ8Gfpv84LkOuCLgPIcsa6eyiohIz7K5W0lERHqg4iAiIl2oOIiISBcqDiIi0oWKg4iIdJG1U1llcDKzRncvDTpHX5jZFUDHirXHAa8BMeAxoA141t2fCiieZAlNZZVBZTAUh87CuiqphJ+6lWTQMrMcM1tjZqM73V9rZqPM7H1m9kJyYbSnzKwi+ZzrzewuM/tb8rVXJR+f0/laCGb2YzP7WPL2BjO7wcxeSl574Jjk4yPM7EEzW2ZmC81sWjLDho6zrZPPW9ux/xR+pl+b2SWd9vttM/unmS02sxPN7HEze8PMPtnpNV82s0XJHKG6DoUER8VBBi13jwN3A5cmHzobeCX5Kfw54JTkwmgLSKxa2mEaiSWuTwW+ZWbjU9jdzuQCcT8DvpR87AbgZXefBnydxPU34sBDwAcAzOxkYIO7b+vlj7nJ3U8F/g78GrgEOAX4r+T7nwNMJrEm0XRgZkgWr5OAqTjIYHcH8O/J2x8HfpW8XQk8bmbLgS8Dx3d6zUPu3pIsIk+T2mJvHYsILgEmJm+/E7gLwN3/Bow0s2HAH4APJ58zL3m/tzrWA1sOvODuDe6+A4gkWyfnJL9eBl4CjiFRLEQOSMVBBjV33wRsM7MzgZOBR5Ob/g/4sbtPBa4Gijq/bP+3AaLs+/9StN9zWpPfY7w90aOnZeH/CRyV7O56P28Xlt7o2G+80+2O+3nJDN9x9+nJr6NCsg6XBEzFQbLBbSS6l+5x91jysWHAluTty/d7/kWWuGb0SBILHC4C3gSOM7PC5Kf/s1LY77Mku7TMbA6Jrqd6T8wCeQC4mcQKtbt6+4Ol4HHg48lraGBmE8xsTBr3J4OEprLKYDMkuVJth5tJtBJ+xdtdSgDXA/ea2RZgITCp07YXgb8AhwH/3XFNATO7B1gGrCHRTXMw15O4GtgyoJl9i9AfSBSdj6X4c/WKuz9hZscC/0yubtoIXEbianYiPdJUVhn0zGwWcIu7vyuF514PNLr7D9IeTCSDqeUgg5qZfQ34FG/PWBKRFKjlICIiXWhAWkREulBxEBGRLlQcRESkCxUHERHpQsVBRES6+P/4IHU5S/MbEgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(L_forecast_test) / LORENZ_LT * 0.01, neg_log_LH(mixture_pred_all_mean,  std_dev))\n",
    "# plt.title(\"Negative Log LH against time\")\n",
    "plt.ylabel(\"Negative Log LH\")\n",
    "plt.xlabel(\"Lyapunov Time\")\n",
    "plt.grid(\"on\")\n",
    "plt.savefig(\"RC Deep Ensemble NLL.png\", facecolor = \"white\", bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "922f8246-3655-4c31-a601-bddef8f7a2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall negative log LH: 15.86700\n"
     ]
    }
   ],
   "source": [
    "print(f\"Overall negative log LH: {neg_log_LH(mixture_pred_all_mean, std_dev).mean():.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
