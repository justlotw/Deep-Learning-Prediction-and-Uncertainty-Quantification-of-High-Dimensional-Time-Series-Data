{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14d57da9-ca77-4333-ba41-8236efa46467",
   "metadata": {},
   "source": [
    "# Method: LSTM\n",
    "# Dataset: Lorenz-96, F = 8\n",
    "# Purpose: Uncertainty Quantification - Deep Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9711fa4f-7843-43d5-a047-14c762fd2e5f",
   "metadata": {},
   "source": [
    "# 1. Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9f852d7-2ea3-49a4-8bd5-a85ba731f802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "# Package\n",
    "import sys\n",
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ee758f3-121d-4ca7-a44e-f00db4631d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from create_data import load_data\n",
    "from utils import * # Number of testing samples\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from functools import partial\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.nn.initializers import glorot_normal, normal\n",
    "from jax.example_libraries import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee80a55c-5e5d-4120-8c56-8be07285e9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = load_data(\"Lorenz 96, F = 8\", \"../../data/lorenz8\", 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e30a3f5f-c622-4e95-ae1c-dd652be02b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (90000, 40)\n",
      "Test size: (90000, 40)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train size: {train.data.shape}\")\n",
    "print(f\"Test size: {test.data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8288061f-20ca-4fe6-840e-6ee8cd8064b1",
   "metadata": {},
   "source": [
    "**Create test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c868d5f-50c3-48a5-8762-e0de61468e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_forecast_test = 400   # steps to forecast forward (when testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a2ec67a-c0aa-45b0-b059-cb9a1dceb438",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "data_test = test.data\n",
    "\n",
    "T_test, data_dim = data_test.shape\n",
    "possible_idx = T_test - (L_forecast_test + 1) # minus number of steps forward, and the warm-up period\n",
    "T_indices = np.random.randint(0, possible_idx, size = NUM_TEST)\n",
    "\n",
    "t_past_batch = np.repeat(T_indices[:, None], WARM_UP_TEST, axis = 1).astype(int) # 200 warmup \n",
    "t_pred_batch = (T_indices[:, None] + np.arange(1, 1 + L_forecast_test)[None, :].astype(int))\n",
    "\n",
    "X_test = data_test[t_past_batch]\n",
    "y_test = data_test[t_pred_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e57b737-d4d5-41f0-9077-071567f3758f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test input size: (100, 2000, 40)\n",
      "Test output size: (100, 400, 40)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test input size: {X_test.shape}\")  # Number of test points x input length x dim\n",
    "print(f\"Test output size: {y_test.shape}\") # Number of test points x horizon x dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0bd417-72d0-4d90-8b16-30945dd0ee20",
   "metadata": {},
   "source": [
    "# 2. LSTM Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf9258f6-5dd2-4ddf-ab11-8f9f274ffb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM(h_dim, data_dim, W_init = glorot_normal(), b_init = normal()):\n",
    "    \"\"\"\n",
    "    args:\n",
    "    ====\n",
    "     h_dim: dimension of the internal state\n",
    "     data_dim: dimensionity of the time series\n",
    "\n",
    "    outputs:\n",
    "    ======\n",
    "     init_fun: function to initialize the parameters\n",
    "     process: function to process a time-series and compute the final prediction and final internal state\n",
    "     forecast: function that, given a pair (internal-state, input), computes the next T predictions\n",
    "    \"\"\"\n",
    "    \n",
    "    def init_fun(rng):\n",
    "        \"\"\"\n",
    "        This function initialize the weights of the RNN\n",
    "        \n",
    "        args:\n",
    "        ====\n",
    "         rng: jax RNG\n",
    "         \n",
    "        outputs:\n",
    "        ======\n",
    "         params: a tuple of parameters\n",
    "        \"\"\"\n",
    "        \n",
    "        # Forget Layer\n",
    "        k1, k2, k3 = jax.random.split(rng, num = 3)\n",
    "        fU = W_init(k1, (h_dim, data_dim))\n",
    "        fW = W_init(k2, (h_dim, h_dim)) \n",
    "        fb = b_init(k3, (h_dim,))\n",
    "        \n",
    "        # Input Layer\n",
    "        k1, k2, k3 = jax.random.split(rng, num = 3)\n",
    "        iU = W_init(k1, (h_dim, data_dim))\n",
    "        iW = W_init(k2, (h_dim, h_dim))\n",
    "        ib = b_init(k3, (h_dim,))\n",
    "        \n",
    "        # Candidate layer\n",
    "        k1, k2, k3 = jax.random.split(rng, num = 3)\n",
    "        gU = W_init(k1, (h_dim, data_dim))\n",
    "        gW = W_init(k2, (h_dim, h_dim))\n",
    "        gb = b_init(k3, (h_dim,))\n",
    "        \n",
    "        # Output layer\n",
    "        k1, k2, k3 = jax.random.split(rng, num = 3)\n",
    "        oU = W_init(k1, (h_dim, data_dim))\n",
    "        oW = W_init(k2, (h_dim, h_dim))\n",
    "        ob = b_init(k3, (h_dim,))\n",
    "        \n",
    "        # Dense layer (hidden -> y)\n",
    "        k1, k2 = jax.random.split(rng, num = 2)\n",
    "        dO = W_init(k1, (data_dim, h_dim))\n",
    "        db = b_init(k2, (data_dim,))\n",
    "                \n",
    "        params = fU, fW, fb, iU, iW, ib, gU, gW, gb, oU, oW, ob, dO, db\n",
    "        return params\n",
    "    \n",
    "    def process(params, time_series):\n",
    "        \"\"\"\n",
    "        This function takes a time-series in input, pass it through the RNN, \n",
    "        and finally outputs the last prediction and internal state\n",
    "        \n",
    "        args:\n",
    "        ====\n",
    "         params: tuple of parameters\n",
    "         time_series: data of dimension (T, dim_data)\n",
    "         \n",
    "        outputs:\n",
    "        =======\n",
    "         c_final: jax vector of dimension nn_size\n",
    "         h_final: jax vector of dimension nn_size\n",
    "         pred_traj[-1]: last prediction\n",
    "        \"\"\"\n",
    "        \n",
    "        fU, fW, fb, iU, iW, ib, gU, gW, gb, oU, oW, ob, dO, db = params \n",
    "        \n",
    "        c_zero = np.zeros((h_dim, ))\n",
    "        h_zero = np.zeros((h_dim, ))\n",
    "        \n",
    "        # forward pass\n",
    "        def process_internal(start, x):\n",
    "            c, h = start\n",
    "            \n",
    "            forget_gate = sigmoid(jnp.dot(fU, x) + jnp.dot(fW, h) + fb)\n",
    "            input_gate = sigmoid(jnp.dot(iU, x) + jnp.dot(iW, h) + ib)\n",
    "            cand_gate = jnp.tanh(jnp.dot(gU, x) + jnp.dot(gW, h) + gb)\n",
    "            c_new = forget_gate * c + input_gate * cand_gate\n",
    "            output_gate = sigmoid(jnp.dot(oU, x) + jnp.dot(oW, h) + ob)\n",
    "            h_new = jnp.tanh(c_new) * output_gate\n",
    "            y = x + dO @ h_new + db\n",
    "            \n",
    "            return (c_new, h_new), y\n",
    "        (c_final, h_final), pred_traj = jax.lax.scan(process_internal, (c_zero, h_zero), time_series)\n",
    "        return (c_final, h_final), pred_traj[-1]\n",
    "    \n",
    "    \n",
    "    def forecast(params, internal_states, x_input, horizon):\n",
    "        \"\"\"\n",
    "        This function takes in an internal state and a first input and produces \n",
    "        prediction over a finite horizon.\n",
    "        \n",
    "        args:\n",
    "        ====\n",
    "         params: tuple of parameters\n",
    "         internal_states = (c_internal, h_internal): internal state values of c and h\n",
    "         x_input: jax vector of dimension dim_data\n",
    "         horizon: horizon of the prediction\n",
    "         \n",
    "        outputs:\n",
    "        =======\n",
    "         preds: a trajectory of prediction of dimension (horison, dim_data) \n",
    "        \"\"\"\n",
    "        c_internal, h_internal = internal_states\n",
    "        # extract parameters\n",
    "        fU, fW, fb, iU, iW, ib, gU, gW, gb, oU, oW, ob, dO, db = params \n",
    "        \n",
    "        # forward pass\n",
    "        def forecast_internal(triple_c_h_x, _ ):\n",
    "            cell, hidden, x = triple_c_h_x\n",
    "            \n",
    "            forget_gate = sigmoid(jnp.dot(fU, x) + jnp.dot(fW, hidden) + fb)\n",
    "            input_gate = sigmoid(jnp.dot(iU, x) + jnp.dot(iW, hidden) + ib)\n",
    "            cand_gate = jnp.tanh(jnp.dot(gU, x) + jnp.dot(gW, hidden) + gb)\n",
    "            c_new = forget_gate * cell + input_gate * cand_gate\n",
    "            output_gate = sigmoid(jnp.dot(oU, x) + jnp.dot(oW, hidden) + ob)\n",
    "            h_new = jnp.tanh(c_new) * output_gate\n",
    "            y = x + dO @ h_new + db\n",
    "            \n",
    "            return (c_new, h_new, y), y\n",
    "        \n",
    "        _, pred_traj = jax.lax.scan(forecast_internal, (c_internal, h_internal, x_input), None, length=horizon)\n",
    "        \n",
    "        # return the trajectory of predictions\n",
    "        return pred_traj\n",
    "    \n",
    "    return init_fun, process, forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e38aeb0-0445-45f9-9a44-36b0e096cebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameters(nn_size, seed, batch_size, L_past, L_forecast_train, \n",
    "                   num_epoch, lr_schedule, early_stopping = EARLY_STOPPING, \n",
    "                  early_stopping_baseline = 1.):\n",
    "    assert len(num_epoch) == len(lr_schedule)\n",
    "    def training(x, y, init_params):\n",
    "        @jax.jit\n",
    "        def step(i, opt_state, x_batch, y_batch):\n",
    "            params = get_params(opt_state)\n",
    "            value, g = jax.value_and_grad(mse)(params, x_batch, y_batch)\n",
    "            opt_state = opt_update(i, g, opt_state)\n",
    "            return get_params(opt_state), opt_state, value\n",
    "        \n",
    "        @partial(jax.jit, static_argnums=2)\n",
    "        def make_forecast(params, x_batch, horizon):\n",
    "            # pass the data through the RNN. \n",
    "            # note that \"preds\" is the first forecasts\n",
    "            hs, preds = process_batch(params, x_batch)\n",
    "            # compute the (L_forecast-1) next forecasts\n",
    "            y_pred = forecast_batch(params, hs, preds, horizon-1)\n",
    "            #stick all the forecasts together\n",
    "            y_pred = jnp.concatenate([preds[:, None,:], y_pred], axis=1)\n",
    "\n",
    "            return y_pred\n",
    "\n",
    "        @jax.jit\n",
    "        def mse(params, x_batch, y_truth):\n",
    "            \"\"\"\n",
    "            For each time-series in a batch, forecasts over a finite horizon \n",
    "            and compute the MSE.\n",
    "\n",
    "            args:\n",
    "            ====\n",
    "             params: neural parameters\n",
    "             x_batch: a batch of inputs with dimension (batch_size, T_past, dim_data)\n",
    "             y_truth: a batch of values to forecasts with dimension (batch_size, T_future, dim_data)\n",
    "\n",
    "            outputs:\n",
    "            =======\n",
    "             MSE: MSE between forecasts and targets\n",
    "            \"\"\"\n",
    "\n",
    "            # horizon of the forecast\n",
    "            L_forecast = y_truth.shape[1]    \n",
    "            y_pred = make_forecast(params, x_batch, L_forecast)\n",
    "\n",
    "            #compute MSE\n",
    "            error = y_pred - y_truth\n",
    "            mu_loss = jnp.mean(error**2)\n",
    "            return mu_loss \n",
    "        \n",
    "        start = time()\n",
    "                \n",
    "        loss_train_traj = []\n",
    "        loss_train_all_traj = []\n",
    "        \n",
    "        overall_best_params = init_params\n",
    "        overall_best_mse = 999999999\n",
    "        \n",
    "        # train/val split\n",
    "        t_size = int(0.9 * train_size)\n",
    "        v_size = train_size - t_size\n",
    "        T_indices_val = np.arange(t_size, train_size - (L_forecast_test//2 + L_past))\n",
    "        t_start_val = T_indices_val[::10]\n",
    "        t_past_batch_val = (t_start_val[:,None] + np.arange(L_past)[None,:]).astype(int) \n",
    "        t_pred_batch_val = (t_start_val[:,None] + np.arange(L_past,L_past+L_forecast_test//2)[None,:]).astype(int) \n",
    "        x_val = x[t_past_batch_val]\n",
    "        y_val = y[t_pred_batch_val]\n",
    "        \n",
    "        \n",
    "        print(\"Backpropogation start\", end = \"\\n\\n\")\n",
    "        for i, lr in enumerate(lr_schedule):\n",
    "            opt_init, opt_update, get_params = optimizers.adam(step_size = lr) \n",
    "            opt_state = opt_init(overall_best_params)\n",
    "            counter = 0\n",
    "            best_mse = 999999999\n",
    "            \n",
    "            for epoch in range(num_epoch[i]):\n",
    "                e_start = time()\n",
    "                \n",
    "                # randomize the order of the training data\n",
    "                T_indices = np.arange(t_size - (L_forecast_train + L_past))\n",
    "                np.random.shuffle(T_indices)\n",
    "                \n",
    "                # training\n",
    "                loss_epoch_train = []\n",
    "                \n",
    "                for k in range(t_size // batch_size + 1):\n",
    "                    # create a batch of data\n",
    "                    t_start = T_indices[np.arange(k*batch_size, (k+1)*batch_size).astype(int) % len(T_indices)] # start of each time series in the batch\n",
    "                    # create 2d array of dimension (batch_size, L_past) containing all the time indices\n",
    "                    t_past_batch = (t_start[:,None] + np.arange(L_past)[None,:]).astype(int) # transposes data\n",
    "                    t_pred_batch = (t_start[:,None] + np.arange(L_past,L_past+L_forecast_train)[None,:]).astype(int) \n",
    "\n",
    "                    #create batch of dimension (batch_size, L_past, data_dim)\n",
    "                    x_batch = x[t_past_batch]  \n",
    "                    y_batch = y[t_pred_batch]\n",
    "\n",
    "                    params, opt_state, loss_current = step(k, opt_state, x_batch, y_batch) # update\n",
    "                    loss_epoch_train.append(loss_current)\n",
    "                \n",
    "                mse_train = np.mean(loss_epoch_train)\n",
    "                \n",
    "                # validation             \n",
    "                mse_val = mse(params, x_val, y_val)\n",
    "                \n",
    "                if  best_mse > mse_val: # Improvement\n",
    "                    counter = 0\n",
    "                    best_mse = mse_val\n",
    "                    best_params = params\n",
    "                else:\n",
    "                    counter += 1\n",
    "                \n",
    "                e_end = time()\n",
    "                if (epoch + 1) % 10 == 0 or (counter == 0 and epoch >= 50):\n",
    "                    print(f\"Epoch {epoch + 1}: Time taken = {e_end - e_start:.2f} | Train loss = {mse_train:.7f} | Val loss = {mse_val: .7f}\")\n",
    "                \n",
    "                if best_mse < early_stopping_baseline and counter >= early_stopping:\n",
    "                    print(f\"EARLY STOPPING. Epoch {epoch + 1}: Train loss = {mse_train:.7f} | Val loss = {mse_val: .7f}\")\n",
    "                    break\n",
    "            print(f\"Best Validation MSE: {best_mse:.7f}\")\n",
    "            \n",
    "            if best_mse < overall_best_mse: # Best round so far\n",
    "                print(\"IMPROVED VALIDATION MSE\")\n",
    "                overall_best_mse = best_mse\n",
    "                overall_best_params = best_params\n",
    "            print()\n",
    "        \n",
    "        end = time()\n",
    "        print(f\"Total time: {end - start:.2f}\")\n",
    "        \n",
    "        return overall_best_params\n",
    "\n",
    "    start = time()\n",
    "    x, y = train.data[:-1], train.data[1:]\n",
    "    train_size, data_dim = x.data.shape\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    key = jax.random.PRNGKey(seed)\n",
    "    \n",
    "    # Initialize LSTM\n",
    "    init_fun, process, forecast = LSTM(nn_size, data_dim)       # LSTM Network\n",
    "    process_batch = jax.jit(jax.vmap(process, in_axes=(None,0)))\n",
    "    forecast_batch = jax.jit(jax.vmap(forecast, in_axes=(None,0,0,None)), static_argnums=3)\n",
    "    init_params = init_fun(key)\n",
    "    \n",
    "    final_params = training(x, y, init_params)\n",
    "    end = time()\n",
    "    print(f\"Complete. Time taken: {end - start:.2f}s\")\n",
    "    \n",
    "    return final_params, (process_batch, forecast_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2863ad98-35c2-435c-bcea-86318c9152df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_pred(data_test, params, lstm_fx):  \n",
    "    @partial(jax.jit, static_argnums=2)\n",
    "    def make_forecast(params, x_batch, horizon):\n",
    "        pbatch, fbatch = lstm_fx\n",
    "        # pass the data through the RNN. \n",
    "        # note that \"preds\" is the first forecasts\n",
    "        hs, preds = pbatch(params, x_batch)\n",
    "        # compute the (L_forecast-1) next forecasts\n",
    "        y_pred = fbatch(params, hs, preds, horizon-1)\n",
    "        #stick all the forecasts together\n",
    "        y_pred = jnp.concatenate([preds[:, None,:], y_pred], axis=1)\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    @jax.jit\n",
    "    def loss(params, x_batch, y_truth):\n",
    "        \"\"\"\n",
    "        For each time-series in a batch, forecasts over a finite horizon \n",
    "        and compute the MSE.\n",
    "\n",
    "        args:\n",
    "        ====\n",
    "         params: neural parameters\n",
    "         x_batch: a batch of inputs with dimension (batch_size, T_past, dim_data)\n",
    "         y_truth: a batch of values to forecasts with dimension (batch_size, T_future, dim_data)\n",
    "\n",
    "        outputs:\n",
    "        =======\n",
    "         MSE: MSE between forecasts and targets\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # horizon of the forecast\n",
    "        L_forecast = y_truth.shape[1]    \n",
    "        y_pred = make_forecast(params, x_batch, L_forecast)\n",
    "\n",
    "        #compute MSE\n",
    "        error = y_pred - y_truth\n",
    "        return jnp.mean(error**2)\n",
    "    \n",
    "    start = time()\n",
    "    num_data_test, L_past, data_dim = data_test.shape # testing ex, # steps used before, dim of data\n",
    "    mu_pred = make_forecast(params, data_test, L_forecast_test)\n",
    "    end = time()\n",
    "    print(f\"Testing complete. Time taken: {end - start:.2f}\")\n",
    "    return np.array(mu_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffce42df-dfac-4615-b07e-4446a271acf9",
   "metadata": {},
   "source": [
    "# 3. Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fcf92b1-c8cb-4996-939f-882d454fb811",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_size = 1000\n",
    "L_forecast_train = 8\n",
    "L_past = 1\n",
    "\n",
    "b_size = 128 # Batch size\n",
    "lr_list = [1e-3, 1e-4, 1e-5, 1e-6] # Learning rate schedule\n",
    "epoch_list = [400, 200, 200, 200]  # Number of epochs for each learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74d7b604-3ef1-4bcb-906c-7bf127f6a62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_folder = os.path.join(\"results\", \"ensemble\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7070f12-ba7a-4599-9006-1beede669821",
   "metadata": {},
   "source": [
    "# 4. Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e889a637-c08a-4c93-89a7-9e47d06cd87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_seed(seed):\n",
    "    \"\"\"\n",
    "    Runs the experiment with optimal parameters and appends the predictions into the global variable mu_preds\n",
    "    \"\"\"\n",
    "    params, lstm_fx = get_parameters(nn_size = nn_size, seed = seed, batch_size = b_size, L_past = L_past, \n",
    "                                 L_forecast_train = L_forecast_train, num_epoch = epoch_list, lr_schedule = lr_list,\n",
    "                                early_stopping = 50)\n",
    "    mean_pred = get_test_pred(X_test, params, lstm_fx)\n",
    "    file_name = \"mu_preds_\" + str(seed) + \".pkl\"\n",
    "    save_obj(mean_pred, res_folder, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b029e63e-02d0-42b0-bbf9-e982688efdb0",
   "metadata": {},
   "source": [
    "## 4.1 Seed 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94a029d6-0662-428d-979b-516d596711c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backpropogation start\n",
      "\n",
      "Epoch 10: Time taken = 6.18 | Train loss = 0.0003621 | Val loss =  0.6605164\n",
      "Epoch 20: Time taken = 6.21 | Train loss = 0.0001524 | Val loss =  0.5334616\n",
      "Epoch 30: Time taken = 6.27 | Train loss = 0.0000979 | Val loss =  0.4412132\n",
      "Epoch 40: Time taken = 6.28 | Train loss = 0.0000757 | Val loss =  0.4295097\n",
      "Epoch 50: Time taken = 6.28 | Train loss = 0.0000478 | Val loss =  0.2926973\n",
      "Epoch 55: Time taken = 6.28 | Train loss = 0.0000474 | Val loss =  0.2836868\n",
      "Epoch 60: Time taken = 6.28 | Train loss = 0.0000438 | Val loss =  0.2879066\n",
      "Epoch 62: Time taken = 6.26 | Train loss = 0.0000445 | Val loss =  0.2653593\n",
      "Epoch 65: Time taken = 6.27 | Train loss = 0.0000355 | Val loss =  0.2537400\n",
      "Epoch 67: Time taken = 6.27 | Train loss = 0.0000398 | Val loss =  0.2512762\n",
      "Epoch 70: Time taken = 6.27 | Train loss = 0.0000385 | Val loss =  0.2753908\n",
      "Epoch 73: Time taken = 6.27 | Train loss = 0.0000306 | Val loss =  0.2436080\n",
      "Epoch 75: Time taken = 6.28 | Train loss = 0.0000325 | Val loss =  0.2385906\n",
      "Epoch 80: Time taken = 6.29 | Train loss = 0.0000328 | Val loss =  0.2531511\n",
      "Epoch 82: Time taken = 6.29 | Train loss = 0.0000262 | Val loss =  0.2253591\n",
      "Epoch 84: Time taken = 6.28 | Train loss = 0.0000250 | Val loss =  0.2235845\n",
      "Epoch 87: Time taken = 6.28 | Train loss = 0.0000272 | Val loss =  0.1973390\n",
      "Epoch 89: Time taken = 6.29 | Train loss = 0.0000219 | Val loss =  0.1872062\n",
      "Epoch 90: Time taken = 6.27 | Train loss = 0.0000328 | Val loss =  0.2243250\n",
      "Epoch 100: Time taken = 6.28 | Train loss = 0.0000267 | Val loss =  0.2140512\n",
      "Epoch 107: Time taken = 6.27 | Train loss = 0.0000217 | Val loss =  0.1757658\n",
      "Epoch 110: Time taken = 6.27 | Train loss = 0.0000239 | Val loss =  0.2127549\n",
      "Epoch 113: Time taken = 6.27 | Train loss = 0.0000216 | Val loss =  0.1730997\n",
      "Epoch 118: Time taken = 6.27 | Train loss = 0.0000201 | Val loss =  0.1688433\n",
      "Epoch 120: Time taken = 6.28 | Train loss = 0.0000233 | Val loss =  0.2189374\n",
      "Epoch 130: Time taken = 6.27 | Train loss = 0.0000182 | Val loss =  0.1902616\n",
      "Epoch 140: Time taken = 6.27 | Train loss = 0.0000204 | Val loss =  0.1607496\n",
      "Epoch 141: Time taken = 6.29 | Train loss = 0.0000180 | Val loss =  0.1565040\n",
      "Epoch 150: Time taken = 6.27 | Train loss = 0.0000184 | Val loss =  0.1632179\n",
      "Epoch 152: Time taken = 6.27 | Train loss = 0.0000170 | Val loss =  0.1530033\n",
      "Epoch 160: Time taken = 6.28 | Train loss = 0.0000160 | Val loss =  0.1679316\n",
      "Epoch 170: Time taken = 6.28 | Train loss = 0.0000179 | Val loss =  0.1679028\n",
      "Epoch 180: Time taken = 6.27 | Train loss = 0.0000150 | Val loss =  0.1773424\n",
      "Epoch 182: Time taken = 6.28 | Train loss = 0.0000136 | Val loss =  0.1462652\n",
      "Epoch 190: Time taken = 6.27 | Train loss = 0.0000130 | Val loss =  0.1429807\n",
      "Epoch 200: Time taken = 6.28 | Train loss = 0.0000118 | Val loss =  0.1388427\n",
      "Epoch 202: Time taken = 6.29 | Train loss = 0.0000125 | Val loss =  0.1368892\n",
      "Epoch 210: Time taken = 6.28 | Train loss = 0.0000134 | Val loss =  0.1609489\n",
      "Epoch 220: Time taken = 6.29 | Train loss = 0.0000136 | Val loss =  0.1395368\n",
      "Epoch 223: Time taken = 6.28 | Train loss = 0.0000118 | Val loss =  0.1281106\n",
      "Epoch 230: Time taken = 6.28 | Train loss = 0.0000124 | Val loss =  0.1695172\n",
      "Epoch 240: Time taken = 6.28 | Train loss = 0.0000125 | Val loss =  0.1314655\n",
      "Epoch 243: Time taken = 6.27 | Train loss = 0.0000117 | Val loss =  0.1254645\n",
      "Epoch 249: Time taken = 6.27 | Train loss = 0.0000104 | Val loss =  0.1219690\n",
      "Epoch 250: Time taken = 6.27 | Train loss = 0.0000128 | Val loss =  0.1367800\n",
      "Epoch 260: Time taken = 6.28 | Train loss = 0.0000123 | Val loss =  0.1524238\n",
      "Epoch 263: Time taken = 6.28 | Train loss = 0.0000102 | Val loss =  0.1182539\n",
      "Epoch 270: Time taken = 6.28 | Train loss = 0.0000111 | Val loss =  0.1449965\n",
      "Epoch 271: Time taken = 6.28 | Train loss = 0.0000096 | Val loss =  0.1167554\n",
      "Epoch 278: Time taken = 6.28 | Train loss = 0.0000086 | Val loss =  0.1122227\n",
      "Epoch 280: Time taken = 6.27 | Train loss = 0.0000090 | Val loss =  0.1011054\n",
      "Epoch 290: Time taken = 6.27 | Train loss = 0.0000093 | Val loss =  0.1134352\n",
      "Epoch 300: Time taken = 6.27 | Train loss = 0.0000094 | Val loss =  0.1296918\n",
      "Epoch 310: Time taken = 6.27 | Train loss = 0.0000095 | Val loss =  0.1150395\n",
      "Epoch 320: Time taken = 6.27 | Train loss = 0.0000070 | Val loss =  0.1089391\n",
      "Epoch 330: Time taken = 6.26 | Train loss = 0.0000094 | Val loss =  0.1165833\n",
      "EARLY STOPPING. Epoch 330: Train loss = 0.0000094 | Val loss =  0.1165833\n",
      "Best Validation MSE: 0.1011054\n",
      "IMPROVED VALIDATION MSE\n",
      "\n",
      "Epoch 10: Time taken = 6.28 | Train loss = 0.0000100 | Val loss =  0.1463178\n",
      "Epoch 20: Time taken = 6.27 | Train loss = 0.0000113 | Val loss =  0.1435457\n",
      "Epoch 30: Time taken = 6.28 | Train loss = 0.0000099 | Val loss =  0.1116374\n",
      "Epoch 40: Time taken = 6.28 | Train loss = 0.0000095 | Val loss =  0.1238477\n",
      "Epoch 50: Time taken = 6.28 | Train loss = 0.0000093 | Val loss =  0.1219960\n",
      "EARLY STOPPING. Epoch 51: Train loss = 0.0000087 | Val loss =  0.1280287\n",
      "Best Validation MSE: 0.0978542\n",
      "IMPROVED VALIDATION MSE\n",
      "\n",
      "Epoch 10: Time taken = 6.28 | Train loss = 0.0000099 | Val loss =  0.1140982\n",
      "Epoch 20: Time taken = 6.28 | Train loss = 0.0000088 | Val loss =  0.1165983\n",
      "Epoch 30: Time taken = 6.27 | Train loss = 0.0000101 | Val loss =  0.1337231\n",
      "Epoch 40: Time taken = 6.28 | Train loss = 0.0000101 | Val loss =  0.1549246\n",
      "Epoch 50: Time taken = 6.28 | Train loss = 0.0000092 | Val loss =  0.1162289\n",
      "Epoch 60: Time taken = 6.27 | Train loss = 0.0000095 | Val loss =  0.1221056\n",
      "Epoch 70: Time taken = 6.28 | Train loss = 0.0000086 | Val loss =  0.1220016\n",
      "Epoch 74: Time taken = 6.28 | Train loss = 0.0000075 | Val loss =  0.0958220\n",
      "Epoch 80: Time taken = 6.27 | Train loss = 0.0000087 | Val loss =  0.1232861\n",
      "Epoch 86: Time taken = 6.27 | Train loss = 0.0000082 | Val loss =  0.0920511\n",
      "Epoch 90: Time taken = 6.27 | Train loss = 0.0000076 | Val loss =  0.1015724\n",
      "Epoch 100: Time taken = 6.28 | Train loss = 0.0000081 | Val loss =  0.1202990\n",
      "Epoch 110: Time taken = 6.27 | Train loss = 0.0000080 | Val loss =  0.1074850\n",
      "Epoch 120: Time taken = 6.27 | Train loss = 0.0000081 | Val loss =  0.1086567\n",
      "Epoch 129: Time taken = 6.28 | Train loss = 0.0000074 | Val loss =  0.0909728\n",
      "Epoch 130: Time taken = 6.28 | Train loss = 0.0000081 | Val loss =  0.1078698\n",
      "Epoch 140: Time taken = 6.29 | Train loss = 0.0000080 | Val loss =  0.1121984\n",
      "Epoch 150: Time taken = 6.28 | Train loss = 0.0000070 | Val loss =  0.0991130\n",
      "Epoch 160: Time taken = 6.27 | Train loss = 0.0000076 | Val loss =  0.1025873\n",
      "Epoch 161: Time taken = 6.28 | Train loss = 0.0000072 | Val loss =  0.0876805\n",
      "Epoch 170: Time taken = 6.28 | Train loss = 0.0000069 | Val loss =  0.0882603\n",
      "Epoch 180: Time taken = 6.27 | Train loss = 0.0000073 | Val loss =  0.0841453\n",
      "Epoch 184: Time taken = 6.26 | Train loss = 0.0000073 | Val loss =  0.0828908\n",
      "Epoch 190: Time taken = 6.28 | Train loss = 0.0000071 | Val loss =  0.0868179\n",
      "Epoch 192: Time taken = 6.28 | Train loss = 0.0000069 | Val loss =  0.0805608\n",
      "Epoch 200: Time taken = 6.26 | Train loss = 0.0000069 | Val loss =  0.0828996\n",
      "Best Validation MSE: 0.0805608\n",
      "IMPROVED VALIDATION MSE\n",
      "\n",
      "Epoch 10: Time taken = 6.27 | Train loss = 0.0000069 | Val loss =  0.1032384\n",
      "Epoch 20: Time taken = 6.27 | Train loss = 0.0000070 | Val loss =  0.0994706\n",
      "Epoch 30: Time taken = 6.28 | Train loss = 0.0000068 | Val loss =  0.0869319\n",
      "Epoch 40: Time taken = 6.27 | Train loss = 0.0000063 | Val loss =  0.0929983\n",
      "Epoch 50: Time taken = 6.27 | Train loss = 0.0000068 | Val loss =  0.1040837\n",
      "EARLY STOPPING. Epoch 52: Train loss = 0.0000063 | Val loss =  0.0922477\n",
      "Best Validation MSE: 0.0707140\n",
      "IMPROVED VALIDATION MSE\n",
      "\n",
      "Total time: 3974.38\n",
      "Complete. Time taken: 3977.64s\n",
      "Testing complete. Time taken: 1.32\n"
     ]
    }
   ],
   "source": [
    "run_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1bcbde-a902-403b-8e4b-7a33bb214bf6",
   "metadata": {},
   "source": [
    "## 4.2 Seed 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "234ce9db-336a-4605-935c-509ca931f01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backpropogation start\n",
      "\n",
      "Epoch 10: Time taken = 6.17 | Train loss = 0.0003976 | Val loss =  0.6610633\n",
      "Epoch 20: Time taken = 6.17 | Train loss = 0.0001653 | Val loss =  0.5161388\n",
      "Epoch 30: Time taken = 6.17 | Train loss = 0.0000940 | Val loss =  0.4461673\n",
      "Epoch 40: Time taken = 6.17 | Train loss = 0.0000687 | Val loss =  0.3789758\n",
      "Epoch 50: Time taken = 6.16 | Train loss = 0.0000625 | Val loss =  0.3145964\n",
      "Epoch 52: Time taken = 6.16 | Train loss = 0.0000576 | Val loss =  0.3086750\n",
      "Epoch 53: Time taken = 6.17 | Train loss = 0.0000458 | Val loss =  0.2977281\n",
      "Epoch 59: Time taken = 6.17 | Train loss = 0.0000437 | Val loss =  0.2962177\n",
      "Epoch 60: Time taken = 6.17 | Train loss = 0.0000406 | Val loss =  0.3437899\n",
      "Epoch 63: Time taken = 6.17 | Train loss = 0.0000343 | Val loss =  0.2595979\n",
      "Epoch 64: Time taken = 6.17 | Train loss = 0.0000468 | Val loss =  0.2578274\n",
      "Epoch 68: Time taken = 6.17 | Train loss = 0.0000333 | Val loss =  0.2477776\n",
      "Epoch 70: Time taken = 6.17 | Train loss = 0.0000382 | Val loss =  0.2733217\n",
      "Epoch 76: Time taken = 6.18 | Train loss = 0.0000296 | Val loss =  0.2461102\n",
      "Epoch 80: Time taken = 6.18 | Train loss = 0.0000297 | Val loss =  0.2718782\n",
      "Epoch 81: Time taken = 6.18 | Train loss = 0.0000325 | Val loss =  0.2189089\n",
      "Epoch 87: Time taken = 6.17 | Train loss = 0.0000325 | Val loss =  0.2149984\n",
      "Epoch 90: Time taken = 6.17 | Train loss = 0.0000286 | Val loss =  0.2729653\n",
      "Epoch 92: Time taken = 6.18 | Train loss = 0.0000255 | Val loss =  0.1871996\n",
      "Epoch 100: Time taken = 6.17 | Train loss = 0.0000233 | Val loss =  0.2289263\n",
      "Epoch 110: Time taken = 6.18 | Train loss = 0.0000217 | Val loss =  0.2111348\n",
      "Epoch 118: Time taken = 6.18 | Train loss = 0.0000218 | Val loss =  0.1863749\n",
      "Epoch 120: Time taken = 6.18 | Train loss = 0.0000224 | Val loss =  0.2246676\n",
      "Epoch 121: Time taken = 6.18 | Train loss = 0.0000222 | Val loss =  0.1862139\n",
      "Epoch 128: Time taken = 6.18 | Train loss = 0.0000228 | Val loss =  0.1604717\n",
      "Epoch 130: Time taken = 6.17 | Train loss = 0.0000201 | Val loss =  0.1766621\n",
      "Epoch 140: Time taken = 6.17 | Train loss = 0.0000175 | Val loss =  0.1939190\n",
      "Epoch 149: Time taken = 6.16 | Train loss = 0.0000170 | Val loss =  0.1561128\n",
      "Epoch 150: Time taken = 6.17 | Train loss = 0.0000192 | Val loss =  0.1685942\n",
      "Epoch 160: Time taken = 6.18 | Train loss = 0.0000154 | Val loss =  0.1591686\n",
      "Epoch 162: Time taken = 6.18 | Train loss = 0.0000147 | Val loss =  0.1541366\n",
      "Epoch 165: Time taken = 6.17 | Train loss = 0.0000135 | Val loss =  0.1434615\n",
      "Epoch 170: Time taken = 6.17 | Train loss = 0.0000176 | Val loss =  0.1667073\n",
      "Epoch 180: Time taken = 6.18 | Train loss = 0.0000125 | Val loss =  0.1645641\n",
      "Epoch 181: Time taken = 6.17 | Train loss = 0.0000168 | Val loss =  0.1391626\n",
      "Epoch 188: Time taken = 6.18 | Train loss = 0.0000144 | Val loss =  0.1383858\n",
      "Epoch 190: Time taken = 6.17 | Train loss = 0.0000133 | Val loss =  0.1876386\n",
      "Epoch 196: Time taken = 6.17 | Train loss = 0.0000137 | Val loss =  0.1314728\n",
      "Epoch 200: Time taken = 6.17 | Train loss = 0.0000151 | Val loss =  0.1465164\n",
      "Epoch 210: Time taken = 6.18 | Train loss = 0.0000124 | Val loss =  0.1345817\n",
      "Epoch 220: Time taken = 6.17 | Train loss = 0.0000137 | Val loss =  0.1503476\n",
      "Epoch 226: Time taken = 6.17 | Train loss = 0.0000127 | Val loss =  0.1308630\n",
      "Epoch 230: Time taken = 6.17 | Train loss = 0.0000133 | Val loss =  0.1349413\n",
      "Epoch 240: Time taken = 6.17 | Train loss = 0.0000110 | Val loss =  0.1409034\n",
      "Epoch 243: Time taken = 6.17 | Train loss = 0.0000113 | Val loss =  0.1247165\n",
      "Epoch 250: Time taken = 6.17 | Train loss = 0.0000112 | Val loss =  0.1344191\n",
      "Epoch 252: Time taken = 6.17 | Train loss = 0.0000107 | Val loss =  0.1189930\n",
      "Epoch 260: Time taken = 6.17 | Train loss = 0.0000100 | Val loss =  0.1422110\n",
      "Epoch 270: Time taken = 6.17 | Train loss = 0.0000096 | Val loss =  0.1181840\n",
      "Epoch 280: Time taken = 6.18 | Train loss = 0.0000102 | Val loss =  0.1393744\n",
      "Epoch 288: Time taken = 6.18 | Train loss = 0.0000098 | Val loss =  0.1177970\n",
      "Epoch 290: Time taken = 6.18 | Train loss = 0.0000096 | Val loss =  0.1189755\n",
      "Epoch 291: Time taken = 6.17 | Train loss = 0.0000093 | Val loss =  0.1153803\n",
      "Epoch 298: Time taken = 6.18 | Train loss = 0.0000088 | Val loss =  0.1143586\n",
      "Epoch 300: Time taken = 6.18 | Train loss = 0.0000087 | Val loss =  0.1283010\n",
      "Epoch 304: Time taken = 6.18 | Train loss = 0.0000087 | Val loss =  0.1073203\n",
      "Epoch 310: Time taken = 6.17 | Train loss = 0.0000088 | Val loss =  0.1313512\n",
      "Epoch 320: Time taken = 6.17 | Train loss = 0.0000097 | Val loss =  0.1302599\n",
      "Epoch 322: Time taken = 6.17 | Train loss = 0.0000085 | Val loss =  0.1070926\n",
      "Epoch 330: Time taken = 6.18 | Train loss = 0.0000098 | Val loss =  0.1133763\n",
      "Epoch 336: Time taken = 6.17 | Train loss = 0.0000086 | Val loss =  0.1052833\n",
      "Epoch 337: Time taken = 6.17 | Train loss = 0.0000087 | Val loss =  0.1046433\n",
      "Epoch 338: Time taken = 6.17 | Train loss = 0.0000088 | Val loss =  0.1041894\n",
      "Epoch 340: Time taken = 6.17 | Train loss = 0.0000083 | Val loss =  0.1163181\n",
      "Epoch 343: Time taken = 6.18 | Train loss = 0.0000079 | Val loss =  0.1026768\n",
      "Epoch 350: Time taken = 6.17 | Train loss = 0.0000082 | Val loss =  0.1116323\n",
      "Epoch 360: Time taken = 6.18 | Train loss = 0.0000078 | Val loss =  0.1017474\n",
      "Epoch 370: Time taken = 6.19 | Train loss = 0.0000072 | Val loss =  0.1159900\n",
      "Epoch 380: Time taken = 6.15 | Train loss = 0.0000081 | Val loss =  0.1126967\n",
      "Epoch 385: Time taken = 6.16 | Train loss = 0.0000079 | Val loss =  0.0983684\n",
      "Epoch 390: Time taken = 6.15 | Train loss = 0.0000086 | Val loss =  0.1123709\n",
      "Epoch 400: Time taken = 6.18 | Train loss = 0.0000073 | Val loss =  0.1003590\n",
      "Best Validation MSE: 0.0983684\n",
      "IMPROVED VALIDATION MSE\n",
      "\n",
      "Epoch 10: Time taken = 6.18 | Train loss = 0.0000079 | Val loss =  0.0998680\n",
      "Epoch 20: Time taken = 6.19 | Train loss = 0.0000078 | Val loss =  0.1141748\n",
      "Epoch 30: Time taken = 6.18 | Train loss = 0.0000075 | Val loss =  0.1071656\n",
      "Epoch 40: Time taken = 6.17 | Train loss = 0.0000079 | Val loss =  0.0953915\n",
      "Epoch 50: Time taken = 6.19 | Train loss = 0.0000079 | Val loss =  0.1159269\n",
      "EARLY STOPPING. Epoch 51: Train loss = 0.0000071 | Val loss =  0.0956390\n",
      "Best Validation MSE: 0.0825434\n",
      "IMPROVED VALIDATION MSE\n",
      "\n",
      "Epoch 10: Time taken = 6.18 | Train loss = 0.0000079 | Val loss =  0.1037971\n",
      "Epoch 20: Time taken = 6.17 | Train loss = 0.0000078 | Val loss =  0.1160438\n",
      "Epoch 30: Time taken = 6.17 | Train loss = 0.0000073 | Val loss =  0.1166568\n",
      "Epoch 40: Time taken = 6.19 | Train loss = 0.0000075 | Val loss =  0.1067228\n",
      "Epoch 50: Time taken = 6.18 | Train loss = 0.0000075 | Val loss =  0.1008860\n",
      "EARLY STOPPING. Epoch 51: Train loss = 0.0000066 | Val loss =  0.0920171\n",
      "Best Validation MSE: 0.0788020\n",
      "IMPROVED VALIDATION MSE\n",
      "\n",
      "Epoch 10: Time taken = 6.19 | Train loss = 0.0000076 | Val loss =  0.1087747\n",
      "Epoch 20: Time taken = 6.20 | Train loss = 0.0000078 | Val loss =  0.1057410\n",
      "Epoch 30: Time taken = 6.18 | Train loss = 0.0000069 | Val loss =  0.1007082\n",
      "Epoch 40: Time taken = 6.19 | Train loss = 0.0000081 | Val loss =  0.1056344\n",
      "Epoch 50: Time taken = 6.20 | Train loss = 0.0000077 | Val loss =  0.0951246\n",
      "EARLY STOPPING. Epoch 51: Train loss = 0.0000071 | Val loss =  0.1104427\n",
      "Best Validation MSE: 0.0858293\n",
      "\n",
      "Total time: 3418.47\n",
      "Complete. Time taken: 3418.49s\n",
      "Testing complete. Time taken: 1.16\n"
     ]
    }
   ],
   "source": [
    "run_seed(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abf4d4d-b41c-4b37-afd7-947a70837ff8",
   "metadata": {},
   "source": [
    "## 4.3 Seed 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f751f451-8373-4ae3-b8b3-594b344fa18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backpropogation start\n",
      "\n",
      "Epoch 10: Time taken = 6.27 | Train loss = 0.0004073 | Val loss =  0.6422133\n",
      "Epoch 20: Time taken = 6.26 | Train loss = 0.0001673 | Val loss =  0.5703543\n",
      "Epoch 30: Time taken = 6.26 | Train loss = 0.0000923 | Val loss =  0.4546742\n",
      "Epoch 40: Time taken = 6.25 | Train loss = 0.0000677 | Val loss =  0.3779160\n",
      "Epoch 50: Time taken = 6.26 | Train loss = 0.0000509 | Val loss =  0.3178094\n",
      "Epoch 51: Time taken = 6.26 | Train loss = 0.0000541 | Val loss =  0.3088782\n",
      "Epoch 52: Time taken = 6.26 | Train loss = 0.0000473 | Val loss =  0.3048953\n",
      "Epoch 53: Time taken = 6.26 | Train loss = 0.0000487 | Val loss =  0.3043582\n",
      "Epoch 56: Time taken = 6.25 | Train loss = 0.0000465 | Val loss =  0.2978412\n",
      "Epoch 59: Time taken = 6.26 | Train loss = 0.0000379 | Val loss =  0.2766347\n",
      "Epoch 60: Time taken = 6.26 | Train loss = 0.0000451 | Val loss =  0.2498205\n",
      "Epoch 64: Time taken = 6.26 | Train loss = 0.0000358 | Val loss =  0.2475344\n",
      "Epoch 70: Time taken = 6.26 | Train loss = 0.0000369 | Val loss =  0.2506974\n",
      "Epoch 74: Time taken = 6.27 | Train loss = 0.0000333 | Val loss =  0.2430925\n",
      "Epoch 78: Time taken = 6.26 | Train loss = 0.0000330 | Val loss =  0.2301580\n",
      "Epoch 80: Time taken = 6.26 | Train loss = 0.0000289 | Val loss =  0.2533680\n",
      "Epoch 85: Time taken = 6.26 | Train loss = 0.0000299 | Val loss =  0.2234534\n",
      "Epoch 86: Time taken = 6.26 | Train loss = 0.0000312 | Val loss =  0.2160641\n",
      "Epoch 87: Time taken = 6.25 | Train loss = 0.0000269 | Val loss =  0.2020629\n",
      "Epoch 89: Time taken = 6.27 | Train loss = 0.0000259 | Val loss =  0.1991639\n",
      "Epoch 90: Time taken = 6.26 | Train loss = 0.0000333 | Val loss =  0.2138886\n",
      "Epoch 99: Time taken = 6.26 | Train loss = 0.0000245 | Val loss =  0.1904418\n",
      "Epoch 100: Time taken = 6.25 | Train loss = 0.0000265 | Val loss =  0.2381558\n",
      "Epoch 109: Time taken = 6.26 | Train loss = 0.0000214 | Val loss =  0.1778382\n",
      "Epoch 110: Time taken = 6.26 | Train loss = 0.0000288 | Val loss =  0.2213933\n",
      "Epoch 120: Time taken = 6.26 | Train loss = 0.0000234 | Val loss =  0.2039444\n",
      "Epoch 121: Time taken = 6.27 | Train loss = 0.0000209 | Val loss =  0.1710798\n",
      "Epoch 130: Time taken = 6.27 | Train loss = 0.0000195 | Val loss =  0.1980294\n",
      "Epoch 136: Time taken = 6.26 | Train loss = 0.0000181 | Val loss =  0.1686429\n",
      "Epoch 140: Time taken = 6.26 | Train loss = 0.0000202 | Val loss =  0.1801648\n",
      "Epoch 141: Time taken = 6.26 | Train loss = 0.0000191 | Val loss =  0.1608647\n",
      "Epoch 150: Time taken = 6.27 | Train loss = 0.0000202 | Val loss =  0.1697464\n",
      "Epoch 160: Time taken = 6.26 | Train loss = 0.0000192 | Val loss =  0.2058588\n",
      "Epoch 166: Time taken = 6.26 | Train loss = 0.0000154 | Val loss =  0.1472718\n",
      "Epoch 170: Time taken = 6.26 | Train loss = 0.0000184 | Val loss =  0.1694434\n",
      "Epoch 180: Time taken = 6.26 | Train loss = 0.0000152 | Val loss =  0.1787395\n",
      "Epoch 181: Time taken = 6.26 | Train loss = 0.0000146 | Val loss =  0.1411797\n",
      "Epoch 185: Time taken = 6.26 | Train loss = 0.0000143 | Val loss =  0.1337130\n",
      "Epoch 190: Time taken = 6.26 | Train loss = 0.0000169 | Val loss =  0.1638801\n",
      "Epoch 200: Time taken = 6.26 | Train loss = 0.0000139 | Val loss =  0.1542631\n",
      "Epoch 203: Time taken = 6.26 | Train loss = 0.0000117 | Val loss =  0.1333668\n",
      "Epoch 210: Time taken = 6.25 | Train loss = 0.0000133 | Val loss =  0.1514925\n",
      "Epoch 213: Time taken = 6.26 | Train loss = 0.0000128 | Val loss =  0.1153465\n",
      "Epoch 220: Time taken = 6.26 | Train loss = 0.0000124 | Val loss =  0.1352545\n",
      "Epoch 230: Time taken = 6.26 | Train loss = 0.0000141 | Val loss =  0.1613884\n",
      "Epoch 240: Time taken = 6.26 | Train loss = 0.0000120 | Val loss =  0.1390639\n",
      "Epoch 250: Time taken = 6.27 | Train loss = 0.0000119 | Val loss =  0.1244947\n",
      "Epoch 260: Time taken = 6.25 | Train loss = 0.0000108 | Val loss =  0.1240278\n",
      "EARLY STOPPING. Epoch 263: Train loss = 0.0000122 | Val loss =  0.1478968\n",
      "Best Validation MSE: 0.1153465\n",
      "IMPROVED VALIDATION MSE\n",
      "\n",
      "Epoch 10: Time taken = 6.25 | Train loss = 0.0000118 | Val loss =  0.1572293\n",
      "Epoch 20: Time taken = 6.26 | Train loss = 0.0000104 | Val loss =  0.1319779\n",
      "Epoch 30: Time taken = 6.25 | Train loss = 0.0000117 | Val loss =  0.1450094\n",
      "Epoch 40: Time taken = 6.27 | Train loss = 0.0000125 | Val loss =  0.1452313\n",
      "Epoch 50: Time taken = 6.27 | Train loss = 0.0000107 | Val loss =  0.1286275\n",
      "Epoch 60: Time taken = 6.26 | Train loss = 0.0000111 | Val loss =  0.1397744\n",
      "Epoch 69: Time taken = 6.26 | Train loss = 0.0000097 | Val loss =  0.1135342\n",
      "Epoch 70: Time taken = 6.26 | Train loss = 0.0000103 | Val loss =  0.1200475\n",
      "Epoch 80: Time taken = 6.26 | Train loss = 0.0000106 | Val loss =  0.1300339\n",
      "Epoch 81: Time taken = 6.26 | Train loss = 0.0000091 | Val loss =  0.0989234\n",
      "Epoch 90: Time taken = 6.26 | Train loss = 0.0000092 | Val loss =  0.1257044\n",
      "Epoch 100: Time taken = 6.26 | Train loss = 0.0000090 | Val loss =  0.1208346\n",
      "Epoch 110: Time taken = 6.25 | Train loss = 0.0000093 | Val loss =  0.1311884\n",
      "Epoch 117: Time taken = 6.25 | Train loss = 0.0000083 | Val loss =  0.0960494\n",
      "Epoch 120: Time taken = 6.25 | Train loss = 0.0000100 | Val loss =  0.1199230\n",
      "Epoch 130: Time taken = 6.26 | Train loss = 0.0000088 | Val loss =  0.1161623\n",
      "Epoch 140: Time taken = 6.26 | Train loss = 0.0000080 | Val loss =  0.1188712\n",
      "Epoch 150: Time taken = 6.26 | Train loss = 0.0000078 | Val loss =  0.1149905\n",
      "Epoch 160: Time taken = 6.26 | Train loss = 0.0000080 | Val loss =  0.1213968\n",
      "Epoch 163: Time taken = 6.28 | Train loss = 0.0000073 | Val loss =  0.0872570\n",
      "Epoch 170: Time taken = 6.26 | Train loss = 0.0000083 | Val loss =  0.1160516\n",
      "Epoch 180: Time taken = 6.26 | Train loss = 0.0000078 | Val loss =  0.0958735\n",
      "Epoch 190: Time taken = 6.25 | Train loss = 0.0000072 | Val loss =  0.0949811\n",
      "Epoch 200: Time taken = 6.26 | Train loss = 0.0000073 | Val loss =  0.0903018\n",
      "Best Validation MSE: 0.0872570\n",
      "IMPROVED VALIDATION MSE\n",
      "\n",
      "Epoch 10: Time taken = 6.26 | Train loss = 0.0000074 | Val loss =  0.1069916\n",
      "Epoch 20: Time taken = 6.26 | Train loss = 0.0000085 | Val loss =  0.1035316\n",
      "Epoch 30: Time taken = 6.27 | Train loss = 0.0000069 | Val loss =  0.1049302\n",
      "Epoch 40: Time taken = 6.27 | Train loss = 0.0000082 | Val loss =  0.1072889\n",
      "Epoch 50: Time taken = 6.27 | Train loss = 0.0000075 | Val loss =  0.0975403\n",
      "EARLY STOPPING. Epoch 51: Train loss = 0.0000077 | Val loss =  0.1145806\n",
      "Best Validation MSE: 0.0773965\n",
      "IMPROVED VALIDATION MSE\n",
      "\n",
      "Epoch 10: Time taken = 6.27 | Train loss = 0.0000076 | Val loss =  0.0989564\n",
      "Epoch 20: Time taken = 6.26 | Train loss = 0.0000082 | Val loss =  0.1060290\n",
      "Epoch 30: Time taken = 6.25 | Train loss = 0.0000073 | Val loss =  0.1043617\n",
      "Epoch 40: Time taken = 6.25 | Train loss = 0.0000076 | Val loss =  0.0992078\n",
      "Epoch 50: Time taken = 6.25 | Train loss = 0.0000077 | Val loss =  0.1069399\n",
      "EARLY STOPPING. Epoch 51: Train loss = 0.0000070 | Val loss =  0.0984130\n",
      "Best Validation MSE: 0.0792718\n",
      "\n",
      "Total time: 3539.73\n",
      "Complete. Time taken: 3539.75s\n",
      "Testing complete. Time taken: 1.15\n"
     ]
    }
   ],
   "source": [
    "run_seed(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99791ee8-6d4d-49a2-99b5-48d06755a32d",
   "metadata": {},
   "source": [
    "## 4.4 Seed 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6398e9f5-b404-4029-8d31-e839467929d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backpropogation start\n",
      "\n",
      "Epoch 10: Time taken = 6.16 | Train loss = 0.0003946 | Val loss =  0.6631701\n",
      "Epoch 20: Time taken = 6.16 | Train loss = 0.0001783 | Val loss =  0.5340534\n",
      "Epoch 30: Time taken = 6.18 | Train loss = 0.0000928 | Val loss =  0.4557289\n",
      "Epoch 40: Time taken = 6.19 | Train loss = 0.0000723 | Val loss =  0.3836211\n",
      "Epoch 50: Time taken = 6.18 | Train loss = 0.0000545 | Val loss =  0.3339385\n",
      "Epoch 51: Time taken = 6.17 | Train loss = 0.0000506 | Val loss =  0.3243167\n",
      "Epoch 54: Time taken = 6.19 | Train loss = 0.0000517 | Val loss =  0.3112192\n",
      "Epoch 58: Time taken = 6.17 | Train loss = 0.0000440 | Val loss =  0.2910033\n",
      "Epoch 59: Time taken = 6.18 | Train loss = 0.0000458 | Val loss =  0.2662245\n",
      "Epoch 60: Time taken = 6.19 | Train loss = 0.0000423 | Val loss =  0.2942129\n",
      "Epoch 65: Time taken = 6.18 | Train loss = 0.0000379 | Val loss =  0.2553405\n",
      "Epoch 67: Time taken = 6.18 | Train loss = 0.0000353 | Val loss =  0.2491886\n",
      "Epoch 70: Time taken = 6.19 | Train loss = 0.0000358 | Val loss =  0.3368106\n",
      "Epoch 71: Time taken = 6.18 | Train loss = 0.0000365 | Val loss =  0.2440623\n",
      "Epoch 75: Time taken = 6.18 | Train loss = 0.0000315 | Val loss =  0.2242508\n",
      "Epoch 80: Time taken = 6.18 | Train loss = 0.0000305 | Val loss =  0.2207221\n",
      "Epoch 84: Time taken = 6.18 | Train loss = 0.0000307 | Val loss =  0.2086459\n",
      "Epoch 90: Time taken = 6.18 | Train loss = 0.0000246 | Val loss =  0.2471483\n",
      "Epoch 100: Time taken = 6.17 | Train loss = 0.0000270 | Val loss =  0.2110066\n",
      "Epoch 108: Time taken = 6.18 | Train loss = 0.0000219 | Val loss =  0.1902844\n",
      "Epoch 110: Time taken = 6.18 | Train loss = 0.0000215 | Val loss =  0.2460110\n",
      "Epoch 118: Time taken = 6.18 | Train loss = 0.0000199 | Val loss =  0.1885923\n",
      "Epoch 120: Time taken = 6.19 | Train loss = 0.0000206 | Val loss =  0.1864408\n",
      "Epoch 126: Time taken = 6.19 | Train loss = 0.0000197 | Val loss =  0.1762148\n",
      "Epoch 130: Time taken = 6.19 | Train loss = 0.0000167 | Val loss =  0.1868680\n",
      "Epoch 140: Time taken = 6.19 | Train loss = 0.0000165 | Val loss =  0.1756310\n",
      "Epoch 150: Time taken = 6.19 | Train loss = 0.0000207 | Val loss =  0.1935085\n",
      "Epoch 151: Time taken = 6.19 | Train loss = 0.0000161 | Val loss =  0.1474942\n",
      "Epoch 160: Time taken = 6.19 | Train loss = 0.0000159 | Val loss =  0.1821020\n",
      "Epoch 170: Time taken = 6.16 | Train loss = 0.0000183 | Val loss =  0.1675641\n",
      "Epoch 180: Time taken = 6.16 | Train loss = 0.0000136 | Val loss =  0.1654283\n",
      "Epoch 190: Time taken = 6.16 | Train loss = 0.0000136 | Val loss =  0.1498567\n",
      "Epoch 192: Time taken = 6.16 | Train loss = 0.0000135 | Val loss =  0.1417141\n",
      "Epoch 200: Time taken = 6.16 | Train loss = 0.0000138 | Val loss =  0.1808985\n",
      "Epoch 204: Time taken = 6.16 | Train loss = 0.0000133 | Val loss =  0.1416024\n",
      "Epoch 205: Time taken = 6.16 | Train loss = 0.0000132 | Val loss =  0.1412632\n",
      "Epoch 210: Time taken = 6.16 | Train loss = 0.0000141 | Val loss =  0.1446107\n",
      "Epoch 217: Time taken = 6.15 | Train loss = 0.0000123 | Val loss =  0.1252368\n",
      "Epoch 220: Time taken = 6.16 | Train loss = 0.0000134 | Val loss =  0.1537628\n",
      "Epoch 230: Time taken = 6.15 | Train loss = 0.0000132 | Val loss =  0.1387701\n",
      "Epoch 238: Time taken = 6.16 | Train loss = 0.0000114 | Val loss =  0.1224298\n",
      "Epoch 240: Time taken = 6.16 | Train loss = 0.0000129 | Val loss =  0.1569759\n",
      "Epoch 247: Time taken = 6.16 | Train loss = 0.0000100 | Val loss =  0.1213443\n",
      "Epoch 250: Time taken = 6.16 | Train loss = 0.0000129 | Val loss =  0.1413649\n",
      "Epoch 253: Time taken = 6.16 | Train loss = 0.0000102 | Val loss =  0.1210079\n",
      "Epoch 260: Time taken = 6.16 | Train loss = 0.0000108 | Val loss =  0.1372004\n",
      "Epoch 270: Time taken = 6.16 | Train loss = 0.0000091 | Val loss =  0.1102099\n",
      "Epoch 280: Time taken = 6.16 | Train loss = 0.0000115 | Val loss =  0.1271963\n",
      "Epoch 290: Time taken = 6.16 | Train loss = 0.0000099 | Val loss =  0.1272347\n",
      "Epoch 300: Time taken = 6.16 | Train loss = 0.0000102 | Val loss =  0.1366618\n",
      "Epoch 310: Time taken = 6.16 | Train loss = 0.0000100 | Val loss =  0.1314125\n",
      "Epoch 316: Time taken = 6.15 | Train loss = 0.0000088 | Val loss =  0.1100686\n",
      "Epoch 320: Time taken = 6.16 | Train loss = 0.0000091 | Val loss =  0.1348592\n",
      "Epoch 326: Time taken = 6.16 | Train loss = 0.0000098 | Val loss =  0.1069752\n",
      "Epoch 328: Time taken = 6.17 | Train loss = 0.0000091 | Val loss =  0.1062935\n",
      "Epoch 330: Time taken = 6.16 | Train loss = 0.0000087 | Val loss =  0.1223298\n",
      "Epoch 332: Time taken = 6.16 | Train loss = 0.0000088 | Val loss =  0.1022776\n",
      "Epoch 340: Time taken = 6.16 | Train loss = 0.0000084 | Val loss =  0.1121678\n",
      "Epoch 350: Time taken = 6.16 | Train loss = 0.0000087 | Val loss =  0.1260228\n",
      "Epoch 357: Time taken = 6.16 | Train loss = 0.0000085 | Val loss =  0.1003966\n",
      "Epoch 360: Time taken = 6.16 | Train loss = 0.0000084 | Val loss =  0.1100252\n",
      "Epoch 370: Time taken = 6.15 | Train loss = 0.0000080 | Val loss =  0.1101924\n",
      "Epoch 372: Time taken = 6.15 | Train loss = 0.0000080 | Val loss =  0.1003667\n",
      "Epoch 380: Time taken = 6.15 | Train loss = 0.0000085 | Val loss =  0.1216357\n",
      "Epoch 385: Time taken = 6.15 | Train loss = 0.0000078 | Val loss =  0.1003648\n",
      "Epoch 390: Time taken = 6.16 | Train loss = 0.0000082 | Val loss =  0.1272528\n",
      "Epoch 396: Time taken = 6.15 | Train loss = 0.0000078 | Val loss =  0.0884643\n",
      "Epoch 400: Time taken = 6.15 | Train loss = 0.0000070 | Val loss =  0.0892500\n",
      "Best Validation MSE: 0.0884643\n",
      "IMPROVED VALIDATION MSE\n",
      "\n",
      "Epoch 10: Time taken = 6.17 | Train loss = 0.0000076 | Val loss =  0.1143430\n",
      "Epoch 20: Time taken = 6.17 | Train loss = 0.0000078 | Val loss =  0.1084014\n",
      "Epoch 30: Time taken = 6.17 | Train loss = 0.0000078 | Val loss =  0.1121228\n",
      "Epoch 40: Time taken = 6.17 | Train loss = 0.0000076 | Val loss =  0.0940132\n",
      "Epoch 50: Time taken = 6.17 | Train loss = 0.0000065 | Val loss =  0.1032023\n",
      "EARLY STOPPING. Epoch 51: Train loss = 0.0000078 | Val loss =  0.1035499\n",
      "Best Validation MSE: 0.0782763\n",
      "IMPROVED VALIDATION MSE\n",
      "\n",
      "Epoch 10: Time taken = 6.16 | Train loss = 0.0000077 | Val loss =  0.1008505\n",
      "Epoch 20: Time taken = 6.17 | Train loss = 0.0000076 | Val loss =  0.1017928\n",
      "Epoch 30: Time taken = 6.16 | Train loss = 0.0000069 | Val loss =  0.1027223\n",
      "Epoch 40: Time taken = 6.17 | Train loss = 0.0000081 | Val loss =  0.1261410\n",
      "Epoch 50: Time taken = 6.17 | Train loss = 0.0000079 | Val loss =  0.1072977\n",
      "EARLY STOPPING. Epoch 51: Train loss = 0.0000072 | Val loss =  0.0975904\n",
      "Best Validation MSE: 0.0632917\n",
      "IMPROVED VALIDATION MSE\n",
      "\n",
      "Epoch 10: Time taken = 6.16 | Train loss = 0.0000077 | Val loss =  0.1231398\n",
      "Epoch 20: Time taken = 6.16 | Train loss = 0.0000076 | Val loss =  0.1029173\n",
      "Epoch 30: Time taken = 6.16 | Train loss = 0.0000080 | Val loss =  0.1117991\n",
      "Epoch 40: Time taken = 6.16 | Train loss = 0.0000070 | Val loss =  0.0997336\n",
      "Epoch 50: Time taken = 6.16 | Train loss = 0.0000069 | Val loss =  0.1047147\n",
      "EARLY STOPPING. Epoch 51: Train loss = 0.0000084 | Val loss =  0.1126581\n",
      "Best Validation MSE: 0.0722687\n",
      "\n",
      "Total time: 3412.68\n",
      "Complete. Time taken: 3412.70s\n",
      "Testing complete. Time taken: 1.09\n"
     ]
    }
   ],
   "source": [
    "run_seed(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44cb3d9-6d9b-4bc9-bfae-2f56f7a8848b",
   "metadata": {},
   "source": [
    "## 4.5 Seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c531e8d9-b83e-4a1e-9307-71e37e3049a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backpropogation start\n",
      "\n",
      "Epoch 10: Time taken = 6.15 | Train loss = 0.0003910 | Val loss =  0.6467596\n",
      "Epoch 20: Time taken = 6.17 | Train loss = 0.0001614 | Val loss =  0.5453808\n",
      "Epoch 30: Time taken = 6.18 | Train loss = 0.0001061 | Val loss =  0.5463936\n",
      "Epoch 40: Time taken = 6.17 | Train loss = 0.0000716 | Val loss =  0.4025752\n",
      "Epoch 50: Time taken = 6.17 | Train loss = 0.0000534 | Val loss =  0.3426100\n",
      "Epoch 52: Time taken = 6.17 | Train loss = 0.0000526 | Val loss =  0.3067254\n",
      "Epoch 55: Time taken = 6.18 | Train loss = 0.0000433 | Val loss =  0.2814210\n",
      "Epoch 60: Time taken = 6.17 | Train loss = 0.0000455 | Val loss =  0.3335185\n",
      "Epoch 64: Time taken = 6.17 | Train loss = 0.0000396 | Val loss =  0.2681451\n",
      "Epoch 67: Time taken = 6.18 | Train loss = 0.0000397 | Val loss =  0.2619560\n",
      "Epoch 70: Time taken = 6.18 | Train loss = 0.0000348 | Val loss =  0.2714801\n",
      "Epoch 75: Time taken = 6.18 | Train loss = 0.0000310 | Val loss =  0.2409087\n",
      "Epoch 77: Time taken = 6.18 | Train loss = 0.0000302 | Val loss =  0.2408399\n",
      "Epoch 80: Time taken = 6.18 | Train loss = 0.0000320 | Val loss =  0.2373666\n",
      "Epoch 83: Time taken = 6.18 | Train loss = 0.0000313 | Val loss =  0.2189378\n",
      "Epoch 87: Time taken = 6.18 | Train loss = 0.0000291 | Val loss =  0.2159054\n",
      "Epoch 90: Time taken = 6.18 | Train loss = 0.0000276 | Val loss =  0.2542958\n",
      "Epoch 93: Time taken = 6.18 | Train loss = 0.0000311 | Val loss =  0.2085958\n",
      "Epoch 95: Time taken = 6.19 | Train loss = 0.0000268 | Val loss =  0.2022888\n",
      "Epoch 98: Time taken = 6.18 | Train loss = 0.0000274 | Val loss =  0.1996591\n",
      "Epoch 100: Time taken = 6.18 | Train loss = 0.0000281 | Val loss =  0.1995790\n",
      "Epoch 101: Time taken = 6.18 | Train loss = 0.0000236 | Val loss =  0.1940900\n",
      "Epoch 103: Time taken = 6.18 | Train loss = 0.0000236 | Val loss =  0.1853248\n",
      "Epoch 110: Time taken = 6.18 | Train loss = 0.0000238 | Val loss =  0.2464011\n",
      "Epoch 112: Time taken = 6.18 | Train loss = 0.0000214 | Val loss =  0.1847023\n",
      "Epoch 120: Time taken = 6.18 | Train loss = 0.0000244 | Val loss =  0.2187738\n",
      "Epoch 127: Time taken = 6.18 | Train loss = 0.0000200 | Val loss =  0.1802702\n",
      "Epoch 130: Time taken = 6.18 | Train loss = 0.0000229 | Val loss =  0.2025788\n",
      "Epoch 133: Time taken = 6.18 | Train loss = 0.0000196 | Val loss =  0.1784726\n",
      "Epoch 136: Time taken = 6.18 | Train loss = 0.0000198 | Val loss =  0.1766572\n",
      "Epoch 140: Time taken = 6.18 | Train loss = 0.0000169 | Val loss =  0.1493665\n",
      "Epoch 150: Time taken = 6.17 | Train loss = 0.0000170 | Val loss =  0.1813039\n",
      "Epoch 160: Time taken = 6.17 | Train loss = 0.0000169 | Val loss =  0.2020223\n",
      "Epoch 162: Time taken = 6.17 | Train loss = 0.0000165 | Val loss =  0.1477443\n",
      "Epoch 170: Time taken = 6.18 | Train loss = 0.0000175 | Val loss =  0.1968377\n",
      "Epoch 176: Time taken = 6.18 | Train loss = 0.0000144 | Val loss =  0.1421674\n",
      "Epoch 180: Time taken = 6.18 | Train loss = 0.0000136 | Val loss =  0.1488329\n",
      "Epoch 190: Time taken = 6.18 | Train loss = 0.0000135 | Val loss =  0.1539701\n",
      "Epoch 192: Time taken = 6.18 | Train loss = 0.0000135 | Val loss =  0.1346151\n",
      "Epoch 200: Time taken = 6.19 | Train loss = 0.0000134 | Val loss =  0.1503453\n",
      "Epoch 210: Time taken = 6.18 | Train loss = 0.0000115 | Val loss =  0.1341260\n",
      "Epoch 217: Time taken = 6.19 | Train loss = 0.0000125 | Val loss =  0.1304252\n",
      "Epoch 220: Time taken = 6.18 | Train loss = 0.0000133 | Val loss =  0.1312073\n",
      "Epoch 229: Time taken = 6.18 | Train loss = 0.0000122 | Val loss =  0.1275336\n",
      "Epoch 230: Time taken = 6.18 | Train loss = 0.0000129 | Val loss =  0.1286369\n",
      "Epoch 240: Time taken = 6.18 | Train loss = 0.0000131 | Val loss =  0.1455008\n",
      "Epoch 250: Time taken = 6.18 | Train loss = 0.0000127 | Val loss =  0.1376297\n",
      "Epoch 253: Time taken = 6.18 | Train loss = 0.0000112 | Val loss =  0.1264753\n",
      "Epoch 257: Time taken = 6.18 | Train loss = 0.0000109 | Val loss =  0.1231827\n",
      "Epoch 260: Time taken = 6.18 | Train loss = 0.0000103 | Val loss =  0.1364475\n",
      "Epoch 268: Time taken = 6.18 | Train loss = 0.0000103 | Val loss =  0.1056242\n",
      "Epoch 270: Time taken = 6.18 | Train loss = 0.0000107 | Val loss =  0.1650041\n",
      "Epoch 280: Time taken = 6.18 | Train loss = 0.0000110 | Val loss =  0.1337446\n",
      "Epoch 290: Time taken = 6.18 | Train loss = 0.0000111 | Val loss =  0.1260893\n",
      "Epoch 300: Time taken = 6.18 | Train loss = 0.0000102 | Val loss =  0.1335851\n",
      "Epoch 310: Time taken = 6.18 | Train loss = 0.0000088 | Val loss =  0.1160429\n",
      "EARLY STOPPING. Epoch 318: Train loss = 0.0000098 | Val loss =  0.1216445\n",
      "Best Validation MSE: 0.1056242\n",
      "IMPROVED VALIDATION MSE\n",
      "\n",
      "Epoch 10: Time taken = 6.17 | Train loss = 0.0000103 | Val loss =  0.1203477\n",
      "Epoch 20: Time taken = 6.17 | Train loss = 0.0000095 | Val loss =  0.1273355\n",
      "Epoch 30: Time taken = 6.18 | Train loss = 0.0000101 | Val loss =  0.1413011\n",
      "Epoch 40: Time taken = 6.17 | Train loss = 0.0000092 | Val loss =  0.1154262\n",
      "Epoch 50: Time taken = 6.18 | Train loss = 0.0000095 | Val loss =  0.1117783\n",
      "EARLY STOPPING. Epoch 51: Train loss = 0.0000086 | Val loss =  0.1223061\n",
      "Best Validation MSE: 0.0881611\n",
      "IMPROVED VALIDATION MSE\n",
      "\n",
      "Epoch 10: Time taken = 6.19 | Train loss = 0.0000105 | Val loss =  0.1410311\n",
      "Epoch 20: Time taken = 6.18 | Train loss = 0.0000099 | Val loss =  0.1377763\n",
      "Epoch 30: Time taken = 6.18 | Train loss = 0.0000088 | Val loss =  0.1156403\n",
      "Epoch 40: Time taken = 6.18 | Train loss = 0.0000093 | Val loss =  0.1456764\n",
      "Epoch 50: Time taken = 6.18 | Train loss = 0.0000095 | Val loss =  0.1272203\n",
      "Epoch 53: Time taken = 6.18 | Train loss = 0.0000089 | Val loss =  0.1050016\n",
      "Epoch 59: Time taken = 6.17 | Train loss = 0.0000095 | Val loss =  0.1001231\n",
      "Epoch 60: Time taken = 6.18 | Train loss = 0.0000089 | Val loss =  0.1297824\n",
      "Epoch 70: Time taken = 6.18 | Train loss = 0.0000084 | Val loss =  0.1191682\n",
      "Epoch 80: Time taken = 6.18 | Train loss = 0.0000094 | Val loss =  0.1199533\n",
      "Epoch 90: Time taken = 6.17 | Train loss = 0.0000075 | Val loss =  0.1153425\n",
      "Epoch 100: Time taken = 6.18 | Train loss = 0.0000081 | Val loss =  0.1104669\n",
      "EARLY STOPPING. Epoch 109: Train loss = 0.0000072 | Val loss =  0.1059897\n",
      "Best Validation MSE: 0.1001231\n",
      "\n",
      "Epoch 10: Time taken = 6.18 | Train loss = 0.0000115 | Val loss =  0.1287881\n",
      "Epoch 20: Time taken = 6.18 | Train loss = 0.0000109 | Val loss =  0.1115518\n",
      "Epoch 30: Time taken = 6.18 | Train loss = 0.0000097 | Val loss =  0.1215771\n",
      "Epoch 40: Time taken = 6.18 | Train loss = 0.0000110 | Val loss =  0.1379233\n",
      "Epoch 50: Time taken = 6.18 | Train loss = 0.0000096 | Val loss =  0.1127137\n",
      "EARLY STOPPING. Epoch 51: Train loss = 0.0000092 | Val loss =  0.1309247\n",
      "Best Validation MSE: 0.0950608\n",
      "\n",
      "Total time: 3271.11\n",
      "Complete. Time taken: 3271.13s\n",
      "Testing complete. Time taken: 1.11\n"
     ]
    }
   ],
   "source": [
    "run_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021f9a9c-dd4d-4549-b65a-195d2dd63192",
   "metadata": {},
   "source": [
    "## 4.6 Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4eb224e2-cb94-492f-96c7-22ed0c48535d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_preds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00a4c7bd-9d75-4b6b-a71b-b3bdbdefb694",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirpath, dirnames, filenames in os.walk(res_folder):\n",
    "    for f in filenames:\n",
    "        mu_preds.append(load_obj(os.path.join(res_folder, f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce03a763-3f8b-456e-994a-02301a96bc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_preds = np.array(mu_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "021d249e-f6dd-48f6-85c0-3081a16b4071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean preds shape: (5, 100, 400, 40)\n"
     ]
    }
   ],
   "source": [
    "print(f\"mean preds shape: {mu_preds.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6622806d-4d17-4d9a-abf0-0253f0a0446d",
   "metadata": {},
   "source": [
    "# 5. Analyze results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d349930f-82f7-4530-8938-b67d9b7362eb",
   "metadata": {},
   "source": [
    "## 5.1 MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31c4a1d8-05cd-4830-becc-f23a33e56fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture_pred_all_mean = mu_preds.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3fc92fa-1969-4539-ae5b-54f5911208eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It takes around 3.82 Lyapunov Time for mean error to exceed 0.5\n",
      "\n",
      "Median NRMSE at 0.5 Lyapunov Time: 0.012\n",
      "Median NRMSE at 1.0 Lyapunov Time: 0.029\n",
      "Median NRMSE at 2.0 Lyapunov Time: 0.102\n",
      "Median NRMSE at 5.0 Lyapunov Time: 0.797\n"
     ]
    }
   ],
   "source": [
    "res_single = PointExperimentResultLyapunov(mixture_pred_all_mean - y_test, \"lorenz\")\n",
    "res_single.plot_rmse(save_name = \"LSTM Deep Ensemble Horizon\")\n",
    "print()\n",
    "res_single.get_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5940bab-d631-400a-a49d-3168d71d0990",
   "metadata": {},
   "source": [
    "## 5.2 Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fdd5d5-735b-4e79-90ed-eda4c531a245",
   "metadata": {},
   "source": [
    "**Visualise for one dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37c9cf91-abdb-4659-9884-df017290a633",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29907764-8ca3-4c54-8aca-3fd004dd26c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAq3UlEQVR4nO3de3iU5Z3/8fc3ZyCEM+EsZxBFESJIDxq0KlYtrUsrdavVVqld6bbdtVW726NXt9tfta1bXVnW0lZbTV2rFS0WtBJrrQcEESQCxnAKyClRIEBOM9/fHzNoCAGGwJMnT+bzuq65Zp7TzCchzHfmfu7nvs3dERGR9JURdgAREQmXCoGISJpTIRARSXMqBCIiaU6FQEQkzWWFHeB49e7d24cOHdqqY/ft20eXLl1ObqA2EtXsUc0Nyh6GqOaG9p992bJlu9y9T0vbIlcIhg4dyquvvtqqY0tLSykuLj65gdpIVLNHNTcoexiimhvaf3Yz23ikbWoaEhFJcyoEIiJpToVARCTNqRCIiKS5QAuBmU03s7VmVm5mt7awvZuZPWFmr5vZajO7Lsg8IiJyuMAKgZllAvcAlwDjgM+a2bhmu90ElLn7mUAxcKeZ5QSVSUREDhfkN4LJQLm7V7h7PVACzGi2jwNdzcyAfKAaaAwwk4iINGNBDUNtZjOB6e5+fXL5amCKu89psk9XYAEwFugKXOnuf2rhuWYDswEKCwsnlZSUtCpTTU0N+fn5rTo2bFHNHtXcoOxhiGpuCDa7u/P42w1M7JvJkILMVj3HtGnTlrl7UUvbgrygzFpY17zqXAysAM4HRgBPm9nz7r7nkIPc5wHzAIqKiry1F2209ws+jiaq2aOaG5Q9DFHNDcFmv+/5Cv5Y/iYDBg3hmuKxJ/35g2waqgQGN1keBGxtts91wKOeUA6sJ/HtQEREgGfKtvPDhW9yyen9uPmiMYG8RpCFYCkwysyGJU8AzyLRDNTUJuACADMrBMYAFQFmEhGJjB17a/nmH1Zy2oACfnblBDIyWmpoOXGBNQ25e6OZzQEWAZnAfHdfbWY3JrfPBW4Hfm1mq0g0Jd3i7ruCyiQiEhXuzrceXUVNXSM/v3ICedmtOzeQikAHnXP3hcDCZuvmNnm8FbgoyAwiIlH08KubeebNHXz7snGM7Ns10NfSlcUiIu3M5ur9/OCJMqYO78V1Hxoa+OupEIiItCOxuPOvD79Ohhl3fObMwM4LNBW5+QhERDqy+56v4JUN1dz56TMZ2L1Tm7ymvhGIiLQTa7bt4c7F67j4tEKumDiwzV5XhUBEpB2obYjxtZIVFHTK4j8+NZ7EyDttQ01DIiLtwA+eLGPNtr386tqz6ZWf26avrW8EIiIhe+L1rTz48ia+dN5wpo3t2+avr0IgIhKiN9/Zw22PrmLSKT0CG0LiWFQIRERCsrl6P9fMf4X83Cx+8dmzyM4M5y1ZhUBEJAQ799Zx9S9fpiEW54EvTmZAG3UVbYkKgYhIG9tb28C1v3qF7XvqmH/t2YwqDHYIiWNRIRARaUO1DTFm37+Mtdv2cu/nJjJxSI+wI6n7qIhIW4nFna+VrODFiirumjWB4jFt30OoJfpGICLSRr7/xGr+vHob3718HDMmtN2Vw8eiQiAi0gZ+/cJ67n9xI7PPHc51Hx4WdpxDqBCIiARsyZod/ODJMi4aV8it09vfbLyBFgIzm25ma82s3MxubWH7N8xsRfL2hpnFzKxnkJlERNpSVU0d//LwCsb2K+Dns4KbbvJEBFYIzCwTuAe4BBgHfNbMxjXdx91/4u4T3H0CcBvwnLtXB5VJRKStfe+JMvbVxbhr1gQ657TP/jlBfiOYDJS7e4W71wMlwIyj7P9Z4KEA84iItKmny7bzxOtbmXP+yNCvFTgac/dgnthsJjDd3a9PLl8NTHH3OS3s2xmoBEa29I3AzGYDswEKCwsnlZSUtCpTTU0N+fn5rTo2bFHNHtXcoOxhiGpuODz7vgbn3/52gK45xnen5pEVcpPQtGnTlrl7UUvbgvye0tJPfaSqcznwwpGahdx9HjAPoKioyIuLi1sVqLS0lNYeG7aoZo9qblD2MEQ1Nxye/bZHV7KnfjP33/AhzhjUPbRcqQiyaagSGNxkeRCw9Qj7zkLNQiLSQfy9fBcPvbKZG84d3u6LAARbCJYCo8xsmJnlkHizX9B8JzPrBpwHPB5gFhGRNrG/vpFbH13FsN5d+PrHRocdJyWBNQ25e6OZzQEWAZnAfHdfbWY3JrfPTe76KWCxu+8LKouISFu5c/E6NlXv5/ezzyEvOzPsOCkJtC+Tuy8EFjZbN7fZ8q+BXweZQ0SkLSzf9C7zX1jP584ZwpThvcKOkzJdWSwichI0xJ1bHllJ/4I8bmmHVw8fTfu8ukFEJGIWvN3AWzsa+NW1Z9M1LzvsOMdF3whERE7Q8k3v8qeKBv5h4qBQJp8/USoEIiInoKaukX99+HV65Brf/cS4Yx/QDqkQiIi0UjzufP33K9hUvZ8bzsilIGJNQgepEIiItIK786On3uTpsu38+6WnMrZnNLqKtkQni0Ukbe0+0MDbO2uorqknNzuDwoI8RvTJJ/MY4wI1xuLc/mQZv3lxI1efcwrXfmgozz23sY1Sn3wqBCKSVmrqGnlseSWPLKtk5ZbdNB93s3NOJuMHduOc4b348MjeTBjcnZysRONJPO68vL6aHy4s440te7jho8P41sdPxaz9zTFwPFQIRCQtxOLOQ69s4mdPr6NqXz2nDSjgqxeMYvzAbvTOz6U+Fmdz9X5WVu5m+aZ3+a9n3+Kuv7xFblYGg3t2Ji87g3feq6VqXz2983O556qJfHx8v8gXAVAhEJE0UPnufv7l4dd5ZX01k4f1ZN70MUwc0uOwN/Gzh/bkiomDANi9v4EXK6pYtrGaTdX7qW+MM7ZfAeeO7sMFY/vSJbfjvH12nJ9ERKQFSzdUM/v+V2mIOT+ZeQYzJw1K6VN8t87ZTD+9H9NP79cGKcOlQiAiHdYfX9vCNx9ZyaAenfjltWczrHeXsCO1SyoEItIh/X7pJm75wyrOGd6TuZ+bRPfOOWFHardUCESkw3l0eSW3PrqK80b3Yd41k8jNim4f/7agC8pEpEN5cuVWbv6/15k6vBf/c7WKQCoCLQRmNt3M1ppZuZndeoR9is1shZmtNrPngswjIh3b4tXb+GrJCiad0oP7Pl8UmYlhwhZY05CZZQL3ABeSmL94qZktcPeyJvt0B/4bmO7um8wsesP2iUi7sGTNDm56cDmnD+zG/GvPpnOOWr5TFeQ3gslAubtXuHs9UALMaLbPVcCj7r4JwN13BJhHRDqoF8p38aXfLmN0YVfuv25y5OYDCFuQhWAgsLnJcmVyXVOjgR5mVmpmy8zsmgDziEgHtGTNDr74m6UM792F335xCt06qwgcL/PmA22crCc2+zRwsbtfn1y+Gpjs7l9pss/dQBFwAdAJeBG41N3XNXuu2cBsgMLCwkklJSWtylRTU0N+fn6rjg1bVLNHNTcoe1s50OhUHXAcoH4/A3t2ISOFC77i7jyzsZGH1tQzpCCDf52UR0FueMM9tPff+bRp05a5e1FL24JsRKsEBjdZHgRsbWGfXe6+D9hnZn8FzgQOKQTuPg+YB1BUVOTFxcWtClRaWkprjw1bVLNHNTco+/HYVVPH4tXbWb11N7sPNGBmdM3LoiAvm4JOifv83Cz21jawY28dle8eYGPVPjZW7adqX32TZzI6Zddx1pDufGhEL6aO6M3pAwsO6fnj7izf9C53LFrHixVVfOzUvtw166zQh3yI8t9LkL+5pcAoMxsGbAFmkTgn0NTjwN1mlgXkAFOAnwWYSUROovrGOHcuXstvXtxAbUOcgrwseufn4sDe2kb2HGigPhY/5JgMg34FeQzt3YWLTivklF5dGNSjExlmvPTaG2R0H8DL66u5Y/E6YB05mRmM7d+Vgd07EYs7a7btZVP1fgrysvjRFeOZdfbgDjHwW5gCKwTu3mhmc4BFQCYw391Xm9mNye1z3f1NM/szsBKIA/e5+xtBZRKRk+e9/fV86YFlvLy+mismDuRL545gdGH+YW/KtQ0x9tQ2sLe2ka55WfTqknvE8f47V62luPg0AKr31fNyRRUrKt9j5ebdlO+owYFx/Qu44dzhXHHWwNC/BXQUgf4W3X0hsLDZurnNln8C/CTIHCJycjXE4sx+YBkrNr3Hz6+cwCfPat4P5AN52ZnkZWfSt+vxvUbPLjlcMr4/l4zvf4Jp5VhUTkXkuP1o4RpeWV99zCIg0aAhJkTkuLxcUcX8F9Zz7YeGqgh0ECoEIpKyxlic7y5YzcDunbhl+tiw48hJokIgIil78JVNrNm2l29fdiqdcjSOT0ehQiAiKalrjHHPknImD+3Jxad1/Fm70okKgYik5A/LtrB9Tx1fuWCk+u13MCoEInJMjbE49z5XzpmDuvGRkb3DjiMnmQqBiBzTM2/uYHP1Ab5cPELfBjogFQIROaYHXtrAgG55fOzUwrCjSABUCETkqMp31PBCeRVXTRlCVqbeMjoi/auKyFE9+PImsjONK88eEnYUCYgKgYgcUUMszuMrtvCxUwvp0zU37DgSEBUCETmi59bupGpfPf8wcVDYUSRAKgQickSPvlZJzy45nDemT9hRJEAqBCLSot37G3imbAefOHMA2TpJ3KHpX1dEWvTkqq3Ux+JqFkoDgRYCM5tuZmvNrNzMbm1he7GZ7TazFcnbd4LMIyKpe3T5FkYX5nP6wIKwo0jAApuYxswygXuAC0lMUr/UzBa4e1mzXZ9398uCyiEix6/y3f0s2/gu37h4jK4kTgNBfiOYDJS7e4W71wMlwIwAX09ETpKnVm0D4FJNE5kWgiwEA4HNTZYrk+uam2pmr5vZU2Z2WoB5RCRFf1r1DqcNKGBo7y5hR5E2YO4ezBObfRq42N2vTy5fDUx296802acAiLt7jZl9HLjL3Ue18FyzgdkAhYWFk0pKSlqVqaamhvz8/FYdG7aoZo9qbkjf7LsOxLn5uQPMHJ3NZcNzTnKyo0vX33lbmDZt2jJ3L2pxo7sHcgOmAouaLN8G3HaMYzYAvY+2z6RJk7y1lixZ0upjwxbV7FHN7Z6+2ec997afcsuTvmFXzckLlKJ0/Z23BeBVP8L7apBNQ0uBUWY2zMxygFnAgqY7mFk/S56JMrPJJJqqqgLMJCLH8OSqdzh9YAGn9FKzULoIrNeQuzea2RxgEZAJzHf31WZ2Y3L7XGAm8GUzawQOALOSlUtEQrC5ej+vb36Pb04fE3YUaUOBFQIAd18ILGy2bm6Tx3cDdweZQURS99Qb7wDqLZRudGWxiLzvT6u2qVkoDakQiAgA7+w+wOub3+OS0/VtIN0csxCYWaGZ/dLMnkoujzOzLwYfTUTa0jNl2wG4+DRNR5luUvlG8GsSJ3wHJJfXAV8LKI+IhGRx2XaG9e7CiD7tty+8BCOVQtDb3R8G4pDoDQTEAk0lIm1qT20DL1VUcdG4Qo0tlIZSKQT7zKwX4ABmdg6wO9BUItKmStfupCHmXDhOzULpKJXuo/9C4kKwEWb2AtCHRP9/Eekgni7bTq8uOZw1pEfYUSQExywE7r7czM4DxgAGrHX3hsCTiUibqG+MU7pmBx8f35/MDDULpaNUeg3dBOS7+2p3fwPIN7N/Cj6aiLSFlyqq2FvXqGahNJbKOYIb3P29gwvu/i5wQ2CJRKRNPV22nU7ZmXxkVO+wo0hIUikEGdakG0Fy5rG2HZtWRALh7jzz5nbOHd2bvOzMsONISFIpBIuAh83sAjM7H3gI+HOwsUSkLbyxZQ/v7K7lwnH9wo4iIUql19AtwJeAL5M4WbwYuC/IUCLSNhaXbSPD4PyxfcOOIiFKpddQHLg3eRORDuTpsu2cPbQnPbuotTedpdJr6MNm9rSZrTOzCjNbb2YVbRFORIKzqWo/a7btVW8hSalp6JfA14FlaGgJkQ5jcdk2AC7S+YG0l8rJ4t3u/pS773D3qoO3VJ7czKab2VozKzezW4+y39lmFjMzXbEs0kaeLtvOmMKuDOnVOewoErJUCsESM/uJmU01s4kHb8c6KNnN9B7gEmAc8FkzG3eE/X5MoneSiLSBd/fVs3RDNRdpyGkhtaahKcn7oibrHDj/GMdNBsrdvQLAzEqAGUBZs/2+AvwBODuFLCJyEjy7ZgdxR+cHBAALaq74ZDPPdHe/Prl8NTDF3ec02Wcg8CCJovJL4El3f6SF55oNzAYoLCycVFJS0qpMNTU15OdHc6z1qGaPam7o2Nl/8VotFe/F+Wlxp3Y17HRH/p2Hbdq0acvcvailbSlNXm9mlwKnAXkH17n7D451WAvrmlednwO3uHvsaH+M7j4PmAdQVFTkxcXFxw7dgtLSUlp7bNiimj2quaHjZq9tiPHlvzzNzElDmDbt9LYNdgwd9Xfe3h2zEJjZXKAzMI3EhWQzgVdSeO5KYHCT5UHA1mb7FAElySLQG/i4mTW6+x9TeH4RaYUXyndxoCGmZiF5Xyoniz/k7tcA77r794GpHPoGfyRLgVFmNszMcoBZJOY1eJ+7D3P3oe4+FHgE+CcVAZFgLVq9ja55WZwzvFfYUaSdSKVp6EDyfr+ZDQCqgGHHOsjdG81sDoneQJnAfHdfbWY3JrfPbWVmEWmlWNx55s0dnD+2LzlZqXwOlHSQSiF40sy6Az8BlpNo509prCF3XwgsbLauxQLg7tem8pwi0nrLNr5L9b56XUQmh0hlrKHbkw//YGZPAnnurjmLRSJo8ept5GRmcN6YPmFHkXbkiIXAzM5392fN7IoWtuHujwYbTUROJndncdl2PjyyF/m5KXUYlDRxtL+G84Bngctb2OaACoFIhKzdvpdN1fv5cvGIsKNIO3PEQuDu3zWzDOApd3+4DTOJSAAWr96OGVxwquYekEMdtdtAci6COUfbR0SiYXHZNiYO6UHfrnnH3lnSSir9x542s5vNbLCZ9Tx4CzyZiJw0m6v388aWPbqITFqUyhmjLyTvb2qyzoHhJz+OiAThT6veAeDS8f1DTiLtUSrdR4958ZiItG9PvL6VCYO7M7in5h6Qw6U66NzpJOYUaDro3P1BhRKRk+ftnTWs3rqHb1922HQgIkBqg859FygmUQgWkpho5m+ACoFIBDz5+juYqVlIjiyVk8UzgQuAbe5+HXAmkBtoKhE5KdydJ1ZuZfLQnvTrpt5C0rJUCkFtshtpo5kVADvQiWKRSFi7fS/lO2q4/MwBYUeRduxoQ0zcDTwEvJIcdO5/gWVADanNRyAiIXt0+RayMoxLTtcgc3JkRztH8BZwBzCAxJv/Q8CFQIG7r2yDbCJyAuob4zy6vJILTu1Lr3y15sqRHbFpyN3vcvepwLlANfAr4Cngk2Y2qo3yiUgrPbtmO7tq6rny7FTmkZJ0dsxzBO6+0d1/7O5nAVcBnwLWBJ5MRE7I75duprAgl3NHachpObpjFgIzyzazy83sdyS+EawD/iGVJzez6Wa21szKzezWFrbPMLOVZrbCzF41s48c908gIofZsT9O6bqdfKZoMFmZmolMju5oJ4svBD4LXEri5HAJMNvd96XyxGaWCdxD4rxCJbDUzBa4e1mT3f4CLHB3N7MzgIeBsa36SUTkfc9sbCDTjM+dc0rYUSQCjnay+FvAg8DN7l7diueeDJS7ewWAmZUAM4D3C4G71zTZvwuJMYxE5ATsrW3gr5WNXHbGAAoLdO2AHJu5B/Pea2Yzgenufn1y+WpgirvPabbfp4AfAX2BS939xRaeazYwG6CwsHBSSUlJqzLV1NSQn5/fqmPDFtXsUc0N0c3+5/UNlKyt5ztT8xjeLTPsOMclqr9zaP/Zp02btszdi1raFuR8ddbCusOqjrs/BjxmZucCtwMfa2GfecA8gKKiIi8uLm5VoNLSUlp7bNiimj2quSGa2Q/Ux7j5b0s4tWcGX5hxQdhxjlsUf+cHRTl7kGeRKoGm/dYGAVuPtLO7/xUYYWa9A8wk0qE9+MomdtXU8cmROWFHkQgJshAsBUaZ2TAzywFmAQua7mBmI83Mko8nAjlAVYCZRDqsvbUN3Fv6NlOH92JMz2g1CUm4AmsacvdGM5sDLAIygfnuvtrMbkxun0uiG+o1ZtYAHACu9KBOWoh0cHcuXkfVvjruu6SI995eEXYciZAgzxHg7gtJDF3ddN3cJo9/DPw4yAwi6eCNLbu5/8UNfG7KKUwY3J3St8NOJFGiK01EIi4Wd/7tsVX07JLLzRePCTuORJAKgUjEPfjyRl6v3M23LzuVbp2yw44jEaRCIBJhO/bW8v8WreXDI3vxCc05IK2kQiASYT/805vUNcS5fcbpJDvgiRw3FQKRiHqhfBePr9jKjcUjGN6n/V7RKu2fCoFIBNU2xPj3P77BKb0680/FI8KOIxEXaPdREQnG/zxXwfpd+7j/C5PJy9bFY3Ji9I1AJGI27NrHPaXlXHZGf84drUln5MSpEIhEiLvznQWryc3M4NuXjQs7jnQQKgQiEbK4bDt/XbeTr184WnMNyEmjQiASEbUNMW5/sowxhV25ZqpmHpOTRyeLRSJi7nNvU/nuAR664RzNQywnlf6aRCLgnd0HuLf0bS49oz9TR/QKO450MCoEIhHwX38pJ+7ObZeMDTuKdEAqBCLt3Maqffzfq5u5avIQBvXoHHYc6YBUCETaubueeYusTOOmaSPDjiIdVKCFwMymm9laMys3s1tb2P6PZrYyefu7mZ0ZZB6RqHlr+14eW7GFz08dSl91F5WABFYIzCwTuAe4BBgHfNbMml8Bsx44z93PAG4H5gWVRySKfvbMOrrkZHHjeRpPSIIT5DeCyUC5u1e4ez1QAsxouoO7/93d300uvgQMCjCPSKS8sWU3C1dt4wsfGUaPLjlhx5EOzIKaK97MZgLT3f365PLVwBR3n3OE/W8Gxh7cv9m22cBsgMLCwkklJSWtylRTU0N+fjSH641q9qjmhvCz/3RZLW+/F+Mn53amc/bxzTUQdvbWimpuaP/Zp02btszdi1rc6O6B3IBPA/c1Wb4a+MUR9p0GvAn0OtbzTpo0yVtryZIlrT42bFHNHtXc7uFmf3VDlZ9yy5P+30vKW3V8VH/vUc3t3v6zA6/6Ed5Xg7yyuBIY3GR5ELC1+U5mdgZwH3CJu1cFmEckMu5YtI7e+bl8/kMaSkKCF+Q5gqXAKDMbZmY5wCxgQdMdzGwI8ChwtbuvCzCLSGS8UL6LFyuquGnaCDrnaBQYCV5gf2Xu3mhmc4BFQCYw391Xm9mNye1zge8AvYD/Ts632uhHasMSSQPuzh2L1zKgWx5XTRkSdhxJE4F+3HD3hcDCZuvmNnl8PXDYyWGRdPXsmh28tuk9fnTFeHKzNPOYtA1dWSzSTsTjzp2L13FKr87MnKSe1NJ2VAhE2oknVm6l7J09fP1jo8nWMNPShvTXJtIO1DfGuXPxOk7tX8AnzhwQdhxJMyoEIu1AydJNbKrezzenjyEj4/guHhM5USoEIiHbV9fIf/3lLaYM60nx6D5hx5E0pEIgErL7nl/Prpp6brlkLMlu1CJtSoVAJEQ79tbyv89XcPFphUwc0iPsOJKmVAhEQvTjp9ZS1xjjlumaglLCo0IgEpJlG9/lD8sruf6jwxnep/2OWikdnwqBSAhiced7C1bTryCPOZqCUkKmQiASgt++tJFVW3Zz28fH0iVXA8tJuFQIRNrY5ur9/PjPazh3dB9dPCbtggqBSBuKx51vPrKSDDP+84rx6i4q7YIKgUgb+t0rm3ixoop/u/RUBnTvFHYcEUCFQKTNrN66m9ufLOPc0X2YdfbgYx8g0kZUCETawO79Ddz0u+X06JzNzz5zppqEpF0JtBCY2XQzW2tm5WZ2awvbx5rZi2ZWZ2Y3B5lFJCx1jTFueOBVtrx3gLuvmkiv/NywI4kcIrB+a2aWCdwDXEhiIvulZrbA3cua7FYN/DPwyaByiISptiHGVx56jVfWV3PXrAmcPbRn2JFEDhPkN4LJQLm7V7h7PVACzGi6g7vvcPelQEOAOURCsWNvLZ+f/wpPl23n+584jRkTBoYdSaRF5u7BPLHZTGB6cl5izOxqYIq7z2lh3+8BNe5+xxGeazYwG6CwsHBSSUlJqzLV1NSQnx/NS/mjmj2KuWNxZ/t+Z8u7+6m1XGpj0BBzGuKQk2l0yoKuOUaPPKNHrtEt18ho0ua/r8H5+5ZG/vh2PXUxuP70XM4Z0LYXjUXx9w7RzQ3tP/u0adOWuXtRS9uC/Ots6WxYq6qOu88D5gEUFRV5cXFxqwKVlpbS2mPDFtXsUcldvqOGP618h7+/vYuVlbs50BAj8Sdcf8xjMzOMvl1zKSzIo7YhRsXOfdTH4kwe1pMfXTGeESGMIxSV33tzUc0N0c4eZCGoBJr2kRsEbA3w9USO28sVVdy9pJzn39qFGYwf2I0rzx7M+IHd2LVxLR8vnkqX3CzysjPIyczgQEOMvbWNVNXUs21PLdv21LJ9d/J+Ty09u+Rw3pg+XH7GAE4f2C3sH08kJUEWgqXAKDMbBmwBZgFXBfh6Iilbv2sf33n8DZ5/axe983P4xsVjmDlpEIUFee/vU7q3nME9Ox9yXNfMDLrmZTOgeyfGozd66RgCKwTu3mhmc4BFQCYw391Xm9mNye1zzawf8CpQAMTN7GvAOHffE1QuSW+xuHNvaTn/9Ww5OZkZ/Pulp/KPU06hU05m2NFEQhPoGSx3XwgsbLZubpPH20g0GYkEbseeWr5asoIXK6q4dHx/vnP5uEO+AYikK41/K2nhb2/t4mu/f42aukZ+MvMMPl2kIR5EDlIhkA4tFnfuemYdv1hSzsg++Tx4wzmMLuwadiyRdkWFQDqs7Xtq+eeHXuPl9dV8etIgvj/jNDrn6E9epDn9r5AO6a/rdvL1369gf32MOz59JjMn6VSUyJGoEEiH0hiL8/Nn3uKe0nJG9c2n5KqJjFJTkMhRqRBIh7Ftdy3/XJIY4O0zRYP4/idOV7dQkRSoEEiH8HTZdr75yOvUNcb56WfO5IqJagoSSZUKgUTagfoYP1xYxm9f2sRpAwq4a9ZZjOzbfgf+EmmPVAgksl6uqOK2x1ZRsXMfN3x0GDdfPIbcLDUFiRwvFQKJnO17arlz8VoefrWSQT068cAXJ/PRUX3CjiUSWSoEEhlb3zvA/L+t54GXNhKLOzeeN4KvXjBKJ4RFTpAKgbRrO/fW8bfynTy+YivPrduJAf8wcRD/fMGow0YGFZHWUSGQULk7ew40srOmjl01dezcW0fFzn2U76xh7bY9rNteA0C/gjzmTBvJZ4oGqwCInGQqBBKIA/Uxtu2p5c2qGLtXbGFXTT27aurYtTfxhn9wuaqmnvpY/JBjzWBQj06M6tuVGRMG8tFRvTltQDcyM1qa9E5ETpQKgZyQ6n31rNm2h3Xb9rJ2e+JTfPmOGvbUNn6w09IVAGRnGr265NK7aw6983MZ068rvfNz6Z2fQ5+uucnHuQzp2Vnt/iJtSIVAUlK9r57yHTXv39Zt38uabXvZVVP3/j7dOmUzpl9XLj9zAAO6d6JfQR7bN6zloo9Opnd+Lt06ZWOmT/Ui7U2ghcDMpgN3kZih7D53/89m2y25/ePAfuBad18eZCb5gLtT2xDnvQP17D7QwO79DezYW8c7uw/wzu5atu2uZevuWiqr91O174NJ3DtlZzKqMJ/iMX0Y268rowu7MrZfV/p0zT3sjb50bzkj+2qsH5H2LLBCYGaZwD3AhSQmsl9qZgvcvazJbpcAo5K3KcC9yftIcnca405jzGmIx2mMOY2xOA3x5H3MaUyub4jFaYwn75PrG2L+/uND18VZu6GBNc+9fdjzNMYPfY3Eazv1jTHqG+PUx+LUNSTu6xsTt7rGOHWNMfYcaDysff6gLjmZ9O/eif7d8rhwXCEj++Yzom8+o/rmM6BbJzLUXi/SYQT5jWAyUO7uFQBmVgLMAJoWghnA/e7uwEtm1t3M+rv7Oyc7zHPrdvKt5/fTaVkp7uBA3B33D+7dHYcP1pFc12Q5Hk/c03Sd+/tvyoFas+b9h5kZRtbBW2YG2ZlGVkYGWZlGdmYGOZkZ5GQlbrlZGeTnZTVbl0lBpyy6dcqme6ccunXKplunbPp0zaVftzwK8rLUjCOSJoIsBAOBzU2WKzn8035L+wwEDikEZjYbmA1QWFhIaWnpcYcpfzdGYV6c7MxaAA5+oDUDw7D3HyfuATIA7IN7g0P3w5L7ZpCVAZkGmQfvzT54nAFZLazLNCPTaHaskdF0nSXe9A/s30e3/C5kZiSyZxzzTTqevKXgQOLWSOIXfzKrcE1NTav+vdoDZW97Uc0N0c4eZCFo6Z2q+UfmVPbB3ecB8wCKioq8uLj4uMMUAyNLS2nNse1BaUSzRzU3KHsYopobop09I8DnrgSazhA+CNjain1ERCRAQRaCpcAoMxtmZjnALGBBs30WANdYwjnA7iDOD4iIyJEF1jTk7o1mNgdYRKL76Hx3X21mNya3zwUWkug6Wk6i++h1QeUREZGWBXodgbsvJPFm33Td3CaPHbgpyAwiInJ0QTYNiYhIBKgQiIikORUCEZE0p0IgIpLmLHG+NjrMbCewsZWH9wZ2ncQ4bSmq2aOaG5Q9DFHNDe0/+ynu3uLk3pErBCfCzF5196Kwc7RGVLNHNTcoexiimhuinV1NQyIiaU6FQEQkzaVbIZgXdoATENXsUc0Nyh6GqOaGCGdPq3MEIiJyuHT7RiAiIs2oEIiIpLm0KQRmNt3M1ppZuZndGnaeVJnZfDPbYWZvhJ3leJjZYDNbYmZvmtlqM/tq2JlSZWZ5ZvaKmb2ezP79sDMdDzPLNLPXzOzJsLMcDzPbYGarzGyFmb0adp5UJafYfcTM1iT/3qeGnel4pcU5AjPLBNYBF5KYDGcp8Fl3Lzvqge2AmZ0L1JCY2/n0sPOkysz6A/3dfbmZdQWWAZ+MyO/cgC7uXmNm2cDfgK+6+0shR0uJmf0LUAQUuPtlYedJlZltAIrcvT1flHUYM/sN8Ly735ece6Wzu78Xcqzjki7fCCYD5e5e4e71QAkwI+RMKXH3vwLVYec4Xu7+jrsvTz7eC7xJYj7qds8TapKL2clbJD4xmdkg4FLgvrCzpAMzKwDOBX4J4O71USsCkD6FYCCwuclyJRF5U+oIzGwocBbwcshRUpZsXlkB7ACedveoZP858E0gHnKO1nBgsZktM7PZYYdJ0XBgJ/CrZHPcfWbWJexQxytdCoG1sC4Sn/CizszygT8AX3P3PWHnSZW7x9x9Aol5tCebWbtvljOzy4Ad7r4s7Cyt9GF3nwhcAtyUbBZt77KAicC97n4WsA+IzDnIg9KlEFQCg5ssDwK2hpQlbSTb1/8A/M7dHw07T2skv+aXAtPDTZKSDwOfSLa1lwDnm9lvw42UOnffmrzfATxGokm3vasEKpt8Y3yERGGIlHQpBEuBUWY2LHkyZxawIORMHVryhOsvgTfd/adh5zkeZtbHzLonH3cCPgasCTVUCtz9Nncf5O5DSfyNP+vunws5VkrMrEuyUwHJppWLgHbfU87dtwGbzWxMctUFQLvvENFcoHMWtxfu3mhmc4BFQCYw391XhxwrJWb2EFAM9DazSuC77v7LcFOl5MPA1cCqZFs7wLeS81i3d/2B3yR7m2UAD7t7pLpiRlAh8Fji8wNZwIPu/udwI6XsK8Dvkh8yK4DrQs5z3NKi+6iIiBxZujQNiYjIEagQiIikORUCEZE0p0IgIpLmVAhERNJcWnQflY7JzGrcPT/sHCfCzK4DDo7MOg5YC8SAPwP1wF/d/ZmQ4kmaUPdRiayOUAiaiuromxJ9ahqSDsHMMszsLTPr02S53Mx6m9nlZvZyclCwZ8ysMLnP98zsATN7NnnsDcn1xU3H8jezu83s2uTjDWb2fTNbnhw7f2xyfU8z+6OZrTSzl8zsjGSGDQevUk7uV37w9VP4mX5tZjObvO5/mNmLZvaqmU00s0Vm9raZ3djkmG+Y2dJkjkjNoyDhUSGQDsHd48BvgX9MrvoY8Hry0/XfgHOSg4KVkBid86AzSAzbPBX4jpkNSOHldiUHR7sXuDm57vvAa+5+BvAtEvNHxIHHgU8BmNkUYIO7b2/lj7nZ3acCzwO/BmYC5wA/SD7/RcAoEmP0TAAmRWTgNgmZCoF0JPOBa5KPvwD8Kvl4ELDIzFYB3wBOa3LM4+5+IFkwlpDaQGcHB9BbBgxNPv4I8ACAuz8L9DKzbsDvgSuT+8xKLrfWwfGxVgEvu/ted98J1Ca/dVyUvL0GLAfGkigMIkelQiAdhrtvBrab2fnAFOCp5KZfAHe7+3jgS0Be08OaPw3QyKH/N/Ka7VOXvI/xQYeLIw11/iIwMtlk9Uk+KCKtcfB1400eH1zOSmb4kbtPSN5GRmRcKgmZCoF0NPeRaCJ62N1jyXXdgC3Jx59vtv8MS8xR3IvE4H5LgY3AODPLTX6qvyCF1/0ryWYpMysm0Xy0xxO9MR4DfkpiJNaq1v5gKVgEfCE5BwRmNtDM+gb4etJBqPuoRFnn5IisB/2UxKf/X/FBsxDA94D/M7MtwEvAsCbbXgH+BAwBbj84Jr6ZPQysBN4i0dRyLN8jMUvVSmA/hxac35MoMNem+HO1irsvNrNTgReTo3jWAJ8jMcuayBGp+6h0KGZWBPzM3T+awr7fA2rc/Y7Ag4m0Y/pGIB2Gmd0KfJkPeg6JSAr0jUBEJM3pZLGISJpTIRARSXMqBCIiaU6FQEQkzakQiIikuf8PrqeJefEAODoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(L_forecast_test) / LORENZ_LT * 0.01, mu_preds.var(axis = 0)[idx].mean(axis = 1))\n",
    "plt.grid(\"on\")\n",
    "plt.xlabel(\"Lyapunov Time\")\n",
    "plt.ylabel(\"Variance\")\n",
    "plt.savefig(\"LSTM Deep Ensemble Variance.png\", facecolor = \"white\", bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c7b5b0-794f-4258-8eee-eeb95c6914ee",
   "metadata": {},
   "source": [
    "## 5.3 Negative Log LH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "85d367e5-118a-49b5-a8fe-1ccaf1ee2a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_log_LH(mean_pred, sd_pred):\n",
    "    d = 40\n",
    "    \n",
    "    constant_loss = d * np.log(2 * np.pi)\n",
    "    mu_loss = (mean_pred - y_test)**2\n",
    "    \n",
    "    return 0.5 * (constant_loss + d * np.log(sd_pred) + (mu_loss / sd_pred**2)).mean(axis = (0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d9bc6ed-c14f-4256-8086-6d75f0f5a228",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_dev = mu_preds.std(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "348d6d99-32f0-4648-94d7-f71a2c2c71c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(L_forecast_test) / LORENZ_LT * 0.01, neg_log_LH(mixture_pred_all_mean,  std_dev))\n",
    "# plt.title(\"Negative Log LH against time\")\n",
    "plt.ylabel(\"Negative Log LH\")\n",
    "plt.xlabel(\"Lyapunov Time\")\n",
    "# plt.ylabel(\"Negative Log LH\")\n",
    "plt.grid(\"on\")\n",
    "plt.savefig(\"LSTM Deep Ensemble NLL.png\", facecolor = \"white\", bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c354420-1fac-4e40-90cf-1d408fae7615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall negative log LH: 1.59540\n"
     ]
    }
   ],
   "source": [
    "print(f\"Overall negative log LH: {neg_log_LH(mixture_pred_all_mean, std_dev).mean():.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
